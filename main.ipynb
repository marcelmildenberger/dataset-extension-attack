{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Record Linkage (PPRL): Investigating Dataset Extension Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all relevant libraries and classes used throughout the project. Key components include:\n",
    "\n",
    "- **Torch** ‚Äì for tensor operations and neural network functionality  \n",
    "- **Datasets** ‚Äì for handling training and evaluation data  \n",
    "- **PyTorch Models** ‚Äì custom and pre-defined models for the DEA  \n",
    "- **Graph Matching Attack (GMA)** ‚Äì core logic for the initial re-identification phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NumPy dot (Mac)\n",
      "System Version: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:20:01) [Clang 18.1.8 ]\n",
      "PyTorch version 2.1.2\n",
      "Torchvision version 0.16.2\n",
      "Numpy version 1.24.4\n",
      "Pandas version 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import hickle as hkl\n",
    "import numpy as np\n",
    "import string\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from graphMatching.gma import run_gma\n",
    "\n",
    "from datasets.bloom_filter_dataset import BloomFilterDataset\n",
    "from datasets.tab_min_hash_dataset import TabMinHashDataset\n",
    "from datasets.two_step_hash_dataset import TwoStepHashDataset\n",
    "\n",
    "from pytorch_models.bloom_filter_to_two_gram_classifier import BloomFilterToTwoGramClassifier\n",
    "from pytorch_models.tab_min_hash_to_two_gram_classifier import TabMinHashToTwoGramClassifier\n",
    "from pytorch_models.two_step_hash_to_two_gram_classifier import TwoStepHashToTwoGramClassifier\n",
    "from pytorch_models.test_model import TestModel\n",
    "\n",
    "from early_stopping.early_stopping import EarlyStopping\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Configuration and parameters for the Graph Matching Attack (GMA) and Dataset Extension Attack (DEA). For details and possible values, refer to the documentation at ```./docs/parameters.md```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "GLOBAL_CONFIG = {\n",
    "    \"Data\": \"./data/datasets/fakename_1k.tsv\",\n",
    "    \"Overlap\": 0.8,\n",
    "    \"DropFrom\": \"Eve\",\n",
    "    \"Verbose\": True,  # Print Status Messages\n",
    "    \"MatchingMetric\": \"cosine\",\n",
    "    \"Matching\": \"MinWeight\",\n",
    "    \"Workers\": -1,\n",
    "    \"SaveAliceEncs\": False,\n",
    "    \"SaveEveEncs\": False,\n",
    "    \"DevMode\": False,\n",
    "}\n",
    "\n",
    "\n",
    "DEA_CONFIG = {\n",
    "    \"DevMode\": False,\n",
    "    # BCEWithLogitsLoss / MultiLabelSoftMarginLoss\n",
    "    \"LossFunction:\": \"BCEWithLogitsLoss\",\n",
    "    # Adam / AdamW / SGD / RMSprop\n",
    "    \"Optimizer\": \"Adam\",\n",
    "    \"LearningRate\": 0.001,\n",
    "    # SGD only\n",
    "    \"Momentum\": 0.9,\n",
    "    \"BatchSize\": 16,\n",
    "    \"Epochs\": 20,\n",
    "    # TestSize calculated accordingly\n",
    "    \"TrainSize\": 0.8,\n",
    "    \"FilterThreshold\": 0.5,\n",
    "    \"Patience\": 5,\n",
    "    \"MinDelta\": 0.001,\n",
    "}\n",
    "\n",
    "ENC_CONFIG = {\n",
    "    # TwoStepHash / TabMinHash / BloomFilter\n",
    "    \"AliceAlgo\": \"BloomFilter\",\n",
    "    \"AliceSecret\": \"SuperSecretSalt1337\",\n",
    "    \"AliceN\": 2,\n",
    "    \"AliceMetric\": \"dice\",\n",
    "    \"EveAlgo\": \"None\",\n",
    "    \"EveSecret\": \"ATotallyDifferentString42\",\n",
    "    \"EveN\": 2,\n",
    "    \"EveMetric\": \"dice\",\n",
    "    # For BF encoding\n",
    "    \"AliceBFLength\": 1024,\n",
    "    \"AliceBits\": 10,\n",
    "    \"AliceDiffuse\": False,\n",
    "    \"AliceT\": 10,\n",
    "    \"AliceEldLength\": 1024,\n",
    "    \"EveBFLength\": 1024,\n",
    "    \"EveBits\": 10,\n",
    "    \"EveDiffuse\": False,\n",
    "    \"EveT\": 10,\n",
    "    \"EveEldLength\": 1024,\n",
    "    # For TMH encoding\n",
    "    \"AliceNHash\": 1024,\n",
    "    \"AliceNHashBits\": 64,\n",
    "    \"AliceNSubKeys\": 8,\n",
    "    \"Alice1BitHash\": True,\n",
    "    \"EveNHash\": 1024,\n",
    "    \"EveNHashBits\": 64,\n",
    "    \"EveNSubKeys\": 8,\n",
    "    \"Eve1BitHash\": True,\n",
    "    # For 2SH encoding\n",
    "    \"AliceNHashFunc\": 10,\n",
    "    \"AliceNHashCol\": 1000,\n",
    "    \"AliceRandMode\": \"PNG\",\n",
    "    \"EveNHashFunc\": 10,\n",
    "    \"EveNHashCol\": 1000,\n",
    "    \"EveRandMode\": \"PNG\",\n",
    "}\n",
    "\n",
    "EMB_CONFIG = {\n",
    "    \"Algo\": \"Node2Vec\",\n",
    "    \"AliceQuantile\": 0.9,\n",
    "    \"AliceDiscretize\": False,\n",
    "    \"AliceDim\": 128,\n",
    "    \"AliceContext\": 10,\n",
    "    \"AliceNegative\": 1,\n",
    "    \"AliceNormalize\": True,\n",
    "    \"EveQuantile\": 0.9,\n",
    "    \"EveDiscretize\": False,\n",
    "    \"EveDim\": 128,\n",
    "    \"EveContext\": 10,\n",
    "    \"EveNegative\": 1,\n",
    "    \"EveNormalize\": True,\n",
    "    # For Node2Vec\n",
    "    \"AliceWalkLen\": 100,\n",
    "    \"AliceNWalks\": 20,\n",
    "    \"AliceP\": 250,\n",
    "    \"AliceQ\": 300,\n",
    "    \"AliceEpochs\": 5,\n",
    "    \"AliceSeed\": 42,\n",
    "    \"EveWalkLen\": 100,\n",
    "    \"EveNWalks\": 20,\n",
    "    \"EveP\": 250,\n",
    "    \"EveQ\": 300,\n",
    "    \"EveEpochs\": 5,\n",
    "    \"EveSeed\": 42\n",
    "}\n",
    "\n",
    "ALIGN_CONFIG = {\n",
    "    \"RegWS\": max(0.1, GLOBAL_CONFIG[\"Overlap\"]/2), #0005\n",
    "    \"RegInit\":1, # For BF 0.25\n",
    "    \"Batchsize\": 1, # 1 = 100%\n",
    "    \"LR\": 200.0,\n",
    "    \"NIterWS\": 100,\n",
    "    \"NIterInit\": 5 ,  # 800\n",
    "    \"NEpochWS\": 100,\n",
    "    \"LRDecay\": 1,\n",
    "    \"Sqrt\": True,\n",
    "    \"EarlyStopping\": 10,\n",
    "    \"Selection\": \"None\",\n",
    "    \"MaxLoad\": None,\n",
    "    \"Wasserstein\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Data Preparation: Load or Compute Graph Matching Attack (GMA) Results\n",
    "\n",
    "This code snippet either loads previously computed Graph Matching Attack (GMA) results from disk or runs the attack if no saved data is found.\n",
    "\n",
    "1. **Generate Configuration Hashes:**  \n",
    "   The function `get_hashes` creates unique hash values based on the encoding and embedding configurations. These are used to create distinct filenames for the data.\n",
    "\n",
    "2. **Create File Paths:**  \n",
    "   Based on the configuration hashes, paths are generated for:\n",
    "   - Reidentified individuals\n",
    "   - Not reidentified individuals\n",
    "   - All individuals in Alice‚Äôs dataset (with encoding)\n",
    "\n",
    "3. **Load Results from Disk (if available):**  \n",
    "   If the `.h5` files already exist, they are loaded using `hickle` and converted into `pandas.DataFrames`.  \n",
    "   The data format assumes that the first row contains the column headers, and the rest is the data ‚Äî hence the slicing `[1:]` and `columns=...`.\n",
    "\n",
    "4. **Run GMA If Data Is Not Available:**  \n",
    "   If the files are missing, the GMA is executed via `run_gma()`. The results are again converted to `DataFrames`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously saved attack results...\n"
     ]
    }
   ],
   "source": [
    "# Get unique hash identifiers for the encoding and embedding configurations\n",
    "eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash = get_hashes(GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG)\n",
    "\n",
    "# Define file paths based on the configuration hashes\n",
    "path_reidentified = f\"./data/available_to_eve/reidentified_individuals_{eve_enc_hash}_{alice_enc_hash}_{eve_emb_hash}_{alice_emb_hash}.h5\"\n",
    "path_not_reidentified = f\"./data/available_to_eve/not_reidentified_individuals_{eve_enc_hash}_{alice_enc_hash}_{eve_emb_hash}_{alice_emb_hash}.h5\"\n",
    "path_all = f\"./data/dev/alice_data_complete_with_encoding_{eve_enc_hash}_{alice_enc_hash}_{eve_emb_hash}_{alice_emb_hash}.h5\"\n",
    "\n",
    "# Check if the output files already exist\n",
    "if os.path.isfile(path_reidentified) and os.path.isfile(path_not_reidentified) and os.path.isfile(path_all):\n",
    "    # Load previously saved attack results\n",
    "    print(\"Loading previously saved attack results...\")\n",
    "    reidentified_data = hkl.load(path_reidentified)\n",
    "    not_reidentified_data = hkl.load(path_not_reidentified)\n",
    "    all_data = hkl.load(path_all)\n",
    "\n",
    "else:\n",
    "    # Run Graph Matching Attack if files are not found\n",
    "    reidentified_data, not_reidentified_data, all_data = run_gma(\n",
    "        GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG, ALIGN_CONFIG, DEA_CONFIG,\n",
    "        eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash\n",
    "    )\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "df_reidentified = pd.DataFrame(reidentified_data[1:], columns=reidentified_data[0])\n",
    "df_not_reidentified = pd.DataFrame(not_reidentified_data[1:], columns=not_reidentified_data[0])\n",
    "df_all = pd.DataFrame(all_data[1:], columns=all_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî§ Create 2-Gram Dictionary (Letters & Digits)\n",
    "\n",
    "This code creates a comprehensive dictionary of all possible **2-grams** (two-character combinations) that consist of lowercase letters and digits.\n",
    "\n",
    "1. **Character Sets:**\n",
    "   - `string.ascii_lowercase`: the lowercase English alphabet ('a' to 'z')\n",
    "   - `string.digits`: the digits '0' to '9'\n",
    "\n",
    "2. **2-Gram Types Generated:**\n",
    "   - **Letter-Letter (LL):** All combinations like `'aa'`, `'ab'`, ..., `'zz'` (26√ó26 = 676)\n",
    "   - **Digit-Digit (DD):** All combinations like `'00'`, `'01'`, ..., `'99'` (10√ó10 = 100)\n",
    "   - **Letter-Digit (LD):** All combinations like `'a0'`, `'a1'`, ..., `'z9'` (26√ó10 = 260)\n",
    "\n",
    "3. **Combining All 2-Grams:**\n",
    "   - All three types are concatenated into a single list.\n",
    "\n",
    "4. **Indexed Dictionary:**\n",
    "   - The `enumerate()` function is used to assign each 2-gram a unique index in `two_gram_dict`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate a dictionary of all possible 2-grams from letters and digits ---\n",
    "\n",
    "# Lowercase alphabet: 'a' to 'z'\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "# Digits: '0' to '9'\n",
    "digits = string.digits\n",
    "\n",
    "# Generate all letter-letter 2-grams (e.g., 'aa', 'ab', ..., 'zz')\n",
    "letter_letter_grams = [a + b for a in alphabet for b in alphabet]\n",
    "\n",
    "# Generate all digit-digit 2-grams (e.g., '00', '01', ..., '99')\n",
    "digit_digit_grams = [d1 + d2 for d1 in digits for d2 in digits]\n",
    "\n",
    "# Generate all letter-digit 2-grams (e.g., 'a0', 'a1', ..., 'z9')\n",
    "letter_digit_grams = [l + d for l in alphabet for d in digits]\n",
    "\n",
    "# Combine all generated 2-grams into one list\n",
    "all_two_grams = letter_letter_grams + letter_digit_grams + digit_digit_grams\n",
    "\n",
    "# Create a dictionary mapping index to each 2-gram\n",
    "two_gram_dict = {i: two_gram for i, two_gram in enumerate(all_two_grams)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Dataset Creation Based on Alice‚Äôs Encoding Scheme\n",
    "\n",
    "This section initializes the dataset objects depending on which encoding method Alice used. Each encoding requires a different preprocessing strategy for compatibility with downstream neural models.\n",
    "\n",
    "### 1. Bloom Filter (`\"BloomFilter\"`)\n",
    "- Uses binary Bloom filters to represent identifiers.\n",
    "- Loads `BloomFilterDataset` objects.\n",
    "- Stores the bit-length of the bloom filter.\n",
    "\n",
    "### 2. Tabulation MinHash (`\"TabMinHash\"`)\n",
    "- Applies a MinHash-based encoding.\n",
    "- Loads `TabMinHashDataset`.\n",
    "- Captures the length of each encoded vector.\n",
    "\n",
    "### 3. Two-Step Hash with One-Hot Encoding (`\"TwoStepHash\"`)\n",
    "- Extracts all **unique hash values** to build a consistent one-hot vector space.\n",
    "- Constructs datasets using `TwoStepHashDatasetOneHotEncoding`.\n",
    "\n",
    "> ‚öôÔ∏è All dataset constructors are passed:\n",
    "> - Whether the data is labeled\n",
    "> - The full 2-gram list (used as feature tokens)\n",
    "> - Additional encoding-specific configurations\n",
    "> - Dev mode toggle (for debugging or smaller runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è Bloom Filter Encoding\n",
    "if ENC_CONFIG[\"AliceAlgo\"] == \"BloomFilter\":\n",
    "    data_labeled = BloomFilterDataset(\n",
    "        df_reidentified,\n",
    "        is_labeled=True,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    data_not_labeled = BloomFilterDataset(\n",
    "        df_not_reidentified,\n",
    "        is_labeled=False,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    bloomfilter_length = len(df_reidentified[\"bloomfilter\"][0])\n",
    "\n",
    "# 2Ô∏è Tabulation MinHash Encoding\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TabMinHash\":\n",
    "    data_labeled = TabMinHashDataset(\n",
    "        df_reidentified,\n",
    "        is_labeled=True,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    data_not_labeled = TabMinHashDataset(\n",
    "        df_not_reidentified,\n",
    "        is_labeled=False,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    tabminhash_length = len(df_reidentified[\"tabminhash\"][0])\n",
    "\n",
    "# 3 Two-Step Hash Encoding (One-Hot Encoding Mode)\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\":\n",
    "    # Collect all unique integers across both reidentified and non-reidentified data\n",
    "    unique_ints_reid = set().union(*df_reidentified[\"twostephash\"])\n",
    "    unique_ints_not_reid = set().union(*df_not_reidentified[\"twostephash\"])\n",
    "    unique_ints_sorted = sorted(unique_ints_reid.union(unique_ints_not_reid))\n",
    "    unique_integers_dict = {i: val for i, val in enumerate(unique_ints_sorted)}\n",
    "\n",
    "    data_labeled = TwoStepHashDataset(\n",
    "        df_reidentified,\n",
    "        is_labeled=True,\n",
    "        all_integers=unique_ints_sorted,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    data_not_labeled = TwoStepHashDataset(\n",
    "        df_not_reidentified,\n",
    "        is_labeled=False,\n",
    "        all_integers=unique_ints_sorted,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting & Loader Setup\n",
    "\n",
    "After preprocessing the encoded data, we divide it into training, validation, and test sets using PyTorch's `DataLoader` and `random_split`.\n",
    "\n",
    "### Dataset Proportions\n",
    "- The proportion for the training set is defined in `DEA_CONFIG[\"TrainSize\"]`.\n",
    "- The remainder is used for validation.\n",
    "\n",
    "### Splitting\n",
    "- `data_labeled` (the reidentified individuals) is split into:\n",
    "  - `data_train` for training\n",
    "  - `data_val` for validation\n",
    "- `data_not_labeled` (unidentified individuals) is used exclusively for testing.\n",
    "\n",
    "### Dataloader Configuration\n",
    "- **Training Loader**: shuffled for learning generalization.\n",
    "- **Validation Loader**: also shuffled to vary batches during evaluation.\n",
    "- **Test Loader**: also shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset split proportions\n",
    "train_size = int(DEA_CONFIG[\"TrainSize\"] * len(data_labeled))\n",
    "val_size = len(data_labeled) - train_size\n",
    "\n",
    "# Split the reidentified dataset into training and validation sets\n",
    "data_train, data_val = random_split(data_labeled, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training, validation, and testing\n",
    "dataloader_train = DataLoader(\n",
    "    data_train,\n",
    "    batch_size=DEA_CONFIG[\"BatchSize\"],\n",
    "    shuffle=True  # Important for training\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    data_val,\n",
    "    batch_size=DEA_CONFIG[\"BatchSize\"],\n",
    "    shuffle=True  # Allows variation in validation batches\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    data_not_labeled,\n",
    "    batch_size=DEA_CONFIG[\"BatchSize\"],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiation Based on Encoding Scheme\n",
    "\n",
    "The neural network model is selected dynamically based on the encoding technique used for Alice‚Äôs data.\n",
    "\n",
    "### Supported Models:\n",
    "\n",
    "- **BloomFilter** ‚Üí `BloomFilterToTwoGramClassifier`  \n",
    "  - Input: Binary vector (Bloom filter)  \n",
    "  - Output: 2-gram prediction\n",
    "\n",
    "- **TabMinHash** ‚Üí `TabMinHashToTwoGramClassifier`  \n",
    "  - Input: Tabulated MinHash signature  \n",
    "  - Output: 2-gram prediction\n",
    "\n",
    "- **TwoStepHash** ‚Üí `TwoStepHashToTwoGramClassifier`  \n",
    "  - Input: Length of the unique integers present\n",
    "  - Output: 2-gram predicition\n",
    "    \n",
    "Each model outputs predictions over the set of all possible 2-grams (`all_two_grams`), and the input dimension is dynamically configured based on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TestModel(\n",
    "    input_dim=bloomfilter_length,\n",
    "    output_dim=len(all_two_grams),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model based on selected encoding scheme\n",
    "if ENC_CONFIG[\"AliceAlgo\"] == \"BloomFilter\":\n",
    "    model = BloomFilterToTwoGramClassifier(\n",
    "        input_dim=bloomfilter_length,\n",
    "        output_dim=len(all_two_grams)\n",
    "    )\n",
    "\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TabMinHash\":\n",
    "    model = TabMinHashToTwoGramClassifier(\n",
    "        input_dim=tabminhash_length,\n",
    "        output_dim=len(all_two_grams)\n",
    "    )\n",
    "\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\":\n",
    "    model = TwoStepHashToTwoGramClassifier(\n",
    "        input_dim=len(unique_ints_sorted),\n",
    "        output_dim=len(all_two_grams)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Environment Setup\n",
    "This code initializes the core components needed for training a neural network model.\n",
    "\n",
    "1. TensorBoard Setup\n",
    "    - Creates unique run name by combining:\n",
    "    - Loss function type\n",
    "    - Optimizer choice\n",
    "    - Alice's algorithm\n",
    "    - Initializes TensorBoard writer in runs directory\n",
    "2. Device Configuration\n",
    "    - Automatically selects GPU if available, falls back to CPU\n",
    "    - Moves model to selected device\n",
    "3. Loss Functions\n",
    "    - `BCEWithLogitsLoss`: Binary Cross Entropy with Logits\n",
    "    - `MultiLabelSoftMarginLoss`: Multi-Label Soft Margin Loss\n",
    "4. Optimizers:\n",
    "    - `Adam`: Adaptive Moment Estimation\n",
    "    - `AdamW`: Adam with Weight Decay\n",
    "    - `SGD`: Stochastic Gradient Descent (with momentum)\n",
    "    - `RMSprop`: Root Mean Square Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tensorboard logging\n",
    "run_name = \"\".join([\n",
    "    DEA_CONFIG[\"LossFunction:\"],\n",
    "    DEA_CONFIG[\"Optimizer\"],\n",
    "    ENC_CONFIG[\"AliceAlgo\"],\n",
    "])\n",
    "tb_writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "# Setup compute device (GPU/CPU)\n",
    "compute_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(compute_device)\n",
    "\n",
    "# Initialize loss function\n",
    "match DEA_CONFIG[\"LossFunction:\"]:\n",
    "    case \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    case \"MultiLabelSoftMarginLoss\":\n",
    "        criterion = nn.MultiLabelSoftMarginLoss(reduction='mean')\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported loss function: {DEA_CONFIG['LossFunction:']}\")\n",
    "\n",
    "# Initialize optimizer\n",
    "match DEA_CONFIG[\"Optimizer\"]:\n",
    "    case \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=DEA_CONFIG[\"LearningRate\"])\n",
    "    case \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=DEA_CONFIG[\"LearningRate\"])\n",
    "    case \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                            lr=DEA_CONFIG[\"LearningRate\"],\n",
    "                            momentum=DEA_CONFIG[\"Momentum\"])\n",
    "    case \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=DEA_CONFIG[\"LearningRate\"])\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported optimizer: {DEA_CONFIG['Optimizer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Early Stopping\n",
    "\n",
    "The function `train_model` orchestrates the training process for the neural network, including both training and validation phases for each epoch. It also utilizes **early stopping** to halt training when the validation loss fails to improve over multiple epochs, avoiding overfitting.\n",
    "\n",
    "### Key Phases:\n",
    "1. **Training Phase**: \n",
    "   - The model is trained on the `dataloader_train`, computing the training loss using the specified loss function (`criterion`) and optimizer. Gradients are calculated, and the model parameters are updated.\n",
    "  \n",
    "2. **Validation Phase**:\n",
    "   - The model is evaluated on the `dataloader_val` without updating weights. The validation loss is computed to track model performance on unseen data.\n",
    "\n",
    "3. **Logging**: \n",
    "   - Training and validation losses are logged to both the console and **TensorBoard** for tracking model performance during training.\n",
    "\n",
    "4. **Early Stopping**: \n",
    "   - If the validation loss does not improve after a certain number of epochs (defined by `DEA_CONFIG[\"Patience\"]`), the training process is halted to prevent overfitting.\n",
    "\n",
    "### Helper Functions:\n",
    "- `run_epoch`: Handles a single epoch, either for training or validation, depending on the flag `is_training`.\n",
    "- `log_metrics`: Logs the training and validation losses to the console and TensorBoard for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf5e5a06abe4aa6beecebdf8d699653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0926e441189c4267bfca61c59955bb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train loss: 0.1599, Validation loss: 0.0688\n",
      "best_loss updated from  inf  to  0.06879393607378007\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff20ece621b449fb9ef8e234e84cd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b6c2be31544a72a9f5d0f1c1404e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Train loss: 0.0668, Validation loss: 0.0656\n",
      "best_loss updated from  0.06879393607378007  to  0.06561637371778488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "007146d144e94531b58a01266a3a1d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d66b59d1a34889839ec904fee4cec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Train loss: 0.0653, Validation loss: 0.0648\n",
      "Early stopper counter incremented from  0  to  1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79c67a385814d649f5ec354be945690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2c4efca4f54e019ee081591a413dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Train loss: 0.0637, Validation loss: 0.0638\n",
      "best_loss updated from  0.06561637371778488  to  0.06382018886506557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd485c96e8de4ab2a76a4c215e9de9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845e6801358448398b86d52b044ef663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Train loss: 0.0614, Validation loss: 0.0613\n",
      "best_loss updated from  0.06382018886506557  to  0.06130826994776726\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee784e7ec454e7ca59ba0cc29b37f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c775555930704a41bbf47caaf6441e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Train loss: 0.0571, Validation loss: 0.0578\n",
      "best_loss updated from  0.06130826994776726  to  0.05778540074825287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff92a9d59a64311860e3ca33086bcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ca27061ab748ce8a22ed57a0ec961d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Train loss: 0.0522, Validation loss: 0.0542\n",
      "best_loss updated from  0.05778540074825287  to  0.05419020429253578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516433d8dd1f4879b09613d07ab55a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ebaefafe4a444c9f89277d5f491d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Train loss: 0.0471, Validation loss: 0.0512\n",
      "best_loss updated from  0.05419020429253578  to  0.0512198630720377\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de438f01b0224579a7ca77e37d08eef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c2a33950c646bfbc86f946684fb02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Train loss: 0.0422, Validation loss: 0.0482\n",
      "best_loss updated from  0.0512198630720377  to  0.04819736927747727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc85cb12bd94d69a74c1d092cc40ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b915f30fa242b4b368b3f891b30ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Train loss: 0.0375, Validation loss: 0.0460\n",
      "best_loss updated from  0.04819736927747727  to  0.046047579124569894\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5ddf5e2a3b4b3b98a3cb314db158fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1099ce1907d4376aa0a9ffc676f1f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Train loss: 0.0331, Validation loss: 0.0441\n",
      "best_loss updated from  0.046047579124569894  to  0.04409019909799099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7b86b1957d4fe5a44dcafc00b0d68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df93eba704f34b8c8bbec22d55b844b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Train loss: 0.0292, Validation loss: 0.0432\n",
      "Early stopper counter incremented from  0  to  1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03470125dd21411aacbe46c055daac0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30105fed61bb4d96b4c71719b4c5e288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Train loss: 0.0259, Validation loss: 0.0431\n",
      "best_loss updated from  0.04409019909799099  to  0.04308016933500767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea85b5750599498abc60f4f25f85d0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34480420bb74ff68bb8bcb06f6816ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Train loss: 0.0230, Validation loss: 0.0420\n",
      "best_loss updated from  0.04308016933500767  to  0.04199034720659256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef51f875ed9421b93e844864259b2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e106696cfff540a69f3f976454c95bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Train loss: 0.0203, Validation loss: 0.0416\n",
      "Early stopper counter incremented from  0  to  1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c486a55be746e4b18dddecc414acf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408ac5bd218247b8b6047cda1b9add0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Train loss: 0.0183, Validation loss: 0.0412\n",
      "Early stopper counter incremented from  1  to  2 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af8b5de33e84044a89eb96d7f0f5e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b766d95aaa3e4257b7f801fed7f0be15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Train loss: 0.0163, Validation loss: 0.0412\n",
      "Early stopper counter incremented from  2  to  3 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d881fd3479a4cea8c38f63851f3fff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ed5b7b4d36475e98a1e88213837f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Train loss: 0.0145, Validation loss: 0.0409\n",
      "best_loss updated from  0.04199034720659256  to  0.0409008052200079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6bb12cd04749e7a11b3c0ed4e06fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3b96448f46400698dd9b283fc2b8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Train loss: 0.0133, Validation loss: 0.0401\n",
      "Early stopper counter incremented from  0  to  1 / 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c499ec214b4838b6ba75e25b96a92f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d396d8ca03344edbd25cae42f661187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Train loss: 0.0123, Validation loss: 0.0414\n",
      "Early stopper counter incremented from  1  to  2 / 5\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, device):\n",
    "    train_losses, val_losses = [], []\n",
    "    early_stopper = EarlyStopping(patience=DEA_CONFIG[\"Patience\"], min_delta=DEA_CONFIG[\"MinDelta\"])\n",
    "\n",
    "    for epoch in range(DEA_CONFIG[\"Epochs\"]):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = run_epoch(\n",
    "            model, dataloader_train, criterion, optimizer,\n",
    "            device, is_training=True\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = run_epoch(\n",
    "            model, dataloader_val, criterion, optimizer,\n",
    "            device, is_training=False\n",
    "        )\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Logging\n",
    "        log_metrics(train_loss, val_loss, epoch, DEA_CONFIG[\"Epochs\"])\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stopper(val_loss):\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def run_epoch(model, dataloader, criterion, optimizer, device, is_training):\n",
    "    running_loss = 0.0\n",
    "    with torch.set_grad_enabled(is_training):\n",
    "        for data, labels, _ in tqdm(dataloader,\n",
    "                                  desc=\"Training\" if is_training else \"Validation\"):\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "            if is_training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "def log_metrics(train_loss, val_loss, epoch, total_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{total_epochs} - \"\n",
    "          f\"Train loss: {train_loss:.4f}, \"\n",
    "          f\"Validation loss: {val_loss:.4f}\")\n",
    "    tb_writer.add_scalar(\"Loss/train\", train_loss, epoch + 1)\n",
    "    tb_writer.add_scalar(\"Loss/validation\", val_loss, epoch + 1)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model, dataloader_train, dataloader_val,\n",
    "    criterion, optimizer, compute_device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Visualization over Epochs\n",
    "\n",
    "This code snippet generates a plot to visualize the **training loss** and **validation loss** across epochs. It's useful for tracking model performance during training and evaluating if overfitting is occurring (i.e., when validation loss starts increasing while training loss continues to decrease).\n",
    "\n",
    "### Key Elements:\n",
    "1. **Plotting the Losses**: \n",
    "   - The `train_losses` and `val_losses` are plotted over the epochs. \n",
    "   - The **blue line** represents the training loss, and the **red line** represents the validation loss.\n",
    "\n",
    "2. **Legend**: \n",
    "   - A legend is added to distinguish between training and validation losses.\n",
    "\n",
    "3. **Title and Labels**: \n",
    "   - The plot is titled \"Training and Validation Loss over Epochs\" for context.\n",
    "   - **X-axis** represents the epoch number, and **Y-axis** represents the loss value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAZAlJREFUeJzt3QmczPX/B/D33u6bZd1n7nWfOUKIQpHjJ6SihIj6RYXUv8hdyNEvdIlUjhAhIsePHLmFhNznLotddr//x+vz/X1nZ3Znd2d3ZvY7x+v5eHzZ+c53Zr4z3+/MvOZzBmiapgkRERGRHwk0eweIiIiIMhsDEBEREfkdBiAiIiLyOwxARERE5HcYgIiIiMjvMAARERGR32EAIiIiIr/DAERERER+hwGIiIiI/A4DEHmtZ599VkqVKpWh277zzjsSEBAgvuzvv/9Wz3HBggWZ/th4XLzGBuwD1mGf0oJjimPrKecKUXrgPHv88cfN3g1yAAMQuRy+6BxZNm3aZPau+r1XXnlFHYsTJ06kuM1bb72lttm/f794svPnz6vQtW/fPvG0EDpp0iSzd8WnAkZKnylt27Y1e/fIiwSbvQPke7788kuby1988YWsW7cu2fpKlSo59TiffvqpJCQkZOi2b7/9towYMUL8Xc+ePWX69OmycOFCGT16tN1tvvnmG6lWrZpUr149w4/Tq1cv6d69u4SFhYk7A9DYsWPVF2SNGjVcdq6Q58HxHT58eLL1ERERpuwPeScGIHK5Z555xubyjh07VABKuj6pO3fuSLZs2Rx+nJCQkAzvY3BwsFr8Xf369aVcuXIq5NgLQNu3b5dTp07J+PHjnXqcoKAgtZjFmXOFMteDBw9UWA0NDU1xm6JFi6b5eUKUFlaBkSmaN28uVatWld27d0vTpk1V8HnzzTfVdcuXL5f27durX3MoMShbtqy89957Eh8fn2q7Duvqhrlz56rb4fZ169aVXbt2pdkGCJcHDRoky5YtU/uG21apUkXWrFmTbP9RfVenTh3JkiWLepw5c+Y43K5oy5Yt8vTTT0uJEiXUYxQvXlxeffVVuXv3brLnlyNHDjl37px06tRJ/V2wYEF57bXXkr0WN2/eVNvnzp1b8uTJI3369FHrHC0FOnr0qOzZsyfZdSgZwnPq0aOHxMXFqZBUu3Zt9TjZs2eXJk2ayMaNG9N8DHttgDRNk//7v/+TYsWKqeP/yCOPyKFDh5Ld9vr16+o5oxQKr0GuXLnksccekz/++MPmeOA4Q9++fS1VIkb7J3ttgGJiYlQpAl5/HIeHHnpInTvYr4yeFxl1+fJlef755yU8PFydU5GRkfL5558n227RokXq9c+ZM6d6HfCafPTRR5br79+/r0rBypcvr+4nf/788vDDD6sfIGn566+/1HmZL18+dTwaNGggq1atslx/6dIl9aMB95/UsWPH1Os0Y8YMyzqcf0OHDrW8vgjaH374oU1JnPV7dtq0aZb37OHDh8VZxvsHz6tNmzbqfMVnyrvvvpvsGDt6LsBXX30l9erVU69R3rx51efXzz//nGy73377TW2H41CmTBlVEm7NmWNFrsGfwGSaa9euqS8yVI3g1xw+/AFfWvjgGjZsmPr/l19+UV+80dHRMnHixDTvF1/at27dkhdffFF9uE6YMEGeeuop9UGYVkkAPrR++OEHefnll9WXzMcffyydO3eWM2fOqA8o2Lt3r2prUKRIEfUBhjCCD1WEE0csWbJElXYNGDBA3efOnTtVNdQ///yjrrOG+8aHN0pq8IG8fv16mTx5svqiwO0BH9IdO3ZU+/7SSy+pqsWlS5eqEORoAMLzwOtWq1Ytm8f+9ttvVchBWLt69ar85z//UWGoX79+6jX+7LPP1P7hOSStdkoLjikCULt27dSCANa6dWsVtKzhuCF84Mu5dOnS6osYgbNZs2bqixJfanjOOAa4z/79+6t9hkaNGtl9bLxmHTp0UOENwQP7vnbtWnn99ddV4Jw6dWq6z4uMQvDFDwK0w0LQwnPEeYAvcISIIUOGqO3wxYjXvmXLlipIwJEjR2Tr1q2WbRDCx40bJy+88IL68sV75vfff1ev7aOPPpriPuA1xWuF8xLtwvCcEMDwGn333Xfy5JNPqvcnXnOcE2PGjLG5/eLFi1UJH44R4H6wLV5LvA9x/mzbtk1GjhwpFy5cUGHH2vz58+XevXvq2CGAIISlBuEB52NSCDlZs2a1OYfxXkWYw+cAQiv2HaVMOF/Sey7gfYLXGK8Vbo9Sqv/+97/qMwrnrgHHskuXLur+8D6cN2+eOp4IrwjPzhwrciGNyM0GDhyIn1E265o1a6bWzZ49O9n2d+7cSbbuxRdf1LJly6bdu3fPsq5Pnz5ayZIlLZdPnTql7jN//vza9evXLeuXL1+u1v/444+WdWPGjEm2T7gcGhqqnThxwrLujz/+UOunT59uWffEE0+ofTl37pxl3fHjx7Xg4OBk92mPvec3btw4LSAgQDt9+rTN88P9vfvuuzbb1qxZU6tdu7bl8rJly9R2EyZMsKx78OCB1qRJE7V+/vz5ae5T3bp1tWLFimnx8fGWdWvWrFG3nzNnjuU+Y2NjbW5348YNLTw8XHvuueds1uN2eI0N2AeswzGCy5cvq9e6ffv2WkJCgmW7N998U22H527AMbfeL8D9hIWF2bw2u3btSvH5Jj1XjNfs//7v/2y269KlizoO1ueAo+eFPcY5OXHixBS3mTZtmtrmq6++sqyLi4vTGjZsqOXIkUOLjo5W64YMGaLlypVLHYeUREZGqtc0vYYOHar2YcuWLZZ1t27d0kqXLq2VKlXK8vrjXMB2Bw4csLl95cqVtRYtWlguv/fee1r27Nm1P//802a7ESNGaEFBQdqZM2dsXh88L5wTjsBxxG3sLXgfJX3/DB482LIO5xpeHxzPK1eupOtcwHs8MDBQe/LJJ5Odj9bnsLF/mzdvtqzDc8P5Onz4cKePFbkOq8DINPilh+qKpKx/waGUAb/08IsevypRVZOWbt26qaJpg1EagJKEtLRq1UqVrhjQ8BdVDcZt8YsSpTCokrJucInifZRmOcL6+aHoHc8PvyjxXYvSpaRQqmMNz8f6uaxevVpVTRglQoBf44MHDxZHoQQOJVCbN2+2rEOJEH7hGr/qcZ9GuwxUY6BqCr+kURVor/osNXgNUdKDfbSuNkSVib3zJDAw0PL6o+QQJYOopkjv41q/Zng+KO2whmoQHIeffvopXeeFM7AvhQsXVqU7BpRUYt9u374tv/76q1qHqk2cL6lVkWAbVCMeP3483fuAUghUwRjwGqNEBtVURpUUSlJxrqHEx3Dw4EF1Pd53BpRg4TzF+xDnt7HgdcQxtD7PAKVpjpagAkpE8TokXaxfQwNK1ZJWZ+LcwzmYnnMBpZA471HKaJyP1vdrrXLlypbPHcBzw/lqfb5k9FiR6zAAkWnQkNFeQ0d8KKDIHe1M8CWDDw+jwWNUVFSa94vidmtGGLpx40a6b2vc3rgt2mqgygKBJyl76+xBtQmKw1HMb7TrQXWBveeHtgFJvxis9wdOnz6tquNwX9bwgesoVEPiSwChB1AdgWo0hDrrMIlqEXz5G20WsG9oJ+LIcbGGfQa0f7CG+7N+PMCXDqohsC3CUIECBdR26Jaf3se1fnwEWFRn2euZaOyfo+eFM/BYeG5Jv1ST7guq3ypUqKCOCdpNPffcc8naIaFaBtVm2A7tg1CN48jwBXgMe+dL0n3Aa48qOFSDGRCGEIoQjgz4Use+4ThZLwhAxvvIGqr90gP7gftKupQsWdJmO7ymaH9jDa8NGO3RHD0XTp48qe4P4SYtjpwvGT1W5DoMQGQa65IQAz4QEAbQwBUfED/++KP6ZWe0eXCkK3NKvY3sNWh05W0dgV+/qN9HaHjjjTfUr0o8P6OxbtLnl1k9pwoVKqT26/vvv1ftK/C6o/QN7YOsG38iuKEkBG1/8AWHfW/RooVbu5h/8MEHqj0YGptiH9A+A4+LthSZ1bXd3eeFo8cIYxytWLHC0mYFYci6rRdeI3xRo80JGmyjzRbadeF/V0FY/vPPPy3jLSEMIRQhlBhwXHA+2SulwYISn7Q+C7yZI+dLZhwrSh0bQZNHQW8eVHGgwSk+IAzoiu0J8CWE0g97AwemNpig4cCBA+rLAyUpvXv3tqx3pucHfvVu2LBBVZdYlwKhZ056IOwg1KDIHyVBKH174oknLNejMSx+TePYWBf5J20Q6+g+GyUF1r/Qr1y5kqxUBY+LHmIIXUnDsvWXbnpG9sbjowoEIc/6l79RxZq0JMGd8Fj45Y/QYF0KZG9fUGKKY4IF26NUCA3CR40aZSmBRMkiqpax4JzA+wgNbtHYNrV9sHe+2NsHVP+iYbNRDYbzGY2brSEk47GNEh+z4DVCtZNR6mPsLxi9Ah09F/CccH+o7ktvg/+UZORYkeuwBIg88peT9S8l1Nd/8skn4in7hw91lNxg4D3r8JO03UhKt0/6/PC3dVfm9EIPKrTFmTVrlk1JE3qWpQe+2NC1F681nguqNBD2Utt39IDBWEHphdcQ7Vywj9b3l7R3kPG4SUta0MYEPXSS9gACR7r/4zXDa2TdbRtQ1YYg5Wh7LlfAvly8eNGmXQ2OJ14bBFqjehQ/DKwhLBmDU8bGxtrdBrdHMDKuT20f0JPP+liivRGGk0BQsK72QdsV9PxDyQ+65SOU4dyx1rVrV3VfKK1LCscHzy+zWB9jnEe4jHMPpVbpORfwHPGao2Q6acljRkoCM3qsyHVYAkQeBY2BUVeOYn1jmgaMIJ2ZVQ1pwS80jPvRuHFj1fDY+PBEMXZa0zBUrFhR/ZLEuDb4AkcpC6qdnGlLgtIA7AtGtka7BnxZoZQmve1j8AGMD3mjHZB19RdgfiPcL9pnYZwmlMrNnj1bPR5+vaaHMZ4RugHjfvElhAbgCF7WpTrG4+JLB7+ScX6gFO3rr79O1rYDryu+nLFP+CWPQITGsvbal+A1Q6kSpvnAa4Zxd3BMMQYVGmJbN3h2BZTQoV1VUni90dAYpTioXsS4WAgcKPVC93YEQqNUAqUCaHiOKke0AULbFIQklEYY7VVwLNClHt2tUbqAbtW4L+uGwPbg3MFgmPiyx/sOt0UpJY4xzs+k7ZPQ4Bnt8hCWEYbwultDexZU1eHYGd2/Eahw7LA/eM2THuf0wHsH1aEpncMGBHiUauLzBOcCzi9UP2PMMaNtnaPnAsIJtsGYZGjgjB8IaJOGMcbQhgjncnpk9FiRC7mwRxlRurrBV6lSxe72W7du1Ro0aKBlzZpVi4iI0P79739ra9euVfexcePGNLvB2+tynLRbdkrd4LGvSeExrLtlw4YNG1R3dHSnLVu2rPaf//xHdXHNkiVLmq/H4cOHtVatWqkuzgUKFND69etn6VZt3YUbj4muxEnZ2/dr165pvXr1Ut2Jc+fOrf7eu3evw93gDatWrVK3KVKkiN2uvh988IF6PdClF89/5cqVyY6DI93gAfc/duxY9Vg41s2bN9cOHjyY7PVGN3i8tsZ2jRs31rZv367OISzWMOQBumQbQxIYz93ePqKb96uvvqrOsZCQEK18+fLq3LHu0pze8yIp45xMafnyyy/VdpcuXdL69u2rzgecU9WqVUt23L777jutdevWWqFChdQ2JUqUUMNDXLhwwbINunLXq1dPy5Mnj3qtKlasqL3//vuqW31aTp48qbp+47Y4j3E/OL72oGs+7j9p9/2kr+/IkSO1cuXKqf3Fc2vUqJE2adIky/44MkxAerrBWx9j4/2D54XXDUNXYMgGnJdJz21HzwWYN2+eOvfxHsibN686B9etW2ezf/a6tyc9X505VuQaAfjHlYGKyF/hlye7tRJ5BpQ8oUQlvaWT5D/YBogoA5JOW4HQg/FEUKRNRESej22AiDIA7U/wCxP/oy0GGiCjMei///1vs3eNiIgcwABElAGYXwiNRtF7Bw0hGzZsqMarSTqwHxEReSa2ASIiIiK/wzZARERE5HcYgIiIiMjvsA2QHRjlE6P8YgCy9AyvT0REROZBqx5Ma4LBKZMO4JkUA5AdCD/Fixc3ezeIiIgoA86ePatGTE8NA5AdxtDzeAExVQERERF5vujoaFWAYT2xbUoYgOwwqr0QfhiAiIiIvIsjzVfYCJqIiIj8DgMQERER+R0GICIiIvI7bANERERuFx8fL/fv3zd7N8jLhYSESFBQkEvuiwGIiIjcOi4L5sy7efOm2btCPiJPnjxSuHBhp8fpYwAiIiK3McJPoUKFJFu2bBxclpwK03fu3JHLly+ry0WKFMn4nTEAERGRO6u9jPCTP39+s3eHfEDWrFnV/whBOK+cqQ5jI2giInILo80PSn6IXMU4n5xtU8YAREREbsVqL/LE88n0ADRz5kwpVaqUZMmSRerXry87d+5McdtDhw5J586d1fZ4AaZNm2Z3u3PnzskzzzyjilxRXFatWjX5/fff3fgsiIiIyJuYGoAWL14sw4YNkzFjxsiePXskMjJS2rRpY2nglBQaP5UpU0bGjx+vWoDbc+PGDWncuLHqKvfTTz/J4cOHZfLkyZI3b143PxsiIqKU4cd7Sj/c7dm0aZP6se/uHnQLFixQPav8jamNoKdMmSL9+vWTvn37qsuzZ8+WVatWybx582TEiBHJtq9bt65awN718OGHH6qJ0ObPn29ZV7p0abc9ByIi8q8qFvxof+edd9J9v7t27ZLs2bM7vH2jRo3kwoULkjt37nQ/FnlwCVBcXJzs3r1bWrVqlbgzgYHq8vbt2zN8vytWrJA6derI008/rVqI16xZUz799FPxBPHxIv/8I/L332bvCRERpQShw1hQYoNJsa3XvfbaazZdsx88eODQ/RYsWDBdDcJDQ0NdMt4NeVgAunr1quoiGR4ebrMelzFuREb99ddfMmvWLClfvrysXbtWBgwYIK+88op8/vnnKd4mNjZWoqOjbRZ3+M9/RIoXFxk82C13T0RELoDQYSwofUEAMS4fPXpUcubMqZpY1K5dW8LCwuS3336TkydPSseOHdV3WI4cOVRtxfr161OtAsP9/uc//5Enn3xSBSN8b+FHfEpVYEZVFb7bKlWqpB6nbdu2KpQZEMbwnYft0A72jTfekD59+kinTp3S9RrMmjVLypYtq0LYQw89JF9++aVN6EMJWIkSJdTzj4iIUI9p+OSTT9RzQdtevB5dunQRT2R6I2hXS0hIkFq1askHH3ygSn/69++vqtlQvZaScePGqZPcWFCF5g7G3aIUiIjIH2maSEyMOQse21XQDAPtUY8cOSLVq1eX27dvS7t27WTDhg2yd+9eFUyeeOIJOXPmTKr3M3bsWOnatavs379f3b5nz55y/fr1FLdHW9hJkyapQLJ582Z1/9YlUmgG8vXXX6tmIFu3blU/6JctW5au57Z06VIZMmSIDB8+XA4ePCgvvviiaqqyceNGdf33338vU6dOlTlz5sjx48fV/aOzEaDDEcLQu+++K8eOHZM1a9ZI06ZNxSNpJomNjdWCgoK0pUuX2qzv3bu31qFDhzRvX7JkSW3q1KnJ1pcoUUJ7/vnnbdZ98sknWkRERIr3de/ePS0qKsqynD17Fm8T9bcr7d+Pt5+m5c/v0rslIvJId+/e1Q4fPqz+N9y+rX8OmrHgsdNr/vz5Wu7cuS2XN27cqL4fli1bluZtq1Spok2fPj3F7y3cz9tvv2312txW63766Sebx7px44ZlX3D5xIkTltvMnDlTCw8Pt1zG3xMnTrRcfvDggfpe7Nixo8PPsVGjRlq/fv1stnn66ae1du3aqb8nT56sVahQQYuLi0t2X99//72WK1cuLTo6WsvM88qA721Hv79NKwFCsRqKD5GWrUtvcLlhw4YZvl/0AEPqtPbnn39KyZIlU7wNivBQx2u9uEOxYvr/164hxbvlIYiIKBOgrak1lAChJAZVU6h+QvUUSofSKgFC6ZEBDaTx/ZNST2hAVRmqpgyYDsLYPioqSi5duiT16tWzXI+RkvFdmx5HjhxR36XWcBnrAW1s7969q3plo4YFJUZGO6hHH31Ufd/iul69eqnSKJRaeSJTq8DQBR4NlNE+By8s2uvExMRYeoX17t1bRo4cadNwet++fWrB3xjvB3+fOHHCss2rr74qO3bsUFVgWL9w4UKZO3euDBw4UMyGXoZGB4Bz58zeGyKizIc2wLdvm7O4ckDqpL25EH4QBPDds2XLFvXdhGohfFelBkO2WEObHxQGpGd7vTAp8xQvXlwVNKCtD8bae/nll1U1F0ZmRvsoDGvzzTffqHA2evRoNcSNJ06Ga2oA6tatm6rLxAtUo0YNdcKgvtBoGI3kbN246/z586pdDxasx23x9wsvvGDZBg3PcBLixa9ataq89957qtEZ6lXNhob8Rjugs2fN3hsiInM+B5EdzFjc2ZkK7W2effZZ1aAZwQcNpv/O5C6/aMOK7090tzegsxECSXpUqlRJPR9ruFy5cmXLZQQftHH6+OOPVWNt9N4+cOCAui44OFj16J4wYYJq24TX4ZdffhFPY/pkqIMGDVKLPXhRk7agdyTpPv7442rxRKgGO3qUAYiIyJeg19MPP/ygQgFKZUaNGpVqSY67DB48WHXsKVeunFSsWFGmT5+uBghOT1f6119/XTXMRgEDgsyPP/6onpvRqw290RCsMHsDquS++uorFYhQ9bVy5UrVGxslQhiAePXq1ep1QE8yT2N6API37AlGROR7MLDvc889pwYvLFCggOp+7q4hVVKDx8VQMmhCgvY/6AmNGRbSM2t6p06d5KOPPlK1LOgNhsGE0ausefPm6nq0cUIPODRjQRBCiRdCErrd4zqEJXSTv3fvngqGqJGpUqWKeJoAtIQ2eyc8DU5aFCWiQZmrG0SPGSPy7rsiL76Ika9detdERB4FX4CnTp1SX6AYE4YyH0pfUKWFEh00CfH18yo6Hd/fLAHKZEZPMFaBERGRq50+fVp+/vlnadasmRrkd8aMGSos/Otf/zJ71zyOzw2E6OlYBUZERO6CKaXQRgcdgtB1HQ2T0XYHpUBkiyVAmYy9wIiIyJ1d1JP24CL7WAJkUhXYjRv60OxERESU+RiAMlnu3CI5c+p/sxqMiIjIHAxAJmA1GBERkbkYgEzAnmBERETmYgAyAXuCERERmYsByASsAiMiIjIXA5AJWAVGROT7MHXE0KFDbeazxOTcqcGcXcuWLXP6sV11P6nBdBeYyNxbMQCZgFVgRESeCxOatm3b1u51W7ZsUeECs5ynF2Zpx9xcmRFCLly4II899phLH8vXMACZgFVgRESe6/nnn5d169bJP3Z+pWJS0Dp16kj16tXTfb8FCxZUs6dnhsKFC0tYWFimPJa3YgAysQosKkrk1i2z94aIiKw9/vjjKqxgSglrt2/fliVLlqiAdO3aNenRo4cULVpUhRrMiI5Zz1OTtArs+PHj0rRpUzWhZ+XKlVXosje7e4UKFdRjlClTRkaNGiX3799X12H/xo4dK3/88YcqlcJi7HPSKjBMidGiRQvJmjWrmrW9f//+6vkYnn32WTULPGaAL1KkiNpm4MCBlsdydOLVd999V4oVK6bCF0qm1qxZY7k+Li5OBg0apO4fz7lkyZIybtw4dR3mZUdpVokSJdRtIyIi5JVXXhF34lQYJsBAiBgQEQEIPzA4RQsR+Q1NE7lzx5zHRulLQECamwUHB0vv3r1VmHjrrbdUmACEn/j4eBV8EB5q166tAgpmHV+1apX06tVLypYtK/Xq1XMoLDz11FMSHh4u//3vf9Xs5dbthQw5c+ZU+4FAgBDTr18/te7f//63dOvWTQ4ePKhCBub7AsyEnlRMTIy0adNGGjZsqKrhLl++LC+88IIKI9Yhb+PGjSqc4P8TJ06o+0eIwWM64qOPPpLJkyfLnDlzpGbNmjJv3jzp0KGDHDp0SMqXLy8ff/yxrFixQr799lsVdM6ePasW+P7772Xq1KmyaNEiqVKlily8eFEFO7fSKJmoqCgNLw3+d5eqVfEpoGlr17rtIYiITHX37l3t8OHD6n+L27f1Dz8zFjy2g44cOaK+BzZu3GhZ16RJE+2ZZ55J8Tbt27fXhg8fbrncrFkzbciQIZbLJUuW1KZOnar+Xrt2rRYcHKydO3fOcv1PP/2kHnPp0qUpPsbEiRO12rVrWy6PGTNGi4yMTLad9f3MnTtXy5s3r3bb6vmvWrVKCwwM1C5evKgu9+nTR+3fgwcPLNs8/fTTWrdu3VLcl6SPHRERob3//vs229StW1d7+eWX1d+DBw/WWrRooSUkJCS7r8mTJ2sVKlTQ4uLitAydVxn4/mYVmEnYE4yIyHNVrFhRGjVqpEoxACUiaACN6i9ASdB7772nqr7y5csnOXLkkLVr18qZM2ccuv8jR46oiUtRsmNACU1SixcvVrO6o00PHuPtt992+DGsHysyMlKyZ89uWde4cWNVCnXs2DHLOpS8BAUFWS6jNAilRY6Ijo6W8+fPq/u1hst4fKOabd++ffLQQw+p6q2ff/7Zst3TTz8td+/eVdV8KHFaunSpPHjwQNyJAcgk7AlGRH4J1VBoe2LGks4GyAg7qJq5deuWavyM6q1mzZqp6yZOnKiqfFAFhiojfLGjmgntXFxl+/bt0rNnT2nXrp2sXLlS9u7dq6rkXPkY1kJCQmwuo+oPIclVatWqJadOnVLBEWGna9eu0qVLF3UdwiDC2CeffKLaKb388suqfVR62iClF9sAmYQ9wYjIL6E9jVVJhCfDF/SQIUNk4cKF8sUXX8iAAQMs7YG2bt0qHTt2lGeeeUZdRlD4888/VWNmR1SqVEm1f0F3dZS0wI4dO2y22bZtm2oojNBjOH36tM02oaGhqjQqrcdCWx+0BTJKgbZu3SqBgYGqNMYV0A4KpVm4XyMkGo9j3SYK26FtERaEHww3cP36dVWKhuCDIQiwoAE2SuHQ7gnByR0YgEzCKjAiIs+GKid8UY8cOVJV8aAKx4BGvd99950KKXnz5pUpU6bIpUuXHA5ArVq1Ur27+vTpo0qTcP/WQcd4DFR3oWFw3bp1VUNrVA0l7VmGUhWUQKH3FRpIJ+3+jlKkMWPGqMdCT6srV67I4MGDVaNtNMJ2lddff109DkrK0HgapWbYr6+//lpdj9cIYQ8NpBG+0KgcVXt58uRRAQ1Brn79+qrH21dffaUCEQKgu7AKzCSsAiMi8nyoBrtx44aq3rJur4O2OCiZwHqM+IwvcnQjdxQCAMIMqoJQQoJeWe+//77NNuhB9eqrr6reWggUCFvoBm+tc+fOqhTlkUceUV337XXFR6BA+ySUtCBIoeSlZcuWMmPGDHEltOsZNmyYDB8+XLWNQu809PpCkAOEswkTJqhxlLAff//9t6xevVq9FghBn376qWozhDGW0Kvtxx9/VN3x3SUALaHddu9eCkkcXQnRLRHFde6AdmcVK+pd4qOj3fIQRESmunfvniqdKF26tBr3hcjd51V6vr9ZAmRyFRgGQsR4QERERJR5GIBMgnZoefPqf7MajIiIKHMxAJmIPcGIiIjMwQBkIvYEIyIiMgcDkInYE4yI/AH72pAnnk8MQCZiFRgR+TJjZOE7Zk1+Sj7pzv/Op6QjV6cXB0I0EavAiMiXYV4pjO9izCeF8WiMkZSJMlLyg/CD8wnnlfW8ZRnBAGQiVoERka/DAIHg6KSaRGlB+DHOK2cwAHlIFRiqNPnDiIh8DUp8MP1BoUKF3DqxJfmHkJAQp0t+DAxAJipaVP8/Jkbk5s3EcYGIiHwNvrRc9cVF5ApsBG2ibNlEjGlOWA1GRESUeRiATMaeYERERH4agGbOnCmlSpVSk5rVr19fdu7cmeK2hw4dUrPfYnvULU+bNi3V+x4/frzabujQoeKJ2BOMiIjIDwPQ4sWLZdiwYTJmzBjZs2ePREZGSps2bVLsMYAucGXKlFHBJq1W4Lt27ZI5c+ZI9erVxVOxJxgREZEfBqApU6ZIv379pG/fvlK5cmWZPXu2Giti3rx5drevW7euTJw4Ubp37y5hYWEp3u/t27elZ8+e8umnn0peD25dzCowIiIiPwtAcXFxsnv3bmnVqlXiDgUGqsvbt2936r4HDhwo7du3t7nvlMTGxkp0dLTNkllYBUZERORnAejq1asSHx8v4eHhNutx+eLFixm+30WLFqnqtHHjxjm0PbbLnTu3ZSluFMtkAlaBERER+WEVmKudPXtWhgwZIl9//bVqVO2IkSNHSlRUlGXBfZg1GCIRERG5n6kDIRYoUEANjHXp0iWb9bic0WGuUaWGBtS1atWyrEMp0+bNm2XGjBmquivpYFxoS5Rae6LMGAzx7l2R69cTxwUiIiIiHy0BCg0Nldq1a8uGDRss6xISEtTlhg0bZug+W7ZsKQcOHJB9+/ZZljp16qgG0fjb00YiRSFVwYL636wGIyIiyhymT4WBLvB9+vRRIaVevXpqXJ+YmBjVKwx69+4tRYsWtbTnQcPpw4cPW/4+d+6cCjY5cuSQcuXKSc6cOaVq1ao2j5E9e3bJnz9/svWeAtVgV67o1WCRkWbvDRERke8zPQB169ZNrly5IqNHj1YNn2vUqCFr1qyxNIw+c+aM6hlmOH/+vNSsWdNyedKkSWpp1qyZbNq0SbwReoLt2cOeYERERH4TgGDQoEFqsSdpqMEI0Fo6Wwt7ejBiTzAiIqLM5XO9wLwRB0MkIiLKXAxAHoCDIRIREWUuBiAPwCowIiKizMUA5GEBiIMhEhERuR8DkAeIiND/v3cP04OYvTdERES+jwHIA2AQamM6NFaDERERuR8DkIdgTzAiIqLMwwDkIdgTjIiIKPMwAHkI9gQjIiLKPAxAHoJVYERERJmHAchDsAqMiIgo8zAAeQhWgREREWUeBiAPDEAJCWbvDRERkW9jAPKgwRADAkTi4kSuXDF7b4iIiHwbA5CHCAkRKVxY/5vtgIiIiNyLAciDsB0QERFR5mAA8iDsCUZERJQ5GIA8CMcCIiIiyhwMQB6EVWBERESZgwHIg7AEiIiIKHMwAHkQtgEiIiLKHAxAHlgCdO4cB0MkIiJyJwYgD1KkiEhgoMiDByKXLpm9N0RERL6LAciDBAfrIQhYDUZEROQ+DEAehj3BiIiI3I8ByMOwJxgREZH7MQB5GPYEIyIicj8GIA/DKjAiIiL3YwDyMKwCIyIicj8GIA/DKjAiIiL3YwDy0BKg8+dF4uPN3hsiIiLfxADkYQoXFgkK0sPPxYtm7w0REZFvYgDyMAg/ERH636wGIyIicg8GIA/EnmBERER+EIBmzpwppUqVkixZskj9+vVl586dKW576NAh6dy5s9o+ICBApk2blmybcePGSd26dSVnzpxSqFAh6dSpkxw7dky8BXuCERER+XgAWrx4sQwbNkzGjBkje/bskcjISGnTpo1cvnzZ7vZ37tyRMmXKyPjx46UwGszY8euvv8rAgQNlx44dsm7dOrl//760bt1aYmJixBuwJxgREZF7BYvJpkyZIv369ZO+ffuqy7Nnz5ZVq1bJvHnzZMSIEcm2R8kOFrB3PaxZs8bm8oIFC1RJ0O7du6Vp06bi6VgFRkRE5MMlQHFxcSqUtGrVKnGHAgPV5e3bt7vscaKiotT/+fLlE2/AKjAiIiIfLgG6evWqxMfHS3h4uM16XD569KhLHiMhIUGGDh0qjRs3lqpVq9rdJjY2Vi2G6OhoMROrwIiIiHy8DZC7oS3QwYMHZdGiRSlug0bTuXPntizFjSIYkxgPf+GCyIMHpu4KERGRTzI1ABUoUECCgoLk0qVLNutxOaUGzukxaNAgWblypWzcuFGKGcUqdowcOVJVkxnLWZOLXlAgFhyM0is9BBEREZEPBaDQ0FCpXbu2bNiwwabKCpcbNmyY4fvVNE2Fn6VLl8ovv/wipUuXTnX7sLAwyZUrl81ipsBAkaJF9b9ZDUZEROSDvcDQBb5Pnz5Sp04dqVevnhrXB93VjV5hvXv3lqJFi6pqKqPh9OHDhy1/nzt3Tvbt2yc5cuSQcuXKWaq9Fi5cKMuXL1djAV3835wSqN7KmjWreANUg50+zZ5gREREPhmAunXrJleuXJHRo0eroFKjRg3Vjd1oGH3mzBnVM8xw/vx5qVmzpuXypEmT1NKsWTPZtGmTWjdr1iz1f/PmzW0ea/78+fLss8+KN2BPMCIiIh8OQIDqKiz2GKHGgBGgUcWVmrSu9wbsCUZEROQ+Pt8LzFtxMEQiIiL3YQDyUKwCIyIich8GIA/FKjAiIiL3YQDy8BIgdGC7f9/svSEiIvItDEAeqmBBjJOEBt3o+Wb23hAREfkWBiAPxcEQiYiI3IcByIOxJxgREZF7MAB5MPYEIyIicg8GIA/GnmBERETuwQDkwVgFRkRE5B4MQB6MVWBERETuwQDkwVgFRkRE5B4MQF5QAnTpkkhcnNl7Q0RE5DsYgDxYgQIiYWH63+fOmb03REREvoMByIMFBLAajIiIyB0YgDwce4IRERG5HgOQh2NPMCIiItdjAPJwrAIjIiJyPQYgD8cqMCIiItdjAPJwrAIjIiJyPQYgD8cqMCIiItdjAPKSEqArV0Tu3TN7b4iIiHwDA5CHy5dPJGtW/W8OhkhEROQaDEAejoMhEhERuR4DkBdgTzAiIiLXYgDyAuwJRkRE5FoMQF6AVWBERESuxQDkBVgFRkRE5FoMQF6AVWBERESuxQDkBVgFRkRE5FoMQF5UAnTtmsjdu2bvDRERkfdjAPICefKIZM+u/812QERERM5jAPICHAyRiIjItRiAvAR7ghEREbkOA5CXYE8wIiIiHwtAM2fOlFKlSkmWLFmkfv36snPnzhS3PXTokHTu3FltHxAQINOmTXP6Pr0Bq8CIiIh8KAAtXrxYhg0bJmPGjJE9e/ZIZGSktGnTRi5fvmx3+zt37kiZMmVk/PjxUrhwYZfcpzdgFRgREZEPBaApU6ZIv379pG/fvlK5cmWZPXu2ZMuWTebNm2d3+7p168rEiROle/fuEhYW5pL79AasAiMiIvKRABQXFye7d++WVq1aJe5QYKC6vH379ky7z9jYWImOjrZZPA2rwIiIiHwkAF29elXi4+MlPDzcZj0uX7x4MdPuc9y4cZI7d27LUtwobvEgxi7duCESE2P23hAREXk306vAPMHIkSMlKirKspz1wGKW3LlFcubU/2Y7ICIiIi8OQAUKFJCgoCC5dOmSzXpcTqmBszvuE22JcuXKZbN4IlaDERER+UAACg0Nldq1a8uGDRss6xISEtTlhg0besx9egr2BCMiInKNYDEZuqv36dNH6tSpI/Xq1VPj+sTExKgeXNC7d28pWrSoaqdjNHI+fPiw5e9z587Jvn37JEeOHFKuXDmH7tNbsScYERGRjwSgbt26yZUrV2T06NGqkXKNGjVkzZo1lkbMZ86cUb24DOfPn5eaNWtaLk+aNEktzZo1k02bNjl0n96KVWBERESuEaBpmuai+/IZ6AaP3mBoEO1J7YE++0zkhRdEHntMZPVqs/eGiIjIe7+/2QvMi7AKjIiIyDUYgLwIq8CIiIhcgwHIC0uAoqJEbt0ye2+IiIi8FwOQF8FAiBgQEdgVnoiIKOMYgLwMq8GIiIicxwDkZTgYIhERkfMYgLwMe4IRERE5jwHIy7AKjIiIyHkMQF6GVWBERETOYwDyMqwCIyIich4DkJdhFRgREZHzGIC8tAQIAyFGR5u9N0RERN6JAcjLZM8ukjev/jdLgYiIiDIxAJ09e1b+sWqFu3PnThk6dKjMnTs3g7tB6cFqMCIiIhMC0L/+9S/ZuHGj+vvixYvy6KOPqhD01ltvybvvvuvkLlFa2BOMiIjIhAB08OBBqVevnvr722+/lapVq8q2bdvk66+/lgULFji5S5QW9gQjIiIyIQDdv39fwsLC1N/r16+XDh06qL8rVqwoFy5ccHKXKC2sAiMiIjIhAFWpUkVmz54tW7ZskXXr1knbtm3V+vPnz0v+/Pmd3CVKC6vAiIiITAhAH374ocyZM0eaN28uPXr0kMjISLV+xYoVlqoxch9WgRERETknOCM3QvC5evWqREdHS16jT7aI9O/fX7Jly+bkLlF6qsA0TSQgwOw9IiIi8oMSoLt370psbKwl/Jw+fVqmTZsmx44dk0KFCrl6HymFABQTIxIVZfbeEBER+UkA6tixo3zxxRfq75s3b0r9+vVl8uTJ0qlTJ5k1a5ar95GSQCGb0dSK1WBERESZFID27NkjTZo0UX9/9913Eh4erkqBEIo+/vjjjNwlpRN7ghEREWVyALpz547kzJlT/f3zzz/LU089JYGBgdKgQQMVhMj92BOMiIgokwNQuXLlZNmyZWpKjLVr10rr1q3V+suXL0uuXLmc2B1yFHuCERERZXIAGj16tLz22mtSqlQp1e29YcOGltKgmjVrOrE75ChWgREREWVyN/guXbrIww8/rEZ9NsYAgpYtW8qTTz7pxO6Qo1gFRkRElMkBCAoXLqwWY1b4YsWKcRDETMQqMCIiokyuAktISFCzvufOnVtKliypljx58sh7772nrqPMHwyRiIiI3FwC9NZbb8lnn30m48ePl8aNG6t1v/32m7zzzjty7949ef/99zNyt5SBAHT3rsiNGyL58pm9R0RERN4jQNPSX34QERGhJkM1ZoE3LF++XF5++WU5d+6ceDNM8YHSraioKI/u1YZBt69cEdm3T8SqKRYREZFfik7H93eGqsCuX78uFStWTLYe63AdZQ72BCMiIsqYDAUg9PyaMWNGsvVYV7169QzuCqUXe4IRERFlYhugCRMmSPv27WX9+vWWMYC2b9+uBkZcvXp1BneF0os9wYiIiDKxBKhZs2by559/qjF/MBkqFkyHcejQIfnyyy/TfX8zZ85UgypmyZJFTay6c+fOVLdfsmSJqm7D9tWqVUsWum7fvi2DBg1SXfOzZs0qlStXVm2WfA2rwIiIiDJIc6F9+/ZpgYGB6brNokWLtNDQUG3evHnaoUOHtH79+ml58uTRLl26ZHf7rVu3akFBQdqECRO0w4cPa2+//bYWEhKiHThwwLIN7qNs2bLaxo0btVOnTmlz5sxRt1m+fLlD+xQVFYWG4ep/T/bVV2jArmmPPGL2nhAREZkvPd/fGSoBcqUpU6ZIv379pG/fvpaSmmzZssm8efPsbv/RRx9J27Zt5fXXX5dKlSqpsYdq1apl0yZp27Zt0qdPH2nevLkqWerfv79qt5RWyZK3YRUYERFRxpgagOLi4mT37t3SqlWrxB0KDFSX0abIHqy33h7atGljs32jRo1kxYoVqjs+evlv3LhRVdkZk7b6WhUYGkFzMEQiIqJMmArDFa5evSrx8fESHh5usx6Xjx49avc2Fy9etLs91humT5+uSn3QBig4OFiFqk8//VSaNm1q9z5jY2PVYj2OgDcoWlT//949kWvXRAoUMHuPiIiIfDAAoaFzatAY2hMgAO3YsUOVAmGajs2bN8vAgQPVAI5JS49g3LhxMnbsWPE2YWEIfyKXLunVYAxAREREbghAGF0xret79+7t8P0VKFBAgoKC5BK+wa3gMiZatQfrU9v+7t278uabb8rSpUtVV33A2ET79u2TSZMm2Q1AI0eOlGHDhtmUABU3Gth4QTWYEYBq1jR7b4iIiHwwAM2fP9+lDx4aGiq1a9eWDRs2SKdOndQ6TKaKy+jGbg/GHcL1Q4cOtaxbt26dZTyi+/fvqwXVXtYQtFKaqDUsLEwt3gg5bfduDoZIRETkNW2AACUv6LFVp04dqVevnkybNk1iYmJUrzBAiVLRokVVNRUMGTJEjUM0efJkVcKzaNEi+f3332Xu3Lnqesz9gevRSwxjAKEK7Ndff5UvvvhC9TjzNewJRkRE5IUBqFu3bnLlyhUZPXq0ashco0YNWbNmjaWh85kzZ2xKc9DDa+HChfL222+rqq7y5cvLsmXLpGrVqpZtEIpQrdWzZ081NxlCEGaof+mll8TXcDBEIiKiTJoN3td5y2zw8M03Iv/6F0bnFtm0yey9ISIi8uHZ4MlzsAqMiIgo/RiAfGgwxBTaeBMREVESDEBeDoMhBgRgVG0MLGn23hAREXkHBiAvFxKCsZH0v1kNRkRE5BgGIB/AnmBERETpwwDkQw2hORgiERGRYxiAfAB7ghEREaUPA5APYBUYERFR+jAA+QBWgREREaUPA5APYBUYERFR+jAA+VAV2LlzHAyRiIjIEQxAPiAiQgTzxd6/L3L5stl7Q0RE5PkYgHxAcLBIkSL636wGIyIiShsDkI9gTzAiIiLHMQD5CPYEIyIichwDkI9gTzAiIiLHMQD5CFaBEREROY4BKDNpmr64AavAiIiIHMcAlJmOHNGTyoABIj/9JBIb67K7ZhUYERGR4xiAMtOPP+qjFc6eLdKunUiBAiJduoh88YXI1asuGwwxPt41u0tEROSrAjTNTXUyXiw6Olpy584tUVFRkitXLtfd8b17Ihs3iqxYoS/nzydeh5EMGzcW6dBBXypUSNddI/SEhen/IwRhcEQiIiJ/Ep2O728GoMwMQNbwsu/ZkxiG9u2zvf6hhxLDUMOGIkFBad5liRJ6FdiOHSL167tnt4mIiHzh+5tVYGYJCBCpXVtk7FiRvXtFTp8WmTFDpHVrkZAQkWPHRCZOFGnSRCQ8XOTZZ0V++EHk9u00q8H++ivzngYREZE3YgmQWSVAqe+AyNq1esnQqlUiN24kXhcaKtKypV4y9MQTIkWLWq7q1k3k22/1vwsWFClfXl9Qm2b8Xa6cSI4cmf+UiIiI3I1VYN4egKw9eCCydasehpYvFzl50vZ6lCL9r6pszYVI6dc/IM2u8Jg3LGkwwlK2rEjWrG59NkRERG7DAORLAcgaDhW60hvthtDYx/rwoS98u3YSG15CLj3IJ2fv5JdTUfnl6JX8cuB8ftn9d345dz1rqrVyuAvrUGQEpdKl9cInIiIiT8UA5KsBKKlLl/QqMoShn38WuXs3zZtoWbPK/Rz5JCZrfrkZmF8ux+eXf+7ll1PR+eVCbD65JvmTLTckr0hgkJQqlRiIrBeEJgfaaBMREbkVA5C/BCBrCD8bNohs2aKPKXTtmu1y/bpenZZBNySPCkNXpKBckCKW5bxEyNXgIhJSoojkrFBEClcrKOUfCrQEJbTfRskSERGRuzEA+WMASgsO861b9oNRauuiotL1MPclWC5JuCUgXQmJkAcFikhg0SKSrVyE5KtSRIrUKiKl6hWSPAWC3fZ0iYjI/0Sn4/ub30D+AsUwOBmwoEGPo1BqhEBkhKLLl0UuXNCX8+dFO39B4s7ol0NvXpYQ7YEUk3NqUe6LyIX/Lb8n3m28BMqlwEJyM2sRuZe3iEjhIhJaKkLyNKokhbs0kYDi/+vTT0RE5AYsAfKXEqDMcP9+YkA6f17un7kgN49ckJgTF+TB2fMSfOWCZI++IPniLkqQJKR6VxezlZYrFZtKaKumUqJnE8larRzr0oiIKFWsAnMSA5CbxcfL7VNX5OzOC3J533mJ/vOCxJ66IAEXzkmpq79LDW1vsoB0NaSwnCnZVLSHm0iRbk2lyKNVJSCI43gSEVEiBiAnMQCZJzZWZP9v0XJm8XYJ2LJZiv61WWrE7ZQwibPZ7mZAHjkR/rDcqdNU8nZsKhW615KwHCGm7TcREZmPAchJDECeA2fnmT/vyYmFO+Xuz5sl/+EtUi16q+SQGJvtYiSbHM7dUK5XaSpZWzeR8s/UlyJls5m230RElPkYgJzEAOTZ7kQ/kKPf7JWbKzZLtj1bpMKlLZJPu26zTZyEyP6wunK+TBMJaNZUinVvLFUb5VbTrBERkW/yuslQZ86cKaVKlZIsWbJI/fr1ZefOnaluv2TJEqlYsaLavlq1arJ69epk2xw5ckQ6dOigXojs2bNL3bp15cyZM258FpRZsuUKllov1pUWq4ZLgwvLJO/9K3J65QHZ0fsT2VW2u1wOjpBQuS91YrdJhyMfyhOz20tk87xyKKyWLK02WvZ+dchmAG0iIvI/pgegxYsXy7Bhw2TMmDGyZ88eiYyMlDZt2shl9CayY9u2bdKjRw95/vnnZe/evdKpUye1HDx40LLNyZMn5eGHH1YhadOmTbJ//34ZNWqUCkzke9AYumT7qtLg8wFS98Q3UijuH7m176Qcem2+7K3ZV85lKyeBoqnG1U8efE9q9qoqf2WtIrs6vCsxu4+avftERGQC06vAUOKD0pkZM2aoywkJCVK8eHEZPHiwjBgxItn23bp1k5iYGFm5cqVlXYMGDaRGjRoye/Zsdbl79+4SEhIiX375ZYb2iVVgvifhn/Ny6j8b5Na8JVLp7FqbRtX/5K8uIf/qKuGDu+pzfRARkVfymiqwuLg42b17t7Rq1SpxhwID1eXt27fbvQ3WW28PKDEytkeAWrVqlVSoUEGtL1SokApZy5YtS3E/YmNj1YtmvZBvCSwWIWXf6SU1zqyQO39dkrU9FsimbO3UyNXFru2X8Olvq7k7bpSuJQ8++FDkr7/M3mUiInIjUwPQ1atXJT4+XsIxYZQVXL548aLd22B9atuj6uz27dsyfvx4adu2rfz888/y5JNPylNPPSW//vqr3fscN26cSozGghIo8l15S+eRNgv7SNNbq2Tr95dkRs3PZK20kQcSJHn/3ivBb40QKVtWYmvUE5k0SYRtx4iIfI7pbYBcDSVA0LFjR3n11VdV1Riq0h5//HFLFVlSI0eOVMVlxnL27NlM3msyQ2CgSPOn8smgPc9JlbNrZPJrF+X1XHNkvbRUU3WE/bFL5PXXRUqWFK1hQ5GpU0X++cfs3SYiIm8PQAUKFJCgoCC5dOmSzXpcLly4sN3bYH1q2+M+g4ODpXLlyjbbVKpUKcVeYGFhYaqu0Hoh/1KsmMgbEwvIB1f7y80l66Vr4/MyQD6RTdJMEiRAAnbsEBk2TASlgw8/LDJ9uj7lBxEReSVTA1BoaKjUrl1bNmzYYFOCg8sN8YvbDqy33h7WrVtn2R73iUbVx44ds9nmzz//lJIlS7rleZDvwDhBXbqIfP9buLxyeIAsfWWTVMxxTgbLx7JFHtY32rpV5JVXRIoWFWneXGTWLKRws3ediIjSQzPZokWLtLCwMG3BggXa4cOHtf79+2t58uTRLl68qK7v1auXNmLECMv2W7du1YKDg7VJkyZpR44c0caMGaOFhIRoBw4csGzzww8/qHVz587Vjh8/rk2fPl0LCgrStmzZ4tA+RUVFoWec+p/o9m1NmztX02rU0LSiclYbIlO1bdIA3ScTl8BATWvRQt/w2jWzd5mIyC9FpeP72/QABAgoJUqU0EJDQ7V69eppO3bssFzXrFkzrU+fPjbbf/vtt1qFChXU9lWqVNFWrVqV7D4/++wzrVy5clqWLFm0yMhIbdmyZQ7vDwMQ2ZOQoGnbtyOUa1poqKaVkL+14TJR+z2orm0YCg7WtPbtNe3LLzUtOtrs3SYi8htR6fj+Nn0cIE/EcYAoLVevisyfr9d+nTolUkpOSTdZLP1zLZIy0X8kbojBNx9/HINTibRrJ5I1q5m7TUTk06I5F5hzGIDIUeh0uHatyCefiKxapRcBVZQj8u/ii+Tp+G8kx/njiRvnzCnSqZMehh59VG9wRERELsMA5CQGIMoItLvHsEFffIFBPrFGk85l9sk7Fb+RKgcWSYD18Ar58umtrRGGmjYVCQoycc+JiHwDA5CTGIDIGefPi3z0kV49duuWvq5EsQSZ8NQOeTJukYQu/da21xiGcOjaVaRHD8wNIxIQYNq+ExF5MwYgJzEAkStERYlg7M1p0zCCub4ub16RV15+IENr/ip51iwS+f57kRs3Em9UqhQmvNPDUPXqDENEROnAAOQkBiBypXv3RDAv74QJIidO6OvQFvq550SGD46T0sd/Flm0SATz1cXEJN6wYkW9igzLQw+Ztv9ERN6CAchJDEDkDvHxIkuXinz4ocjvv+vr0PQHBT7//rdIZPk7ektqhCH8HxubeOOaNUWeflrvScaSISIiuxiAnMQARO6Ed9zGjXoQ+vnnxPVt24q88YZIs2YiAbei9RIhhKF160QePEjcMCJC3/ixx/TeZLlzm/I8iIg8DQOQkxiAKLPs3atXjX37rd6lHurV04MQesxjwlY16NAPP4isWCHyyy8id+8m3gGKkBo10sMQlshIlg4Rkd+KZgByDgMQZbaTJ0UmT9YHV0SbIahQQZ+MvlcvTNj7vw1x5ebNIj/9pC9J5ryTIkX00iEsKB1Cq2siIj8RzQDkHAYgMsvlyyIffywyc6bIzZuJmebVV0VefFEk2emIYajXrNHDECYJvnPHtnSoQYPE0qEaNf5XpERE5JsYgJzEAERmw/hBn34qMmWKyLlz+jo09Rk6VGTIkBQKdtBoesuWxNKhI0dsrw8PT2w71Lo1S4eIyOcwADmJAYg8BUaUXrhQbydk5BnMqPHKK3qpUP78qdz4779tS4esu9ijJMi6dAi9zFg6RERejgHISQxA5GnQQBrtoN97T2T/fn1d9uwiAweKDB8uUqhQGneA0qHffkssHTp82PZ63AFKh9q310uH8uRx23MhInIXBiAnMQCRJwchdAZDENqzJ3FQxQEDRF57TW8v5JDTp21Lh27fTt6zDGEI4w5VrcqeZUTkFRiAnMQARJ4O79rVq0XGjhXZtUtflyWLSP/++qCKRYums57NKB3CAIxJ2w4VK6YHISwtW4rkyOHS50JE5CoMQE5iACJvgXcvBlNEENq+XV8XGirywgv6WEIlSmTgTtGzDGEICSvpuEO4c4zUaAQi9NUnIvIQDEBOYgAib4N3MbLKu+/qwwRBSIjIs8+KjBwpUrp0Bu8Y4WfTJj0MoXQI4chauXKJYQjBCMVQREQmYQByEgMQebNff9WDEAKR0aSnd2+RN9/U80qG4aPizz/1IIRAhKR1/37i9dmyibRokdh2KEPFT0REGccA5CQGIPIFW7fqjaXXrtUvo5d7z54ib73losnlMVgRGlAjDGExBiwyVKmSGIbQqBpFUkREbsQA5CQGIPIl//2vHoRQcAPo0NW9ux6EkFFcAh8j6J9vhKFt2xInNwO8j+rXF6lbV6ROHf1/tNRm7zIiciEGICcxAJEv2r1bD0LLl+uXkT06dxYZNUqkenUXP9j163rrbIQhNKjGhK5JFS6sByHrUFSggIt3hIj8STQDkHMYgMiX7dsn8n//J/L994nrMPP822+L1K7thgdESRAeFP31jeXQIZH4+OTbliplG4iwQ3wPEpGDGICcxABE/uDgQZH33xdZvFivwQJMII9eY82bu7l2CpO2Jg1FaGCdFHYCDZasQxEmdcXoj0RESTAAOYkBiPzJ0aMiH3ygzzlmFMrUq6cHoQ4dMnGKsJs39Xq6339PDEVnziTfLjhYH53aOhThMhtZE/m9aAYg5zAAkT/C3KmTJol89pnIvXv6uooV9QEV//UvfQzETHf5sh6ErEMR1iUVFqaHIJQOGUtkpD5zLBH5jWgGIOcwAJE/Q774+GORGTNEoqL0dcWL65OuYoRpTMJqGnxcnT1rG4rwv7GjSWHgI+tQhCUigr3PiHwUA5CTGICI8D4QmTNHZMoUkYsX9XX584u88orIoEEi+fKJZ0Aj67/+0tsUWS9JxyUyoKdZ0lCEdkaoWiMir8YA5CQGIKJEqA774guRCRNETp7U16EU6MUXRYYNS+fEq5npyhWRP/6wDUVo8GSv9xmm8KhWzTYUYWwATvxK5FUYgJzEAESU3IMHetf5ceP0XAFod4xpNjADvVfMi4q5zdAF3zoU4cncvp18W1STGVVoeHIFC9pfTGkcRUT2MAA5iQGIKGX4xMD0GghCxsSrxqCKI0a4aSyhzKhC27vXNhidP+/Y7fEZkVI4srdgzjQicgsGICcxABE5BjNejB8v8uOPietatdK70D/yiJe3NUZrcKMK7fRpvUrNesHo1vaq09KCAJQ0FGFcI7RBMhbMYGt92ZHrUlqPEqpChfS6SlbpkY+LZgByDgMQUfoHVfzwQ5FvvrEdSwglQh07ZuJYQpldcoSxi5IGo9SWuDhz9xmfZwhCWNAbzvjb+nJ4OBuEk9diAHISAxCRD40l5CnwUXvrlv2SJLxYSI5oaGVvSek6R9bjvi9csN/OyR6kVczTllJAMhZ8Nnp1ER/5IgYgJzEAEbl+LCF8fw4erPcey5vX7D30QwhfGBrAWNDGKellBCVHq/VQlWeUGKFbIC67YmHpEzmBAchJDEBErh1LaOpU/bsV8F35/PMiQ4eKlC5t9h6SDYQfpFd74cj6Mqr+3AVdC60DEdpHYZgCY0ntcnq2NRa0nUKpF0qzHP2fJV8Zg7hx7Zrepg7FxUWKiDRqJH4dgGbOnCkTJ06UixcvSmRkpEyfPl3qoQFBCpYsWSKjRo2Sv//+W8qXLy8ffvihtGvXzu62L730ksyZM0emTp0qQ/GJ6wAGICLXQtMXtA+aPFnkwAF9Hb5LnnpKH2G6QQOz95DSPZmtEYpQjYfhBbAuo0tMTOKMvN4iaSCyF5awYJoWdy1o1I6BPY0F68ykaSKXLiUGHHv/41gbMIbG55+7dBfS8/1telnj4sWLZdiwYTJ79mypX7++TJs2Tdq0aSPHjh2TQui5kMS2bdukR48eMm7cOHn88cdl4cKF0qlTJ9mzZ49UxVxAVpYuXSo7duyQCJS9E5Fp0PanTx/98279ej0IoSv9d9/pC34EvvaaPvkqfpCTh0PJDMZIwuKqL06kZHvBCG2YELDwf9K/nb0cG+vcPmekF6A7Ye47Iwyhd6F1OLK+bPydN2/6eijg+aIoN6WAg8mLjcZ/qUEbs5IlRcqUETOZXgKE0FO3bl2ZgcYCqmNFghQvXlwGDx4sI9CFJIlu3bpJTEyMrFy50rKuQYMGUqNGDRWiDOfOnVP3vXbtWmnfvr0q/WEJEJHnQEkQptn4+muR+/f1dWXLirz6qsizz5o85xj5B3z9oTefK/+3/huN0BHsELQyshghLaUF7bpQpZTRIRkCA/U5beyFI8x7g4bz1gEH8/AZb9aUoPQLbcMQcEqVSv5/iRJ61aObeE0JUFxcnOzevVtGYtCQ/wkMDJRWrVrJ9u3b7d4G61FiZA0lRsuWLbNcRojq1auXvP7661KlSpU09yM2NlYt1i8gEbkXZp6YP1/kgw/0xtKzZulTbWCesdGjUX2t/41mAkRugS9rXyhyROBCbwMEIaNnobFYX7b+OypKv51x2VF4vTA7ckoBp1gxr+nuaWoAunr1qsTHx0s4ehFYweWjmLPHDrQTsrc91hvQJig4OFhewayNDkB12tixYzP0HIjIOQg4778v8uabIgsW6KVCGJgZwQhd6nv21OccS1LDTUTWJTmozsJSvrxjt4mLSyw9Sik4oaoTocY64KBJiY/01PONZ2EFJUofffSRahMU4GBLfZRAWZcqoQQI1XBElHlQ5TVwoF7ys3y53k4II02jlAhLmzZ6g2mMNM1OOEROCg3Vf334cRGrqeOzFihQQIKCguQSWo1bweXCaCRlB9antv2WLVvk8uXLUqJECVUKhOX06dMyfPhwKYX0akdYWJiqK7ReiMgcKGFH77CtW1HlLdKli/4DF42mW7fW5yZFxxGzB1UmIu9magAKDQ2V2rVry4YNG2za7+Byw4YN7d4G6623h3Xr1lm2R9uf/fv3y759+ywLeoGhPRAaRBOR90D3+CVLRI4f1wdRRCnR/v16I2n8nsGErDdumL2XROSNTJ+hB1VPn376qXz++edy5MgRGTBggOrl1bdvX3V97969bRpJDxkyRNasWSOTJ09W7YTeeecd+f3332UQWksKGq7nV93hrZeQkBBVQvTQQw+Z9jyJKOPQWxYjS6MTCkIPmiGgNy7aDaG2Gs39jh0zey+JyJuYHoDQrX3SpEkyevRo1ZUdJTYIOEZD5zNnzsgFYwhZwXghjdTYP3PnzlWDJn733XeqB1jSMYCIyPegjSdGxzh1Sq8Gq15dHypm+nR9zjG0E1qxwvOGZyEiz2P6OECeiOMAEXkHfHqhRhylQxgazPg0Q4eVAQP0KTcwpAkR+YfodHx/m14CRESUUegNhl5hKPXBGEKvv66P64Zx21BShCFJ0F7o99/N3lMi8jQMQETkEzCx6oQJIv/8IzJvnkitWvpguagqq1tXb1D95ZfOzX5ARL6DAYiIfAom/EYfCpT6oBv9M8/oQ57897/6XGRoNI3G05i2iIj8FwMQEfls9ZhR6oPeYxhtGlViGOAWPclQYvTkk3obIraEJPI/DEBE5PMKFdJLfdB77IcfRFq00KdBwhSCaENUubI+HxmnASTyHwxAROQ3MIWRUepz6JA+9UaOHCKYehADLWISa6w7fNjsPSUid2MAIiK/ZJT6nDun/1+pksjt2yKffCJSpYpeSoTSogcPzN5TInIHBiAi8msYKgSlPigRQskQSogw99jGjSKdO+tthd57j42miXwNAxAR0f8aTRulPmgrhDZDBQvq3epHj9bnHnv0UZGvvxa5c8fsvSUiZzEAERElUaKE3msMvce++koPRugptn693q2+cGGRfv1Etm1jDzIib8WpMOzgVBhElNTff4t88YXIggV6CZGhfHl9tGmMMYRu9kTkHd/fDEB2MAARUUrQfX7LFj0ILVmiT8ZqVKGhigxhqFMnfUBGIspcDEBOYgAiIkeg19j334vMny/y66+J63PnFuneXQ9D9evr4YiI3I8ByEkMQESUXn/9lVhFhslYDRUr6kEIbYcwzhARuQ8DkJMYgIjImSoylAYhCH33XWKPMXStb91aD0MdO4pkyWL2nhL5HgYgJzEAEZEr3LqltxNCGEK7IUOePCI9euhhCDPVs4qMyDUYgJzEAERErnbihMjnn+sLutdbj0iNMPTUU/po1AxDRBnHAOQkBiAicmcV2S+/6KVCaEB9717idRUq6CNRY0HJEKrNiMhxDEBOYgAioswQFaWHIIw+vW6dSFxc4nUREXp3eoShZs1EQkLM3FMi78AA5CQGICLKbNHRIj/9JLJ0qcjq1Xr7IUPevCKPP65Xk6EhdbZsZu4pkediAHISAxARmSk2Vp+YFWFo+XKRK1cSr8MAi23b6iVDCEUIR0SkYwByEgMQEXmK+Hh9zjGEISyYksMQHCzSvLkehlBdhmozIn8WzQDkHAYgIvJE+LT+4w+9zRDC0MGDttdj1GmjETUaVBP5m2gGIOcwABGRt3StN0qGtm+3vQ7d640wVKsWu9eTf4hmAHIOAxAReZsLF/T2QghD6Gb/4EHideHheuNpLJiwFZeJfBEDkJMYgIjIm928KbJqlR6G1qxJnLHeUKNGYiBq3JjTcpDvYAByEgMQEflSjzJUj61dK/LzzyJ79thej15laEhtBCKORk3ejAHISQxAROSr0KV+/frEQISqM2vFiiWGoVatRPLnN2tPidKPAchJDEBE5A/w6X/oUGIY2rzZdmoOlATVqaOHoTZtRBo04IjU5NkYgJzEAERE/ujuXX3WeoQhLAcO2F6fM6fII4/oYQihqGxZVpeRZ2EAchIDEBGRyPnz+hxlKCHC/1ev2l5funRiVRmCEavLyGwMQE5iACIiSj6L/b59idVlW7eK3L+feD1KgmrW1MNQy5YiDz/MOcso8zEAOYkBiIgodbdvi2zapDeoxoK2RNZCQ/Uu9ghDCEW1a+tTdxC5EwOQkxiAiIjSB73JMAAjwhAmcj171vZ6fJSimswIRBUrsv0Qmfv9HSgeYObMmVKqVCnJkiWL1K9fX3bu3Jnq9kuWLJGKFSuq7atVqyarV6+2XHf//n1544031Prs2bNLRESE9O7dW86jMpuIiNyiSBGRnj1F5s8XOX1a5NgxkU8+EXnqKX3G+uhofaTqV17Rp+lAd/vevUW++ELk3Dmz9578keklQIsXL1YBZfbs2Sr8TJs2TQWcY8eOSaFChZJtv23bNmnatKmMGzdOHn/8cVm4cKF8+OGHsmfPHqlatapKfV26dJF+/fpJZGSk3LhxQ4YMGSLx8fHy+++/O7RPLAEiInLtjPZ79+olQygh+u032+72gBIho/0QBmbMk8esvSVv5lVVYAg9devWlRkzZqjLCQkJUrx4cRk8eLCMGDEi2fbdunWTmJgYWblypWVdgwYNpEaNGipE2bNr1y6pV6+enD59WkqUKJHmPjEAERG5D8LPtm2J1WX4bYpG1obAQH38IQSiJk30qTsKFzZzj8lbpOf729QmaXFxcbJ7924ZOXKkZV1gYKC0atVKtied2vh/sH7YsGE269q0aSPLli1L8XHwQgQEBEieFH5SxMbGqsX6BSQiIvfA3GMtWuiLMXeZ0aAagejoURG0hLBuDYEJXNHLDGHIWMqVEwkKMu1pkJczNQBdvXpVVU2FJ5maGJeP4h1gx8WLF+1uj/X23Lt3T7UJ6tGjR4ppENVpY8eOzfDzICKijMNv006d9AX++SexQTVKh9Ce6NIlfWJXLIbs2UWqV7cNRVWrsvs9OcanOyWiQXTXrl0FtXyzZs1KcTuUQFmXKqEECNVwRESU+YwG0ljgzh19VGqMQ2Qsf/yhz3KPygLrCgNUn6E9kXUowlKwoGlPhzyUqQGoQIECEhQUJJcQ7a3gcuEUKnyx3pHtjfCDdj+//PJLqnWBYWFhaiEiIs+DEp369fXFumH18eOJgQiNrLFgstfDh/Vl4cLE7SMiklehlSmjBybyT6YGoNDQUKldu7Zs2LBBOv2v7BONoHF50KBBdm/TsGFDdf3QoUMt69atW6fWJw0/x48fl40bN0p+js9ORORT0PYHJT1YunfX16FLD1pDWIci/I+ghJFQsKxaZTu3WWSkHoyMBV30MYgj+T7Tq8BQ9dSnTx+pU6eO6qmFbvDo5dW3b191PbrIFy1aVLXTAXRpb9asmUyePFnat28vixYtUt3b586dawk/6AaPbvHoKYY2Rkb7oHz58qnQRUREvgcDK2I8IiyPPZa4/tYtvQrNCERYcBnr0SUfiwFfEVWq2IYihKQcOUx5SuTLAQjd2q9cuSKjR49WQQXd2desWWNp6HzmzBnVM8zQqFEjNfbP22+/LW+++aaUL19e9QDDGEBw7tw5WbFihfob92UNpUHNMcAEERH5DZT0NGqkL4YHD/TeZkbVmbFERSX+bR2sypcXqVXLNhgVKGDK0yEXMX0cIE/EcYCIiPwPvg3//jt5KEppIgE01rYORFgw1Byn+DCPVw2E6IkYgIiIyIB+N0lD0YkT9rfNl09vYG0EomrVRB56CJ1tMnuv/VM0A5BzGICIiCg1GC8XXfGtQ9GhQ3rVmr0G2xUq6GEIrTWMBb3QOJCjazEAOYkBiIiI0gsTCiAEGYEIja0PHtTbFaU0IjZ6nVmHIiyoWmM1WsYwADmJAYiIiFwB37CY7R5ByHpBUEo6IawBXztJQxEWDuaYNgYgJzEAERGRO2Egx1On9O741sEI037gOnvQOdo6EGEMJExagEEeQ0Iy+xl4JgYgJzEAERGRWdVof/6ZvMTor79Svg1GisHYRwhDKS0IT/4w6nU0A5BzGICIiMiT3L4tcuRIYokR/kdPNFSv3b+f9u1RQoS2RamFpHz5vL/tEQOQkxiAiIjIGyQk6N30z55Nvpw5o/9/4YLeFsmROdeKWwUiBCZUrxUtqv+PpVAhz+65xgDkJAYgIiLyFSghwmCOKQWks2dFrl517L4QfjD3uHUwsg5Ixt958phTmpSe72/Tp8IgIiIi90H1V8mS+pKSu3dF/vnHNiCheg2LMZEsSprQQNtYv2tXyveXNWvyUGTvb2xnFgYgIiIiP5c1qz7fGZaUYJBHhCCEIetgZPxt/H/jhh6oTp7Ul5Q88YTI/6buNAUDEBEREaUpOFgvtcFSt27K2yH8GOEotbCEUiAzMQARERGRS0uTypbVl5Sg9bEjvdfcyQ9GBSAiIiJPEhAgEhpq7j4wABEREZHfYQAiIiIiv8MARERERH6HAYiIiIj8DgMQERER+R0GICIiIvI7DEBERETkdxiAiIiIyO8wABEREZHfYQAiIiIiv8MARERERH6HAYiIiIj8DgMQERER+Z1gs3fAE2mapv6Pjo42e1eIiIjIQcb3tvE9nhoGIDtu3bql/i9evLjZu0JEREQZ+B7PnTt3qtsEaI7EJD+TkJAg58+fl5w5c0pAQIDL0ymC1dmzZyVXrlziy/hcfZc/PV8+V9/lT8/XX56rpmkq/EREREhgYOqtfFgCZAdetGLFirn1MXAC+vJJaI3P1Xf50/Plc/Vd/vR8/eG55k6j5MfARtBERETkdxiAiIiIyO8wAGWysLAwGTNmjPrf1/G5+i5/er58rr7Ln56vPz1XR7ERNBEREfkdlgARERGR32EAIiIiIr/DAERERER+hwGIiIiI/A4DkBvMnDlTSpUqJVmyZJH69evLzp07U91+yZIlUrFiRbV9tWrVZPXq1eLpxo0bJ3Xr1lWjZRcqVEg6deokx44dS/U2CxYsUCNrWy94zp7unXfeSbbfOF6+dkwNOHeTPl8sAwcO9PrjunnzZnniiSfUKLHYz2XLltlcjz4ho0ePliJFikjWrFmlVatWcvz4cZe/5z3h+d6/f1/eeOMNdX5mz55dbdO7d281Cr6r3w+ecGyfffbZZPvdtm1brzy2aT1Xe+9fLBMnTvS64+pODEAutnjxYhk2bJjqbrhnzx6JjIyUNm3ayOXLl+1uv23bNunRo4c8//zzsnfvXhUksBw8eFA82a+//qq+EHfs2CHr1q1TH6atW7eWmJiYVG+HEUgvXLhgWU6fPi3eoEqVKjb7/dtvv6W4rbceU8OuXbtsniuOLzz99NNef1xxfuI9iS81eyZMmCAff/yxzJ49W/773/+qYID3771791z2nveU53vnzh21v6NGjVL///DDD+pHTIcOHVz6fvCUYwsIPNb7/c0336R6n556bNN6rtbPEcu8efNUoOncubPXHVe3Qjd4cp169eppAwcOtFyOj4/XIiIitHHjxtndvmvXrlr79u1t1tWvX1978cUXNW9y+fJlDKeg/frrryluM3/+fC137tyatxkzZowWGRnp8Pa+ckwNQ4YM0cqWLaslJCT41HHF+bp06VLLZTy/woULaxMnTrSsu3nzphYWFqZ98803LnvPe8rztWfnzp1qu9OnT7vs/eApz7VPnz5ax44d03U/3nBsHTmueN4tWrRIdZsxXnBcXY0lQC4UFxcnu3fvVsXm1vOK4fL27dvt3gbrrbcH/MJIaXtPFRUVpf7Ply9fqtvdvn1bSpYsqSbl69ixoxw6dEi8AapBUNxcpkwZ6dmzp5w5cybFbX3lmBrn9FdffSXPPfdcqhMDe+txtXbq1Cm5ePGizbHDnEKo9kjp2GXkPe/p72Mc5zx58rjs/eBJNm3apKrsH3roIRkwYIBcu3YtxW195dheunRJVq1apUqk03LcS49rRjEAudDVq1clPj5ewsPDbdbjMj5Y7cH69GzviRISEmTo0KHSuHFjqVq1aorb4UMHRbHLly9XX6q4XaNGjeSff/4RT4YvQLRzWbNmjcyaNUt9UTZp0kTNOOyrx9SAtgU3b95U7Sd87bgmZRyf9By7jLznPRWq+dAmCNW3qU2Wmd73g6dA9dcXX3whGzZskA8//FBV4z/22GPq+Pnysf38889VW82nnnoq1e3qe+lxdQZngyenoS0Q2rekVV/csGFDtRjwJVmpUiWZM2eOvPfee+Kp8CFpqF69uvqgQGnHt99+69CvKm/22WefqeePX4W+dlwpEdrwde3aVTUCx5efL74funfvbvkbDb+x72XLllWlQi1bthRfhR8nKM1Jq2PCY156XJ3BEiAXKlCggAQFBakiR2u4XLhwYbu3wfr0bO9pBg0aJCtXrpSNGzdKsWLF0nXbkJAQqVmzppw4cUK8CaoHKlSokOJ+e/sxNaAh8/r16+WFF17wi+NqHJ/0HLuMvOc9NfzgeKPBe2qlPxl5P3gqVPPg+KW0375wbLds2aIatqf3PezNxzU9GIBcKDQ0VGrXrq2KWA2oDsBl61/I1rDeenvAh1BK23sK/FJE+Fm6dKn88ssvUrp06XTfB4qXDxw4oLocexO0dzl58mSK++2txzSp+fPnq/YS7du394vjinMYX2zWxy46Olr1Bkvp2GXkPe+J4QdtPxB28+fP7/L3g6dCFS3aAKW0395+bI0SXDwH9Bjzl+OaLma3wvY1ixYtUr1GFixYoB0+fFjr37+/lidPHu3ixYvq+l69emkjRoywbL9161YtODhYmzRpknbkyBHVEj8kJEQ7cOCA5skGDBigev5s2rRJu3DhgmW5c+eOZZukz3Xs2LHa2rVrtZMnT2q7d+/WunfvrmXJkkU7dOiQ5smGDx+unuepU6fU8WrVqpVWoEAB1fPNl46pNfR2KVGihPbGG28ku86bj+utW7e0vXv3qgUff1OmTFF/G72exo8fr96vy5cv1/bv3696z5QuXVq7e/eu5T7Qm2b69OkOv+c99fnGxcVpHTp00IoVK6bt27fP5n0cGxub4vNN6/3gic8V17322mva9u3b1X6vX79eq1Wrlla+fHnt3r17Xnds0zqPISoqSsuWLZs2a9Ysu/fRwkuOqzsxALkBTip8eYSGhqpulDt27LBc16xZM9Ud09q3336rVahQQW1fpUoVbdWqVZqnw5vO3oIu0Sk916FDh1pel/DwcK1du3banj17NE/XrVs3rUiRImq/ixYtqi6fOHHC546pNQQaHM9jx44lu86bj+vGjRvtnrfG80FX+FGjRqnngS++li1bJnsNSpYsqUKto+95T32++KJL6X2M26X0fNN6P3jic8UPs9atW2sFCxZUP0bwnPr165csyHjLsU3rPIY5c+ZoWbNmVUM52FPSS46rOwXgn/SVGRERERF5N7YBIiIiIr/DAERERER+hwGIiIiI/A4DEBEREfkdBiAiIiLyOwxARERE5HcYgIiIiMjvMAAREaUgICBAli1bZvZuEJEbMAARkUd69tlnVQBJurRt29bsXSMiHxBs9g4QEaUEYQeTsloLCwszbX+IyHewBIiIPBbCDmZot17y5s2rrkNp0KxZs+Sxxx6TrFmzSpkyZeS7776zuT1mpW/RooW6HjOd9+/fX81ybW3evHlSpUoV9ViY+XrQoEE211+9elWefPJJyZYtm5QvX15WrFhhue7GjRvSs2dPKViwoHoMXJ80sBGRZ2IAIiKvNWrUKOncubP88ccfKoh0795djhw5oq6LiYmRNm3aqMC0a9cuWbJkiaxfv94m4CBADRw4UAUjhCWEm3Llytk8xtixY6Vr166yf/9+adeunXqc69evWx7/8OHD8tNPP6nHxf0VKFAgk18FIsoQs2djJSKyBzNbBwUFadmzZ7dZ3n//fXU9Pr5eeuklm9vUr19fGzBggPp77ty5Wt68ebXbt29brl+1apUWGBhomQU8IiJCe+utt1LcBzzG22+/bbmM+8K6n376SV1+4okntL59+7r4mRNRZmAbICLyWI888ogqVbGWL18+y98NGza0uQ6X9+3bp/5GiUxkZKRkz57dcn3jxo0lISFBjh07pqrQzp8/Ly1btkx1H6pXr275G/eVK1cuuXz5sro8YMAAVQK1Z88ead26tXTq1EkaNWrk5LMmoszAAEREHguBI2mVlKugzY4jQkJCbC4jOCFEAdofnT59WlavXi3r1q1TYQpVapMmTXLLPhOR67ANEBF5rR07diS7XKlSJfU3/kfbILQFMmzdulUCAwPloYcekpw5c0qpUqVkw4YNTu0DGkD36dNHvvrqK5k2bZrMnTvXqfsjoszBEiAi8lixsbFy8eJFm3XBwcGWhsZo2FynTh15+OGH5euvv5adO3fKZ599pq5DY+UxY8aocPLOO+/IlStXZPDgwdKrVy8JDw9X22D9Sy+9JIUKFVKlObdu3VIhCds5YvTo0VK7dm3Viwz7unLlSksAIyLPxgBERB5rzZo1qmu6NZTeHD161NJDa9GiRfLyyy+r7b755hupXLmyug7d1teuXStDhgyRunXrqstorzNlyhTLfSEc3bt3T6ZOnSqvvfaaClZdunRxeP9CQ0Nl5MiR8vfff6sqtSZNmqj9ISLPF4CW0GbvBBFReqEtztKlS1XDYyKi9GIbICIiIvI7DEBERETkd9gGiIi8EmvvicgZLAEiIiIiv8MARERERH6HAYiIiIj8DgMQERER+R0GICIiIvI7DEBERETkdxiAiIiIyO8wABEREZHfYQAiIiIiv/P/ICads4Q8fT0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses over epochs\n",
    "plt.plot(train_losses, label='Training loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation loss', color='red')\n",
    "\n",
    "# Adding a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Setting the title and labels for clarity\n",
    "plt.title(\"Training and Validation Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference and 2-Gram Comparison\n",
    "\n",
    "This code performs inference on the test data and compares the predicted 2-grams with the actual 2-grams, providing a performance evaluation based on the **Dice similarity coefficient**.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Prepare for Evaluation**:\n",
    "   - The model is switched to **evaluation mode** (`model.eval()`), ensuring no gradient computation.\n",
    "   \n",
    "2. **Thresholding**:\n",
    "   - A threshold (`DEA_CONFIG[\"FilterThreshold\"]`) is applied to filter out low-probability predictions, retaining only the most confident predictions.\n",
    "\n",
    "3. **Inference and 2-Gram Scoring**:\n",
    "   - The model is applied to the batch, and the **logits** are converted into probabilities using the **sigmoid function**.\n",
    "   - The probabilities are then mapped to **2-gram scores**, and scores below the threshold are discarded.\n",
    "\n",
    "4. **Reconstructing Words**:\n",
    "   - For each sample in the batch, **2-grams** are reconstructed into words based on the filtered scores.\n",
    "\n",
    "5. **Performance Metrics**:\n",
    "   - The actual 2-grams (from the test dataset) are compared with the predicted 2-grams, and the **Dice similarity coefficient** is calculated for each sample.\n",
    "\n",
    "### Result:\n",
    "- The code generates a list `combined_results_performance`, which contains a detailed comparison for each UID, including:\n",
    "  - **Actual 2-grams** (from the test data)\n",
    "  - **Predicted 2-grams** (from the model)\n",
    "  - **Dice similarity** score indicating how similar the actual and predicted 2-grams are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a85fecd316446acb1ffeb1a1c02f000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test loop:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'uid': '76654', 'actual_two_grams': ['we', 'en', 'nd', 'dy', 'ys', 'sw', 'wa', 'an', 'nk', 'k8', '82', '22', '21', '19', '96', '69'], 'predicted_two_grams': {'81', 'br', 'bb', '19', 'dy', 'an', '96', '21', '22', 'nd'}, 'dice_similarity': 0.5385}, {'uid': '18525', 'actual_two_grams': ['ti', 'ie', 'er', 'rr', 'ra', 'ah', 'ha', 'ad', 'df', 'fi', 'ie', 'el', 'ld', 'd6', '61', '11', '11', '19', '94', '48'], 'predicted_two_grams': {'ra', 'ha', 'er', '19', '94', '12', '11', 'r1'}, 'dice_similarity': 0.4615}, {'uid': '97946', 'actual_two_grams': ['no', 'oa', 'ah', 'hr', 'ro', 'oo', 'os', 'se', 'ev', 've', 'el', 'lt', 't9', '91', '15', '51', '19', '98', '80'], 'predicted_two_grams': {'51', '19', 'ro', 'yd', '98'}, 'dice_similarity': 0.3333}, {'uid': '63361', 'actual_two_grams': ['jo', 'os', 'se', 'ep', 'ph', 'hc', 'cr', 'ro', 'op', 'pp', 'pe', 'er', 'r9', '91', '16', '61', '19', '93', '38'], 'predicted_two_grams': {'pe', 'os', '61', 'ph', '93', 'er', 'op', '19', 'ro', '99', 'ep', '91', 'se'}, 'dice_similarity': 0.75}, {'uid': '17376', 'actual_two_grams': ['fr', 're', 'ed', 'da', 'as', 'si', 'in', 'ng', 'ge', 'er', 'r7', '71', '14', '41', '19', '98', '89'], 'predicted_two_grams': {'in', 're', 'da', '19', '41', 'n4', 'ed', '98'}, 'dice_similarity': 0.56}, {'uid': '73153', 'actual_two_grams': ['me', 'el', 'li', 'is', 'ss', 'sa', 'aw', 'wa', 'ag', 'gn', 'ne', 'er', 'r5', '52', '22', '21', '19', '94', '42'], 'predicted_two_grams': {'25', 'sa', '94', 'aw', '19', 'li', 'ac', 'el', '21', 'is'}, 'dice_similarity': 0.5517}, {'uid': '39036', 'actual_two_grams': ['vi', 'ir', 'rg', 'gi', 'in', 'ni', 'ia', 'as', 'sh', 'ha', 'ap', 'pi', 'ir', 'ro', 'o2', '22', '25', '51', '19', '97', '78'], 'predicted_two_grams': {'51', 'vi', '25', 'in', 'ha', '19', 'ia', 'li', 'rg', '97', 'ir', 'gi', 'ni'}, 'dice_similarity': 0.7273}, {'uid': '22536', 'actual_two_grams': ['je', 'en', 'nn', 'ni', 'ie', 'ej', 'jo', 'oh', 'hn', 'ns', 'so', 'on', 'n1', '12', '29', '92', '20', '00', '00'], 'predicted_two_grams': {'ie', '29', '00', 'n1', 'jo', 'on', 'oh', '11', 'hn', 'en', 'ns', 'so', '91', 'ni', '20'}, 'dice_similarity': 0.7879}, {'uid': '82052', 'actual_two_grams': ['ka', 'ar', 're', 'en', 'na', 'ab', 'ba', 'ad', 'di', 'ie', 'e1', '11', '14', '41', '19', '93', '38'], 'predicted_two_grams': {'ar', '41', '19', '93', 'ke', 'rg', '11', 'ba', 'en'}, 'dice_similarity': 0.5385}, {'uid': '26666', 'actual_two_grams': ['de', 'ea', 'an', 'nb', 'ba', 'ar', 'rt', 'th', 'h8', '85', '51', '19', '95', '53'], 'predicted_two_grams': {'th', '51', 'ar', '19', '53', '95'}, 'dice_similarity': 0.6}, {'uid': '72821', 'actual_two_grams': ['de', 'en', 'nn', 'ni', 'is', 'sb', 'bu', 'ul', 'll', 'la', 'ar', 'rd', 'd4', '42', '21', '11', '19', '95', '53'], 'predicted_two_grams': {'ar', '41', '19', '95', 'rd', 'la', 'll', 'en'}, 'dice_similarity': 0.5185}, {'uid': '5562', 'actual_two_grams': ['de', 'el', 'li', 'ia', 'ad', 'da', 'an', 'ni', 'ie', 'el', 'l4', '41', '12', '21', '19', '94', '45'], 'predicted_two_grams': {'ie', '41', 'da', '19', '94', 'li', 'an', '12', 'el', 'ni'}, 'dice_similarity': 0.7692}, {'uid': '91595', 'actual_two_grams': ['de', 'el', 'll', 'la', 'as', 'sc', 'co', 'ot', 'tt', 't2', '26', '62', '20', '00', '02'], 'predicted_two_grams': {'tt', '00', 'sc', 'la', 'll', '02', 'co', '62', '22', '20'}, 'dice_similarity': 0.72}, {'uid': '14827', 'actual_two_grams': ['ke', 'en', 'nn', 'ne', 'et', 'th', 'hh', 'ha', 'am', 'mm', 'mo', 'on', 'ns', 's9', '91', '11', '11', '19', '97', '70'], 'predicted_two_grams': {'ns', 'th', 'ar', 'ha', 've', '19', 'on', '11', '97', 'en', 'nn', 'ka'}, 'dice_similarity': 0.5806}, {'uid': '80821', 'actual_two_grams': ['ma', 'ar', 'rg', 'go', 'ol', 'la', 'as', 'sh', 'hl', 'le', 'ey', 'y4', '41', '16', '61', '19', '99', '94'], 'predicted_two_grams': {'ar', '61', '94', 'le', '19', 'as', 'sh', 'ey', 'ma', 'la'}, 'dice_similarity': 0.7143}, {'uid': '14776', 'actual_two_grams': ['sa', 'ar', 'ra', 'ah', 'hm', 'mo', 'or', 'rg', 'ga', 'an', 'n3', '32', '22', '21', '19', '99', '93'], 'predicted_two_grams': {'ar', 'sa', '93', '19', 'or', 'an', 'rg', 'ma', '99', '21'}, 'dice_similarity': 0.6667}, {'uid': '37621', 'actual_two_grams': ['al', 'lm', 'ma', 'am', 'mo', 'ot', 'ty', 'yk', 'ka', 'a8', '87', '71', '19', '96', '64'], 'predicted_two_grams': {'19', 'ma', '96', '71'}, 'dice_similarity': 0.4211}, {'uid': '76371', 'actual_two_grams': ['ma', 'ar', 'ri', 'ia', 'an', 'ng', 'gu', 'ul', 'll', 'le', 'et', 'tt', 't8', '81', '18', '81', '19', '94', '40'], 'predicted_two_grams': {'tt', 'ar', 'ri', '94', 'et', '19', 'ia', 'an', 'ma'}, 'dice_similarity': 0.6667}, {'uid': '69454', 'actual_two_grams': ['da', 'av', 'vi', 'id', 'dr', 'ry', 'ya', 'an', 'n1', '12', '22', '22', '21', '19', '96', '65'], 'predicted_two_grams': {'vi', 'da', '19', 'an', '12', '96', '21', 'id', '22', '62', 'av'}, 'dice_similarity': 0.7692}, {'uid': '34111', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'mf', 'fr', 'ra', 'an', 'nk', 'ks', 's1', '11', '11', '11', '19', '99', '93'], 'predicted_two_grams': {'il', '19', 'ia', 'li', 'an', 'wi', '99', '11', 'll', 's1', 'am'}, 'dice_similarity': 0.7857}, {'uid': '92639', 'actual_two_grams': ['ju', 'ud', 'dy', 'ym', 'ma', 'ar', 'rt', 'ti', 'in', 'ne', 'ez', 'z1', '12', '25', '51', '19', '98', '89'], 'predicted_two_grams': {'ar', 'in', 'ti', '19', 'rt', '12', 'st', 'ma', 'ry', '98', 'ne'}, 'dice_similarity': 0.6207}, {'uid': '9693', 'actual_two_grams': ['sa', 'al', 'll', 'ly', 'yw', 'wr', 'ri', 'ig', 'gh', 'ht', 't1', '11', '13', '30', '01', '19', '98', '83'], 'predicted_two_grams': {'30', 'ig', 'ri', 'ht', '19', 'gh', '88', 'wr', 't1', '11', '13', '98', 'al', '01'}, 'dice_similarity': 0.8125}, {'uid': '7631', 'actual_two_grams': ['la', 'au', 'ur', 'ri', 'ie', 'ea', 'ar', 're', 'ev', 'va', 'al', 'lo', 'o6', '61', '18', '81', '19', '94', '44'], 'predicted_two_grams': {'81', 'ur', 'ar', '61', 'au', '94', '19', 'la'}, 'dice_similarity': 0.5926}, {'uid': '85334', 'actual_two_grams': ['ju', 'ud', 'di', 'it', 'th', 'hd', 'de', 'el', 'lo', 'or', 're', 'en', 'nz', 'zo', 'o5', '52', '24', '41', '19', '95', '59'], 'predicted_two_grams': {'th', '51', 're', '19', '95', 'el', 'll', 'en', '54'}, 'dice_similarity': 0.4}, {'uid': '50380', 'actual_two_grams': ['ba', 'ar', 'rb', 'ba', 'ar', 'ra', 'ab', 'by', 'yr', 'rd', 'd8', '83', '30', '01', '19', '98', '85'], 'predicted_two_grams': {'81', 'ar', 'ri', '19', '18', 'rd', '98', 'ba', '01'}, 'dice_similarity': 0.5}, {'uid': '97775', 'actual_two_grams': ['de', 'el', 'll', 'la', 'ar', 'ro', 'oo', 'on', 'ne', 'ey', 'y1', '12', '25', '52', '20', '00', '00'], 'predicted_two_grams': {'ar', '00', '12', 'el', '02', '22', '20'}, 'dice_similarity': 0.4348}, {'uid': '84996', 'actual_two_grams': ['jo', 'oe', 'el', 'lr', 'ro', 'ol', 'lf', 'fe', 'es', 's4', '41', '15', '51', '19', '96', '61'], 'predicted_two_grams': {'51', 'ol', '19', 'jo', '96'}, 'dice_similarity': 0.4762}, {'uid': '15958', 'actual_two_grams': ['sh', 'ha', 'ar', 'ro', 'on', 'nm', 'ma', 'ar', 'rt', 'ti', 'in', 'ne', 'ez', 'z3', '31', '11', '11', '19', '95', '53'], 'predicted_two_grams': {'ar', 'in', 'ha', 'ti', '19', 'on', 'rt', '95', '31', 'ma', '11', 'ez', 'ne'}, 'dice_similarity': 0.8387}, {'uid': '83246', 'actual_two_grams': ['jo', 'os', 'se', 'ep', 'ph', 'hh', 'ha', 'ar', 'rp', 'pe', 'er', 'r3', '34', '41', '19', '95', '58'], 'predicted_two_grams': {'os', 'ar', '19', 'jo', '95', 'ep', '76', 'se'}, 'dice_similarity': 0.56}, {'uid': '22411', 'actual_two_grams': ['ha', 'ar', 'ro', 'ol', 'ld', 'dn', 'ne', 'el', 'ls', 'so', 'on', 'n7', '71', '19', '91', '19', '98', '82'], 'predicted_two_grams': {'27', 'ol', 'ar', 'ha', '19', '71', 'ld', 'on', 'ro', 'el', '98', 'so'}, 'dice_similarity': 0.7586}, {'uid': '23663', 'actual_two_grams': ['ar', 'rt', 'th', 'hu', 'ur', 'rm', 'ma', 'ar', 'rt', 'ti', 'in', 'n1', '10', '02', '28', '81', '19', '96', '69'], 'predicted_two_grams': {'10', 'th', 'ar', '61', 'in', 'ti', '19', 'n1', 'li', 'rt', '12', '96', '69', 'ma'}, 'dice_similarity': 0.7097}, {'uid': '58601', 'actual_two_grams': ['es', 'st', 'te', 'el', 'll', 'la', 'as', 'sw', 'we', 'ee', 'et', 't4', '42', '21', '11', '19', '95', '58'], 'predicted_two_grams': {'il', '19', 'es', 'as', '95', 'st', 'el', '11', 'la', 'll', 'we', 'te'}, 'dice_similarity': 0.7333}, {'uid': '22266', 'actual_two_grams': ['ro', 'og', 'ge', 'er', 'rv', 'va', 'ar', 'rg', 'ga', 'as', 's3', '38', '81', '19', '98', '82'], 'predicted_two_grams': {'32', '81', 'ar', 'er', '19', '18', 'ro', '31', 'ge', 'rg', '82', '98'}, 'dice_similarity': 0.6429}, {'uid': '6445', 'actual_two_grams': ['ju', 'ud', 'di', 'it', 'th', 'hc', 'co', 'om', 'mb', 'bs', 's7', '72', '24', '41', '19', '93', '39'], 'predicted_two_grams': {'27', 'th', 'in', '93', '19', 'om'}, 'dice_similarity': 0.3478}, {'uid': '20184', 'actual_two_grams': ['cl', 'la', 'ar', 'ra', 'ah', 'hy', 'ym', 'me', 'es', 's9', '91', '18', '81', '19', '95', '54'], 'predicted_two_grams': {'81', 'ar', '19', 'es', '18', '95', 'la', '91'}, 'dice_similarity': 0.6667}, {'uid': '20835', 'actual_two_grams': ['ra', 'an', 'nd', 'do', 'ol', 'lp', 'ph', 'hm', 'mi', 'il', 'll', 'le', 'er', 'r1', '11', '18', '81', '19', '97', '71'], 'predicted_two_grams': {'81', 'mi', 'il', 'ra', 'er', 'le', '19', 'do', 'an', 'lp', '11', 'll', '97', 'nd', 'r1'}, 'dice_similarity': 0.8571}, {'uid': '47298', 'actual_two_grams': ['am', 'ma', 'an', 'nd', 'da', 'aw', 'wi', 'il', 'ls', 'so', 'on', 'n1', '11', '11', '14', '41', '19', '98', '87'], 'predicted_two_grams': {'il', '41', 'da', '19', 'an', 'on', 'ma', '11', '98', 'so', 'am'}, 'dice_similarity': 0.7586}, {'uid': '34118', 'actual_two_grams': ['jo', 'os', 'sh', 'hu', 'ua', 'ac', 'ca', 'ar', 'rr', 'ri', 'il', 'll', 'lo', 'o7', '71', '13', '31', '19', '96', '68'], 'predicted_two_grams': {'ar', 'il', '19', '31', '96', 'lo', 'la', 'll', 'ca'}, 'dice_similarity': 0.5517}, {'uid': '61745', 'actual_two_grams': ['jo', 'oh', 'hn', 'nb', 'be', 'ea', 'at', 'tt', 'ty', 'y7', '71', '19', '91', '19', '93', '37'], 'predicted_two_grams': {'be', '19', '71'}, 'dice_similarity': 0.3333}, {'uid': '14864', 'actual_two_grams': ['jo', 'on', 'na', 'at', 'th', 'ha', 'an', 'nc', 'ca', 'as', 'se', 'e5', '59', '91', '19', '98', '89'], 'predicted_two_grams': {'th', 'os', 'ho', '19', 'jo', 'an', 'as', '98', '91'}, 'dice_similarity': 0.5385}, {'uid': '68304', 'actual_two_grams': ['ca', 'ar', 'rm', 'me', 'en', 'nj', 'ja', 'am', 'me', 'es', 's6', '61', '13', '31', '19', '97', '70'], 'predicted_two_grams': {'ar', '19', 'es', '31', 'me', 'ja', '97', 'am'}, 'dice_similarity': 0.6667}, {'uid': '15077', 'actual_two_grams': ['to', 'om', 'mm', 'my', 'yf', 'fo', 'ol', 'ls', 'so', 'om', 'm2', '29', '91', '19', '98', '81'], 'predicted_two_grams': {'ho', '19', 'on', '98', 'so', '91'}, 'dice_similarity': 0.381}, {'uid': '96339', 'actual_two_grams': ['tr', 'ro', 'oy', 'yj', 'je', 'en', 'nn', 'ni', 'in', 'ng', 'gs', 's5', '52', '22', '21', '19', '98', '88'], 'predicted_two_grams': {'in', '19', 'li', 'oy', 'ro', '21', '98', 'en', '22', 'if', 'ni'}, 'dice_similarity': 0.6207}, {'uid': '85068', 'actual_two_grams': ['cr', 'ri', 'is', 'st', 'ti', 'in', 'na', 'am', 'mo', 'oh', 'hr', 'r1', '13', '31', '19', '98', '85'], 'predicted_two_grams': {'ri', 'in', '19', 'li', 'st', '31', '11', '98', 'is'}, 'dice_similarity': 0.5385}, {'uid': '23134', 'actual_two_grams': ['te', 'er', 're', 'es', 'sa', 'ad', 'do', 'ol', 'le', 'es', 's4', '41', '11', '19', '96', '66'], 'predicted_two_grams': {'41', 'le', '19', 're', 'es', '96'}, 'dice_similarity': 0.5714}, {'uid': '44863', 'actual_two_grams': ['ma', 'ar', 'rj', 'jo', 'or', 'ri', 'ie', 'ek', 'ko', 'ov', 'va', 'ar', 'r6', '61', '18', '81', '19', '93', '38'], 'predicted_two_grams': {'38', '81', 'ar', 'ri', '93', '19', 'or', 'an', 'ma', 'mo'}, 'dice_similarity': 0.5714}, {'uid': '43574', 'actual_two_grams': ['vi', 'ir', 'rg', 'gi', 'il', 'll', 'la', 'ar', 'rs', 'so', 'on', 'n3', '31', '13', '31', '19', '93', '37'], 'predicted_two_grams': {'n3', 'vi', 'ar', 'il', '93', '19', 'on', '31', 'la', 'll', 'so'}, 'dice_similarity': 0.7857}, {'uid': '64755', 'actual_two_grams': ['ri', 'ic', 'ch', 'ha', 'ar', 'rd', 'db', 'br', 'ro', 'ow', 'wn', 'n8', '81', '19', '91', '19', '93', '37'], 'predicted_two_grams': {'ar', 'ic', 'ri', 'ha', 'br', 'ow', '19', '93', 'ro', 'rd', 'ch'}, 'dice_similarity': 0.7857}, {'uid': '3812', 'actual_two_grams': ['pa', 'au', 'ul', 'lv', 'va', 'al', 'le', 'er', 'ra', 'a1', '10', '01', '12', '21', '19', '97', '71'], 'predicted_two_grams': {'10', 'ul', '01', 'au', 'ra', 'er', '19', 'ld', '12', 'al', 'pa'}, 'dice_similarity': 0.7143}, {'uid': '89066', 'actual_two_grams': ['sa', 'am', 'ma', 'an', 'nt', 'th', 'ha', 'as', 'sh', 'ho', 'oe', 'em', 'ma', 'ak', 'ke', 'e2', '21', '11', '19', '98', '87'], 'predicted_two_grams': {'th', 'ho', 'sa', '19', 'an', 'as', 'sh', 'om', 'ma', '11', '21', '98'}, 'dice_similarity': 0.6875}, {'uid': '37697', 'actual_two_grams': ['el', 'll', 'la', 'ap', 'pr', 'ro', 'ov', 've', 'en', 'nc', 'ca', 'al', 'l1', '11', '11', '11', '19', '99', '92'], 'predicted_two_grams': {'il', '19', 'el', 'l1', '11', 'la', 'll', '99', 'al', 'en'}, 'dice_similarity': 0.6667}, {'uid': '49542', 'actual_two_grams': ['ca', 'ar', 'ro', 'ol', 'li', 'in', 'ne', 'ek', 'kl', 'li', 'in', 'ne', 'e1', '12', '26', '61', '19', '95', '50'], 'predicted_two_grams': {'ar', 'in', 'ti', '19', 'li', '12', '95', 'ro', '21', 'ne'}, 'dice_similarity': 0.6154}, {'uid': '5136', 'actual_two_grams': ['ka', 'at', 'tr', 'ri', 'in', 'na', 'ab', 'bu', 'ur', 'rt', 'to', 'on', 'n1', '11', '11', '19', '91', '19', '98', '80'], 'predicted_two_grams': {'ur', 'to', 'ri', 'in', '19', 'bu', 'on', 'rt', '12', '11', '98', 'tr', 'pa', 'at'}, 'dice_similarity': 0.75}, {'uid': '34091', 'actual_two_grams': ['po', 'ol', 'll', 'ly', 'yr', 'ri', 'id', 'dl', 'lo', 'on', 'n1', '12', '22', '22', '20', '00', '02'], 'predicted_two_grams': {'ol', 'il', '00', 'n1', '12', '11', 'll', '21', '02', '22', '62', '20'}, 'dice_similarity': 0.5714}, {'uid': '23851', 'actual_two_grams': ['ag', 'gn', 'ne', 'es', 'sc', 'ca', 'am', 'mp', 'p5', '56', '61', '19', '99', '91'], 'predicted_two_grams': {'51', '61', 'ag', '19', 'es', '99', 'ja', 'am', 'ne'}, 'dice_similarity': 0.6087}, {'uid': '62063', 'actual_two_grams': ['tr', 'ra', 'ac', 'ci', 'ie', 'er', 'ro', 'ow', 'wa', 'an', 'n2', '22', '21', '11', '19', '93', '37'], 'predicted_two_grams': {'yb', '93', 'er', '19', 'ro', '11', '21', '22'}, 'dice_similarity': 0.56}, {'uid': '56822', 'actual_two_grams': ['ch', 'hr', 'ri', 'is', 'st', 'ti', 'in', 'ne', 'es', 'sh', 'he', 'er', 'rw', 'wo', 'oo', 'od', 'd8', '81', '13', '31', '19', '96', '60'], 'predicted_two_grams': {'ri', 'in', 'he', 'er', 'ha', '19', 'st', '96', 'ch'}, 'dice_similarity': 0.5}, {'uid': '88811', 'actual_two_grams': ['lu', 'ui', 'is', 'sw', 'wh', 'hi', 'it', 'te', 'e7', '72', '20', '01', '19', '94', '47'], 'predicted_two_grams': {'19', '01', '94', '42'}, 'dice_similarity': 0.3158}, {'uid': '97782', 'actual_two_grams': ['da', 'av', 'vi', 'id', 'dw', 'wi', 'il', 'll', 'li', 'ia', 'am', 'ms', 's1', '11', '13', '30', '01', '19', '96', '68'], 'predicted_two_grams': {'vi', 'il', 'da', '19', 'ia', 'li', 'wi', 'dw', '31', 'll', 'am', '01', 's1', 'av'}, 'dice_similarity': 0.7647}, {'uid': '355', 'actual_two_grams': ['cl', 'la', 'au', 'ud', 'di', 'ia', 'am', 'mo', 'or', 'ra', 'al', 'le', 'es', 's4', '42', '29', '91', '19', '96', '62'], 'predicted_two_grams': {'29', 'au', 'ra', 'le', '19', '91', 'es', 'cl', 'la', '62'}, 'dice_similarity': 0.6667}, {'uid': '48558', 'actual_two_grams': ['mi', 'ic', 'ch', 'he', 'el', 'le', 'es', 'sa', 'au', 'un', 'nd', 'de', 'er', 'rs', 's9', '96', '61', '19', '95', '54'], 'predicted_two_grams': {'mi', '61', 'he', 'er', 'le', '19', 'es', '95', 'de', 'el', 'ch'}, 'dice_similarity': 0.7097}, {'uid': '59175', 'actual_two_grams': ['ja', 'am', 'me', 'es', 'sh', 'hi', 'il', 'll', 'l3', '32', '24', '41', '19', '98', '80'], 'predicted_two_grams': {'il', '19', 'es', 'me', 'ja', 'll', '98', 'am'}, 'dice_similarity': 0.6957}, {'uid': '76710', 'actual_two_grams': ['he', 'er', 'rm', 'ma', 'an', 'nt', 'th', 'ho', 'om', 'ma', 'as', 's1', '11', '12', '28', '81', '19', '93', '38'], 'predicted_two_grams': {'th', 'ho', '93', '19', 'do', 'an', 'as', 'ma', '11', 's1'}, 'dice_similarity': 0.6429}, {'uid': '45611', 'actual_two_grams': ['li', 'in', 'nd', 'da', 'ae', 'en', 'ng', 'ge', 'el', 'lh', 'ha', 'ar', 'rd', 'dt', 't3', '31', '13', '32', '20', '00', '01'], 'predicted_two_grams': {'ar', 'in', 'ha', 'da', '00', '31', 'el', 'rd', '13', 'en', '20'}, 'dice_similarity': 0.6875}, {'uid': '74296', 'actual_two_grams': ['ho', 'ol', 'll', 'ly', 'yh', 'ho', 'oy', 'yt', 't5', '51', '16', '61', '19', '93', '39'], 'predicted_two_grams': {'ol', 'ho', '61', '93', '19', '16', 'll'}, 'dice_similarity': 0.6667}, {'uid': '57644', 'actual_two_grams': ['wi', 'il', 'lb', 'bu', 'ur', 'ry', 'yo', 'od', 'de', 'er', 'r9', '91', '16', '61', '19', '96', '61'], 'predicted_two_grams': {'61', 'il', 've', 'er', '19', '96', '91'}, 'dice_similarity': 0.5217}, {'uid': '53716', 'actual_two_grams': ['du', 'us', 'st', 'ti', 'in', 'nr', 'ru', 'ut', 'tz', 'z9', '91', '11', '11', '19', '98', '81'], 'predicted_two_grams': {'us', 'in', 'ti', '19', 'do', '12', 'st', '11', '98', '91'}, 'dice_similarity': 0.64}, {'uid': '18121', 'actual_two_grams': ['ly', 'yn', 'nn', 'nh', 'hi', 'il', 'll', 'lm', 'ma', 'an', 'n1', '11', '12', '26', '61', '19', '97', '78'], 'predicted_two_grams': {'61', 'il', 've', '19', 'n1', 'an', 'hi', 'ma', '11', 'll', '78', '97', 'nn'}, 'dice_similarity': 0.7742}, {'uid': '69208', 'actual_two_grams': ['je', 'en', 'nn', 'ni', 'if', 'fe', 'er', 'rr', 'ro', 'om', 'ma', 'an', 'no', 'o6', '61', '11', '19', '99', '99'], 'predicted_two_grams': {'ie', '61', 'er', '19', 'an', 'ro', 'je', '99', '11', 'en', 'nn', 'ni'}, 'dice_similarity': 0.7333}, {'uid': '63775', 'actual_two_grams': ['an', 'nt', 'th', 'ho', 'on', 'ny', 'yo', 'ov', 've', 'er', 'rt', 'to', 'on', 'n9', '93', '31', '19', '95', '58'], 'predicted_two_grams': {'n3', 'ho', 've', 'er', '19', 'on', 'an', '95', '31', 'yd'}, 'dice_similarity': 0.5714}, {'uid': '30463', 'actual_two_grams': ['ma', 'ar', 'rk', 'kd', 'du', 'un', 'nn', 'n4', '41', '15', '51', '19', '95', '59'], 'predicted_two_grams': {'51', 'ar', '19', '95', 'ma', 'rk'}, 'dice_similarity': 0.6}, {'uid': '41936', 'actual_two_grams': ['fr', 're', 'ed', 'dm', 'mc', 'cc', 'cl', 'lu', 'ur', 're', 'e1', '11', '18', '81', '19', '97', '72'], 'predicted_two_grams': {'81', 're', '19', '11', '97'}, 'dice_similarity': 0.4762}, {'uid': '24989', 'actual_two_grams': ['li', 'in', 'nd', 'da', 'aj', 'jo', 'on', 'ne', 'es', 's8', '82', '21', '11', '19', '98', '80'], 'predicted_two_grams': {'in', 'da', '19', 'on', '21', '98', 'ne'}, 'dice_similarity': 0.6087}, {'uid': '77547', 'actual_two_grams': ['da', 'an', 'ni', 'ie', 'el', 'lm', 'mi', 'it', 'tc', 'ch', 'he', 'el', 'll', 'l8', '81', '11', '11', '19', '94', '44'], 'predicted_two_grams': {'ie', 'mi', 'tc', 'he', '94', '19', 'an', '45', 'it', 'el', '11', 'll', 'ch', 'ni'}, 'dice_similarity': 0.8125}, {'uid': '63428', 'actual_two_grams': ['am', 'mb', 'be', 'er', 'rg', 'ga', 'as', 'st', 'to', 'on', 'n5', '51', '12', '21', '19', '97', '71'], 'predicted_two_grams': {'to', '71', 'er', '19', 'on', 'ro', 'rg', '21', '97', 'be', 'am'}, 'dice_similarity': 0.7143}, {'uid': '61680', 'actual_two_grams': ['lo', 'og', 'ga', 'an', 'nm', 'ma', 'al', 'lo', 'on', 'ne', 'ey', 'y4', '41', '14', '41', '19', '95', '55'], 'predicted_two_grams': {'55', 'ho', '41', '19', 'an', 'on', '95', 'ma', 'al', 'ne'}, 'dice_similarity': 0.6923}, {'uid': '94663', 'actual_two_grams': ['ma', 'ar', 'rg', 'ga', 'ar', 're', 'et', 'tl', 'la', 'ar', 'rs', 'se', 'en', 'n2', '29', '91', '19', '99', '92'], 'predicted_two_grams': {'29', 'ar', 're', '19', '92', 'rg', 'ma', '99', 'la', 'ga', 'en', '91'}, 'dice_similarity': 0.8276}, {'uid': '63887', 'actual_two_grams': ['am', 'ma', 'an', 'nd', 'da', 'aw', 'wr', 'ri', 'ig', 'gh', 'ht', 't1', '11', '17', '71', '19', '96', '62'], 'predicted_two_grams': {'ri', '71', 'da', '19', 'an', '96', 'ma', '11'}, 'dice_similarity': 0.6154}, {'uid': '31743', 'actual_two_grams': ['li', 'is', 'sa', 'ab', 'bu', 'ug', 'gg', 'gs', 's7', '72', '28', '81', '19', '98', '81'], 'predicted_two_grams': {'81', 'ss', '19', 'li', '98', 'is'}, 'dice_similarity': 0.5}, {'uid': '44791', 'actual_two_grams': ['sh', 'he', 'el', 'li', 'ia', 'as', 'sc', 'co', 'ot', 'tt', 't5', '55', '52', '20', '00', '01'], 'predicted_two_grams': {'tt', 'he', '52', '00', 'li', 'ia', 'as', 'sc', 'sh', '02', '01', 'co', 'ot', '20'}, 'dice_similarity': 0.8667}, {'uid': '65425', 'actual_two_grams': ['ev', 've', 'el', 'ly', 'yn', 'nn', 'ne', 'el', 'ls', 'so', 'on', 'n7', '72', '28', '81', '19', '98', '89'], 'predicted_two_grams': {'81', 've', '19', 'ev', 'on', 'el', 'ly', '98', 'nn'}, 'dice_similarity': 0.6923}, {'uid': '77272', 'actual_two_grams': ['pa', 'am', 'me', 'el', 'la', 'al', 'le', 'ee', 'e2', '21', '13', '31', '19', '94', '42'], 'predicted_two_grams': {'94', '19', 'le', 'el', 'la', 'al'}, 'dice_similarity': 0.5714}, {'uid': '72100', 'actual_two_grams': ['he', 'er', 'rm', 'ma', 'an', 'nz', 'zi', 'ie', 'em', 'me', 'er', 'r3', '33', '31', '19', '95', '52'], 'predicted_two_grams': {'ie', 'er', '19', 'an', '95', '31', 'ma', '13'}, 'dice_similarity': 0.5833}, {'uid': '6000', 'actual_two_grams': ['de', 'en', 'ni', 'is', 'sh', 'ha', 'ab', 'bi', 'ib', 'bl', 'le', 'e7', '74', '41', '19', '96', '64'], 'predicted_two_grams': {'72', 'ha', 'bo', 'le', '19', '41', '96', 'de', 'en', '64', 'is'}, 'dice_similarity': 0.6429}, {'uid': '78301', 'actual_two_grams': ['ma', 'at', 'tt', 'th', 'he', 'ew', 'wv', 'vi', 'il', 'll', 'la', 'ar', 'rr', 're', 'ea', 'al', 'l1', '11', '12', '29', '91', '19', '94', '44'], 'predicted_two_grams': {'th', 'ar', 'il', '94', '19', '12', 'l1', 'ma', '11', 'la', 'll', 'al', '91'}, 'dice_similarity': 0.7027}, {'uid': '7867', 'actual_two_grams': ['da', 'an', 'ni', 'ie', 'el', 'lr', 'ro', 'om', 'ma', 'an', 'no', 'o1', '10', '05', '52', '20', '00', '01'], 'predicted_two_grams': {'10', 'da', '00', '19', 'n1', 'an', 'ro', 'el', 'ma', '02', '01', 'ni', '20'}, 'dice_similarity': 0.6667}, {'uid': '81389', 'actual_two_grams': ['jo', 'oe', 'ed', 'do', 'ob', 'bb', 'bi', 'in', 'ns', 's6', '64', '41', '19', '96', '67'], 'predicted_two_grams': {'61', 'in', '41', '19', 'bb', 'on', '96'}, 'dice_similarity': 0.4545}, {'uid': '19596', 'actual_two_grams': ['ni', 'ic', 'ch', 'ho', 'ol', 'la', 'as', 'sb', 'ba', 'ak', 'ke', 'er', 'r3', '31', '15', '51', '19', '97', '75'], 'predicted_two_grams': {'51', 'ho', 'ic', 'ha', '19', 'ke', 'as', '31', 'r3', '15', 'la', '97', 'ni'}, 'dice_similarity': 0.75}, {'uid': '92248', 'actual_two_grams': ['da', 'av', 'vi', 'id', 'dr', 'ri', 'ic', 'ch', 'ha', 'ar', 'rd', 'ds', 'so', 'on', 'n5', '52', '23', '31', '19', '97', '75'], 'predicted_two_grams': {'51', 'ar', 'ic', 'ri', 'ha', 'da', '19', 'on', '23', '31', '97', 'dd', 'id', 'so', 'av'}, 'dice_similarity': 0.7222}, {'uid': '55766', 'actual_two_grams': ['jo', 'oh', 'hn', 'ns', 'st', 'tu', 'ur', 'rg', 'ge', 'es', 's8', '82', '27', '71', '19', '94', '46'], 'predicted_two_grams': {'27', '71', '19', '94', 'es', 'jo', 'ns'}, 'dice_similarity': 0.5833}, {'uid': '27054', 'actual_two_grams': ['pa', 'am', 'me', 'el', 'la', 'ac', 'co', 'or', 'rt', 't1', '11', '12', '20', '01', '19', '99', '98'], 'predicted_two_grams': {'19', '12', 'ac', 'me', 'el', '11', 'la', '98', '01', 'co'}, 'dice_similarity': 0.7407}, {'uid': '92952', 'actual_two_grams': ['aa', 'ar', 'ro', 'on', 'ns', 'sm', 'mi', 'it', 'th', 'hs', 'so', 'on', 'n3', '32', '21', '11', '19', '99', '90'], 'predicted_two_grams': {'32', 'th', 'mi', 'n3', 'ar', '19', 'on', '23', 'it', 'ro', '31', '99', '11', '21', 'ns', 'so'}, 'dice_similarity': 0.8235}, {'uid': '65142', 'actual_two_grams': ['an', 'nn', 'ni', 'ie', 'eh', 'hy', 'yd', 'de', 'e4', '42', '23', '31', '19', '94', '49'], 'predicted_two_grams': {'ie', 'eh', '94', '19', 'an', '42', 'nn', 'ni'}, 'dice_similarity': 0.6957}, {'uid': '52314', 'actual_two_grams': ['ja', 'am', 'me', 'es', 'sc', 'cu', 'um', 'mm', 'mi', 'in', 'ng', 'gs', 's1', '13', '31', '19', '99', '95'], 'predicted_two_grams': {'in', '19', 'es', '31', '99', 'ja', 'am'}, 'dice_similarity': 0.56}, {'uid': '49197', 'actual_two_grams': ['sa', 'am', 'mu', 'ue', 'el', 'lb', 'bo', 'oc', 'ck', 'k7', '71', '10', '01', '19', '96', '64'], 'predicted_two_grams': {'10', 'sa', '71', 'bo', '19', 'li', '96', 'me', 'el', '01', '64', 'am'}, 'dice_similarity': 0.7143}, {'uid': '48470', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'mj', 'jo', 'on', 'ne', 'es', 's6', '63', '30', '01', '19', '97', '73'], 'predicted_two_grams': {'30', 'il', '73', '19', 'es', 'li', 'ia', 'on', 'wi', 'll', '97', '63', '01', 'am'}, 'dice_similarity': 0.875}, {'uid': '71655', 'actual_two_grams': ['do', 'ol', 'lo', 'or', 're', 'es', 'sd', 'do', 'ou', 'ug', 'gl', 'la', 'as', 's1', '12', '25', '51', '19', '99', '99'], 'predicted_two_grams': {'gl', '93', '19', 'ug', 'or', 'es', 'do', 'as', 'la', 'ou'}, 'dice_similarity': 0.6429}, {'uid': '32326', 'actual_two_grams': ['jo', 'os', 'se', 'ep', 'ph', 'hb', 'br', 'ro', 'oo', 'ok', 'ks', 's6', '61', '10', '01', '19', '96', '61'], 'predicted_two_grams': {'10', 'os', '61', 'ph', 'br', '19', 'jo', 'ro', '96', 'ep', '01', 'cr', 'se'}, 'dice_similarity': 0.8}, {'uid': '58834', 'actual_two_grams': ['sa', 'am', 'ma', 'an', 'nt', 'th', 'ha', 'ap', 'pa', 'ar', 'rk', 'ke', 'er', 'r1', '11', '12', '25', '51', '19', '94', '43'], 'predicted_two_grams': {'th', '51', 'ar', '94', 'er', '19', 'an', '12', '43', 'ma', '11', 'ba', 'r1'}, 'dice_similarity': 0.7059}, {'uid': '16736', 'actual_two_grams': ['je', 'es', 'ss', 'se', 'ef', 'fi', 'ia', 'al', 'la', 'a1', '11', '16', '61', '19', '96', '61'], 'predicted_two_grams': {'61', 'ra', '26', '19', '96', 'al'}, 'dice_similarity': 0.381}, {'uid': '8959', 'actual_two_grams': ['mi', 'ic', 'ch', 'he', 'el', 'll', 'le', 'eh', 'hu', 'us', 'sb', 'ba', 'an', 'nd', 'd1', '10', '01', '11', '19', '94', '46'], 'predicted_two_grams': {'10', 'mi', 'ae', '94', 'le', '19', '43', 'el', 'ba', '01', 'ch'}, 'dice_similarity': 0.5625}, {'uid': '75074', 'actual_two_grams': ['ed', 'dn', 'na', 'ag', 'gr', 'ra', 'av', 've', 'es', 's4', '41', '15', '51', '19', '93', '37'], 'predicted_two_grams': {'51', 'ra', 'ag', '19', 'gr', '41', 'es'}, 'dice_similarity': 0.6087}, {'uid': '8237', 'actual_two_grams': ['ad', 'dr', 'ri', 'ia', 'an', 'np', 'pa', 'at', 'tt', 't9', '91', '13', '31', '19', '98', '83'], 'predicted_two_grams': {'tt', 'ri', '19', 'ad', 'an', '31', '13', 'tr', 'at'}, 'dice_similarity': 0.64}, {'uid': '15011', 'actual_two_grams': ['er', 'ri', 'in', 'nh', 'he', 'ep', 'pw', 'wo', 'or', 'rt', 'th', 'h4', '42', '28', '81', '19', '99', '92'], 'predicted_two_grams': {'th', 'in', 'er', '19', '99'}, 'dice_similarity': 0.4348}, {'uid': '46067', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'mg', 'gr', 're', 'eg', 'go', 'or', 'ry', 'y1', '10', '02', '20', '01', '19', '96', '66'], 'predicted_two_grams': {'10', 'ms', 'il', '19', 'or', 'li', 'ia', 'wi', '96', 'lo', 'll', '01', 'am', '20'}, 'dice_similarity': 0.6857}, {'uid': '39600', 'actual_two_grams': ['al', 'lf', 'fr', 're', 'ed', 'do', 'oy', 'yo', 'ou', 'un', 'ng', 'g1', '12', '23', '31', '19', '94', '48'], 'predicted_two_grams': {'94', '19', '31', '11', 'al'}, 'dice_similarity': 0.3478}, {'uid': '87889', 'actual_two_grams': ['ja', 'ay', 'ym', 'ma', 'ar', 'rr', 'ri', 'io', 'ot', 'tt', 't2', '21', '16', '61', '19', '95', '50'], 'predicted_two_grams': {'ar', '61', 'ri', '19', '95', 'ma'}, 'dice_similarity': 0.5217}, {'uid': '32155', 'actual_two_grams': ['li', 'il', 'll', 'li', 'ia', 'an', 'nc', 'co', 'ol', 'll', 'li', 'in', 'ns', 's6', '61', '18', '81', '19', '93', '38'], 'predicted_two_grams': {'37', '38', '81', 'in', '93', '19', 'ia', 'an', 'li', 'la', 'll', 'ns', 'co'}, 'dice_similarity': 0.7333}, {'uid': '24821', 'actual_two_grams': ['ed', 'di', 'it', 'th', 'hr', 'ro', 'oc', 'ck', 'k1', '11', '13', '30', '01', '19', '97', '77'], 'predicted_two_grams': {'30', 'di', 'th', 'ck', '19', 'ke', 'ro', 'it', '11', '97', '01'}, 'dice_similarity': 0.7407}, {'uid': '14742', 'actual_two_grams': ['ar', 'rm', 'ma', 'an', 'nd', 'do', 'om', 'mc', 'ck', 'ka', 'ay', 'y9', '99', '91', '19', '98', '81'], 'predicted_two_grams': {'ar', '19', 'an', 'ma', '98', '91', 'nd'}, 'dice_similarity': 0.5833}, {'uid': '43589', 'actual_two_grams': ['sh', 'he', 'er', 'rr', 'ry', 'ys', 'st', 'te', 'er', 'rn', 'nb', 'be', 'er', 'rg', 'g4', '41', '13', '31', '19', '98', '85'], 'predicted_two_grams': {'ar', '94', 'er', '19', 'rg', 'ry', '98', 'te'}, 'dice_similarity': 0.4444}, {'uid': '31765', 'actual_two_grams': ['le', 'ew', 'wi', 'is', 'sb', 'be', 'el', 'll', 'l5', '55', '51', '19', '97', '77'], 'predicted_two_grams': {'51', 'le', '19', 'li', 'el', 'ew', 'll', '97', 'is'}, 'dice_similarity': 0.6957}, {'uid': '77287', 'actual_two_grams': ['ke', 'ev', 've', 'en', 'ns', 'si', 'im', 'ms', 's1', '11', '11', '11', '19', '98', '86'], 'predicted_two_grams': {'ve', '19', 'ev', 'ke', 'ly', '11', 'ee', '98', 'en', 'ns', 's1'}, 'dice_similarity': 0.75}, {'uid': '37561', 'actual_two_grams': ['ar', 'rm', 'ma', 'an', 'nd', 'do', 'os', 'se', 'et', 'to', 'o8', '83', '31', '11', '19', '95', '51'], 'predicted_two_grams': {'ar', '19', 'an', '95', '31', '11', 'ma', 'se'}, 'dice_similarity': 0.64}, {'uid': '80997', 'actual_two_grams': ['je', 'ef', 'ff', 'fr', 're', 'ey', 'ya', 'ag', 'gu', 'ui', 'ir', 'rr', 're', 'e4', '41', '11', '19', '95', '55'], 'predicted_two_grams': {'ag', 're', '19', 'gr', '95'}, 'dice_similarity': 0.3478}, {'uid': '96819', 'actual_two_grams': ['je', 'er', 'rr', 'ry', 'yb', 'br', 'ra', 'an', 'nt', 'tl', 'le', 'ey', 'y8', '83', '31', '19', '96', '66'], 'predicted_two_grams': {'er', 'le', 'bu', '19', 'an', '31', '96', 'tl', 'ry', '66'}, 'dice_similarity': 0.6429}, {'uid': '38882', 'actual_two_grams': ['la', 'ar', 'rr', 'ry', 'yd', 'di', 'ia', 'az', 'z9', '96', '61', '19', '94', '47'], 'predicted_two_grams': {'ar', '61', '94', '19', 'la', 'ry', '91'}, 'dice_similarity': 0.5714}, {'uid': '72533', 'actual_two_grams': ['ma', 'ar', 'rk', 'ko', 'ol', 'la', 'ag', 'gu', 'ue', 'e1', '12', '23', '31', '19', '95', '52'], 'predicted_two_grams': {'ar', 'ag', '19', '12', '95', '31', 'ma', '11', 'la', 'rk', '13'}, 'dice_similarity': 0.6667}, {'uid': '91182', 'actual_two_grams': ['ma', 'ar', 'rl', 'le', 'en', 'ne', 'ek', 'ki', 'il', 'lg', 'go', 'or', 're', 'e7', '75', '51', '19', '99', '95'], 'predicted_two_grams': {'51', 'ar', 're', 'le', '19', '71', '95', '99', 'ma', 'en', 'ne'}, 'dice_similarity': 0.6667}, {'uid': '46581', 'actual_two_grams': ['ju', 'ul', 'li', 'im', 'mc', 'cd', 'da', 'an', 'ni', 'ie', 'el', 'l1', '15', '51', '19', '95', '59'], 'predicted_two_grams': {'51', 'ie', '19', 'li', '95', 'el', '11', 'll', '59', 'ni'}, 'dice_similarity': 0.5926}, {'uid': '58620', 'actual_two_grams': ['es', 'st', 'th', 'he', 'er', 'rr', 'ro', 'ou', 'us', 'se', 'e1', '11', '11', '18', '81', '19', '95', '58'], 'predicted_two_grams': {'th', '81', 'he', '93', 'er', '19', '18', '58', '95', '11', 'ot'}, 'dice_similarity': 0.6429}, {'uid': '89896', 'actual_two_grams': ['do', 'on', 'ns', 'sm', 'mi', 'it', 'th', 'h4', '41', '15', '51', '19', '93', '37'], 'predicted_two_grams': {'th', 'mi', '51', '93', '19', 'or', 'do', 'on', 'it', 'ns', '15', 'sm'}, 'dice_similarity': 0.8462}, {'uid': '1131', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'mb', 'ba', 'ar', 'rr', 'ro', 'ow', 'w6', '62', '24', '41', '19', '95', '52'], 'predicted_two_grams': {'ar', 'il', 'ow', '19', 'li', 'ia', 'wi', 'ro', '95', 'll', 'am'}, 'dice_similarity': 0.7333}, {'uid': '1465', 'actual_two_grams': ['gr', 're', 'eg', 'go', 'or', 'ri', 'io', 'op', 'pa', 'ar', 'rk', 'ke', 'er', 'r2', '21', '14', '41', '19', '99', '98'], 'predicted_two_grams': {'ar', 'ri', '41', '19', 'or', 'ge', '99', '21', '98'}, 'dice_similarity': 0.5517}, {'uid': '58465', 'actual_two_grams': ['ed', 'dw', 'wi', 'in', 'nr', 'ri', 'iv', 've', 'er', 'ra', 'a1', '12', '23', '31', '11', '19', '96', '63'], 'predicted_two_grams': {'ri', 'ra', 'in', 've', 'ev', '19', 'do', '12', '96', '11', 'ng'}, 'dice_similarity': 0.5517}, {'uid': '20671', 'actual_two_grams': ['te', 'er', 'rr', 'ry', 'yw', 'wa', 'at', 'tk', 'ki', 'in', 'ns', 's1', '12', '22', '22', '21', '19', '96', '66'], 'predicted_two_grams': {'in', '19', '12', '96', 'ry', '21', '22', '66'}, 'dice_similarity': 0.6154}, {'uid': '14212', 'actual_two_grams': ['do', 'on', 'nn', 'na', 'ak', 'kr', 'ri', 'ie', 'eg', 'g1', '11', '12', '21', '19', '94', '44'], 'predicted_two_grams': {'ri', '94', '19', 'do', 'on', 'an', '12', 'ge', '11', '21'}, 'dice_similarity': 0.6154}, {'uid': '64213', 'actual_two_grams': ['de', 'el', 'll', 'la', 'am', 'ma', 'ar', 'rt', 'ti', 'in', 'n2', '21', '11', '19', '96', '63'], 'predicted_two_grams': {'ar', 'in', '19', 'li', '96', 'el', 'ma', '11', 'la', 'll', 'am'}, 'dice_similarity': 0.7407}, {'uid': '22173', 'actual_two_grams': ['ja', 'ac', 'ck', 'kp', 'pi', 'ie', 'er', 'rc', 'ce', 'e4', '41', '11', '11', '19', '98', '84'], 'predicted_two_grams': {'ie', 'ck', 'ce', 'rc', 'er', '19', '84', 'ac', 'je', '11', '98'}, 'dice_similarity': 0.7692}, {'uid': '31833', 'actual_two_grams': ['li', 'il', 'll', 'li', 'ia', 'an', 'na', 'al', 'll', 'le', 'en', 'n8', '82', '23', '31', '19', '93', '39'], 'predicted_two_grams': {'il', '93', 'le', '19', 'ia', 'an', 'li', 'na', 'll', 'al', 'en'}, 'dice_similarity': 0.8148}, {'uid': '32542', 'actual_two_grams': ['lu', 'uc', 'cy', 'yr', 'ra', 'ay', 'yb', 'bu', 'ur', 'rn', 'n9', '91', '19', '91', '19', '99', '99'], 'predicted_two_grams': {'ur', 'ar', 'au', '19', 'bu', '99', 'la', '91'}, 'dice_similarity': 0.4545}, {'uid': '83494', 'actual_two_grams': ['jo', 'on', 'na', 'ah', 'hj', 'jo', 'on', 'ne', 'es', 's1', '12', '22', '25', '51', '19', '93', '37'], 'predicted_two_grams': {'51', '25', '93', '19', 'es', 'on', 'jo', 'na', '12', '21', '22', 'ne'}, 'dice_similarity': 0.8148}, {'uid': '63404', 'actual_two_grams': ['ir', 'ri', 'is', 'sw', 'wi', 'il', 'll', 'li', 'ia', 'am', 'ms', 's6', '65', '51', '19', '95', '52'], 'predicted_two_grams': {'51', 'ri', 'il', '52', '19', 'li', 'ia', 'wi', '95', 'll', 'am'}, 'dice_similarity': 0.7857}, {'uid': '71211', 'actual_two_grams': ['to', 'om', 'mh', 'ha', 'ar', 'rr', 'ri', 'is', 'so', 'on', 'n2', '22', '25', '51', '19', '96', '69'], 'predicted_two_grams': {'ck', 'ic', 'ar', 'ri', '19', 'on', '96', '69', 'is'}, 'dice_similarity': 0.5385}, {'uid': '40985', 'actual_two_grams': ['ry', 'ya', 'an', 'nb', 'bo', 'ou', 'ur', 'rg', 'ge', 'et', 't2', '27', '71', '19', '95', '57'], 'predicted_two_grams': {'ya', '71', '19', 'or', 'an', '95', 'ge', 'rg', 'ry', 'ou'}, 'dice_similarity': 0.6923}, {'uid': '85617', 'actual_two_grams': ['da', 'av', 'vi', 'id', 'dl', 'la', 'aw', 'ws', 'so', 'on', 'n7', '75', '51', '19', '99', '91'], 'predicted_two_grams': {'51', 'vi', 'n7', '71', 'da', '19', 'on', 'la', 'id', 'so', 'av'}, 'dice_similarity': 0.7407}, {'uid': '36896', 'actual_two_grams': ['di', 'iv', 'vi', 'in', 'na', 'ah', 'he', 'en', 'nd', 'de', 'er', 'rs', 'so', 'on', 'n4', '41', '19', '92', '20', '00', '03'], 'predicted_two_grams': {'in', 'er', 'rs', '00', 'on', 'de', 'en', 'so', 'nd', '20'}, 'dice_similarity': 0.6452}, {'uid': '98417', 'actual_two_grams': ['gr', 're', 'et', 'tc', 'ch', 'he', 'en', 'nh', 'ha', 'al', 'll', 'l5', '52', '20', '02', '20', '00', '00'], 'predicted_two_grams': {'ha', 'le', '00', '02', '20', 'll', 'al', 'en'}, 'dice_similarity': 0.5833}, {'uid': '93848', 'actual_two_grams': ['ma', 'ar', 'ri', 'ie', 'ec', 'co', 'or', 'rn', 'nw', 'we', 'el', 'll', 'l1', '12', '21', '11', '19', '95', '54'], 'predicted_two_grams': {'ar', '19', '95', 'el', 'ma', '11', 'll', '21'}, 'dice_similarity': 0.5926}, {'uid': '68451', 'actual_two_grams': ['ma', 'at', 'tt', 'th', 'he', 'ew', 'wb', 'be', 'en', 'na', 'av', 'vi', 'id', 'de', 'es', 's9', '92', '26', '61', '19', '94', '41'], 'predicted_two_grams': {'th', 'tt', '61', 'he', '26', '19', 'ma', 'at'}, 'dice_similarity': 0.5333}, {'uid': '53093', 'actual_two_grams': ['li', 'in', 'nd', 'da', 'av', 've', 'ei', 'ig', 'ga', 'a9', '91', '11', '11', '19', '97', '79'], 'predicted_two_grams': {'ar', 'in', 've', 'da', '19', '79', '11', '97', '91'}, 'dice_similarity': 0.6667}, {'uid': '35136', 'actual_two_grams': ['ju', 'ul', 'li', 'ia', 'at', 'tu', 'ur', 'rn', 'ne', 'er', 'r1', '12', '22', '21', '19', '95', '56'], 'predicted_two_grams': {'ul', 'ur', 'au', 'er', '19', 'ia', 'li', '12', '95', 'tu', 'r1', 'rn'}, 'dice_similarity': 0.7586}, {'uid': '7463', 'actual_two_grams': ['ra', 'aq', 'qu', 'ue', 'el', 'lr', 'ru', 'us', 'ss', 'se', 'el', 'll', 'l9', '95', '51', '19', '98', '84'], 'predicted_two_grams': {'ps', 'ss', 'sa', '19', '85', 'li', 'el', 'ue', 'll', '98', 'se'}, 'dice_similarity': 0.5}, {'uid': '3868', 'actual_two_grams': ['st', 'te', 'ew', 'wa', 'ar', 'rt', 'tk', 'ko', 'ob', 'be', 'er', 'r3', '31', '13', '31', '19', '99', '93'], 'predicted_two_grams': {'tt', 'ty', 'ar', '93', 'er', '19', 'rt', '23', '31', '99', 'be', 'te'}, 'dice_similarity': 0.6207}, {'uid': '57833', 'actual_two_grams': ['re', 'ey', 'yn', 'na', 'al', 'ld', 'do', 'oc', 'ca', 'ab', 'br', 're', 'er', 'ra', 'a1', '10', '01', '18', '82', '20', '00', '00'], 'predicted_two_grams': {'fe', 'ra', 'er', 'le', 'ld', 'do', '00', '20', 'ey', 'al', '01', '02'}, 'dice_similarity': 0.5625}, {'uid': '47981', 'actual_two_grams': ['le', 'ee', 'ew', 'we', 'el', 'll', 'ls', 's5', '52', '29', '91', '19', '93', '39'], 'predicted_two_grams': {'29', 'le', '19', 'el', 'we', 'll', '91'}, 'dice_similarity': 0.6667}, {'uid': '45199', 'actual_two_grams': ['ma', 'ar', 'ri', 'ie', 'eh', 'ha', 'am', 'mb', 'bl', 'li', 'in', 'n8', '81', '10', '01', '19', '98', '87'], 'predicted_two_grams': {'10', 'ar', 'ri', 'in', 'bl', 'ha', '19', 'li', '98', '01', 'am', 'mb'}, 'dice_similarity': 0.8}, {'uid': '58699', 'actual_two_grams': ['fr', 're', 'ed', 'dd', 'di', 'ie', 'ee', 'ed', 'dw', 'wa', 'ar', 'rd', 'ds', 's9', '91', '10', '01', '19', '97', '70'], 'predicted_two_grams': {'10', 'ar', 're', '19', 'ed', 'rd', '97'}, 'dice_similarity': 0.5385}, {'uid': '96261', 'actual_two_grams': ['fr', 're', 'ed', 'dr', 'ra', 'ad', 'dc', 'cl', 'li', 'if', 'ff', 'fe', 'e9', '93', '30', '01', '19', '94', '44'], 'predicted_two_grams': {'30', 'ri', 'ra', 'dr', 'fr', 're', '19', '94', 'an', 'en', '01'}, 'dice_similarity': 0.5333}, {'uid': '61674', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'mr', 'ri', 'ic', 'co', 'o2', '24', '41', '19', '95', '53'], 'predicted_two_grams': {'ri', 'il', '19', 'li', 'ia', 'wi', '95', 'll', 'co', 'am'}, 'dice_similarity': 0.7692}, {'uid': '37354', 'actual_two_grams': ['ju', 'ud', 'dy', 'yj', 'jo', 'oh', 'hn', 'ns', 'so', 'on', 'n5', '52', '22', '21', '19', '98', '86'], 'predicted_two_grams': {'19', '98', 'on', 'jo', 'oh', '21', 'hn', 'ns', 'so', '22'}, 'dice_similarity': 0.7407}, {'uid': '3570', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'ml', 'le', 'es', 'ss', 'sa', 'ar', 'rd', 'd7', '72', '25', '51', '19', '98', '80'], 'predicted_two_grams': {'51', 'ar', 'il', '19', 'li', 'ia', 'wi', 'll', '98', 'am'}, 'dice_similarity': 0.6667}, {'uid': '28187', 'actual_two_grams': ['ma', 'at', 'tt', 'th', 'he', 'ew', 'wp', 'pu', 'ur', 'rs', 'se', 'el', 'll', 'l2', '28', '81', '19', '96', '64'], 'predicted_two_grams': {'th', 'tt', 'he', '19', '96', 'el', 'ma', 'll'}, 'dice_similarity': 0.5926}, {'uid': '69257', 'actual_two_grams': ['ba', 'ar', 'rb', 'ba', 'ar', 'ra', 'ad', 'do', 'os', 'ss', 's8', '81', '19', '92', '20', '00', '02'], 'predicted_two_grams': {'ar', '02', '00', 'ba', '91', '20'}, 'dice_similarity': 0.4762}, {'uid': '72281', 'actual_two_grams': ['al', 'lv', 'vi', 'in', 'nc', 'cl', 'la', 'ar', 'rk', 'k1', '10', '03', '31', '19', '96', '63'], 'predicted_two_grams': {'30', 'ar', 'in', '19', '63', '31', '13', 'la', 'al', '01'}, 'dice_similarity': 0.5385}, {'uid': '52283', 'actual_two_grams': ['re', 'en', 'ne', 'em', 'mi', 'il', 'le', 'es', 's2', '21', '14', '41', '19', '97', '70'], 'predicted_two_grams': {'mi', 'il', 're', 'le', '19', '41', 'es', 'em', '14', 'ee', '97', 'en', 'ne'}, 'dice_similarity': 0.8571}, {'uid': '6680', 'actual_two_grams': ['st', 'te', 'ep', 'ph', 'he', 'en', 'nm', 'me', 'ey', 'ye', 'er', 'r4', '42', '28', '81', '19', '95', '57'], 'predicted_two_grams': {'81', 've', 'er', '19', '95', 'st', 'en'}, 'dice_similarity': 0.48}, {'uid': '44367', 'actual_two_grams': ['be', 'et', 'tt', 'ty', 'yl', 'lo', 'op', 'pp', 'p1', '12', '22', '26', '61', '19', '94', '40'], 'predicted_two_grams': {'pe', 'tt', 'ty', '26', '94', 'et', '19', 'be'}, 'dice_similarity': 0.5833}, {'uid': '28072', 'actual_two_grams': ['ry', 'ya', 'an', 'np', 'pa', 'au', 'ul', 'li', 'in', 'ng', 'g3', '31', '11', '11', '19', '96', '66'], 'predicted_two_grams': {'ul', 'ya', 'in', '19', 'an', '31', '69', 'ah', '96', 'ry', '66', 'ng'}, 'dice_similarity': 0.7143}, {'uid': '85137', 'actual_two_grams': ['an', 'nn', 'ne', 'eu', 'ur', 'rb', 'ba', 'an', 'ns', 'sk', 'ki', 'i2', '22', '28', '81', '19', '98', '82'], 'predicted_two_grams': {'19', '98', 'an', 'nn', '21', '82', 'ns', 'ni'}, 'dice_similarity': 0.48}, {'uid': '88712', 'actual_two_grams': ['ja', 'ar', 're', 'ed', 'de', 'en', 'ng', 'ge', 'eb', 'br', 're', 'et', 'ts', 'so', 'on', 'n9', '92', '22', '21', '19', '96', '60'], 'predicted_two_grams': {'29', 'ar', 're', '19', 'on', '96', 'de', '60', 'en', 'so', '91'}, 'dice_similarity': 0.5625}, {'uid': '69356', 'actual_two_grams': ['ch', 'he', 'er', 'ry', 'yl', 'lr', 're', 'ed', 'dd', 'di', 'in', 'ng', 'g7', '78', '81', '19', '98', '85'], 'predicted_two_grams': {'di', '81', 'in', 're', '19', 'ed', '98', 'ch'}, 'dice_similarity': 0.6154}, {'uid': '55970', 'actual_two_grams': ['de', 'en', 'nn', 'ni', 'is', 'sj', 'ja', 'ac', 'ck', 'ks', 'so', 'on', 'n1', '10', '02', '23', '31', '19', '97', '70'], 'predicted_two_grams': {'ck', '19', 'on', 'ac', '31', 'aj', 'so'}, 'dice_similarity': 0.4444}, {'uid': '24843', 'actual_two_grams': ['fr', 'ra', 'an', 'nk', 'ka', 'al', 'le', 'ex', 'xa', 'an', 'nd', 'de', 'er', 'r8', '81', '10', '01', '19', '99', '96'], 'predicted_two_grams': {'10', 'ra', 'er', 'le', '19', 'an', 'de', '99', 'al', '01', 'nd'}, 'dice_similarity': 0.7333}, {'uid': '42998', 'actual_two_grams': ['wi', 'il', 'll', 'li', 'ia', 'am', 'mt', 'to', 'ow', 'wn', 'nl', 'le', 'ey', 'y8', '83', '31', '19', '96', '65'], 'predicted_two_grams': {'il', '19', 'li', 'ia', 'wi', '31', 'll', 'am'}, 'dice_similarity': 0.5926}, {'uid': '48525', 'actual_two_grams': ['li', 'is', 'sa', 'ad', 'da', 'av', 'vi', 'is', 's8', '82', '23', '32', '20', '00', '01'], 'predicted_two_grams': {'vi', 'da', 'av', '00', 'li', '23', 's3', '31', '02', 'is', '20'}, 'dice_similarity': 0.64}, {'uid': '67990', 'actual_two_grams': ['pe', 'ea', 'ar', 'rl', 'lb', 'br', 'ri', 'it', 'tt', 'to', 'on', 'n6', '62', '21', '19', '95', '53'], 'predicted_two_grams': {'tt', 'ar', 'ri', 'to', 'et', '19', 'on', '95', 'ma', '22'}, 'dice_similarity': 0.5185}, {'uid': '82543', 'actual_two_grams': ['ma', 'ar', 'rg', 'ga', 'ar', 're', 'et', 'td', 'da', 'an', 'nt', 't1', '10', '07', '71', '19', '95', '54'], 'predicted_two_grams': {'10', 'ar', 're', '19', '71', 'an', '95', 'rg', 'ma', 'ga', '01'}, 'dice_similarity': 0.7143}, {'uid': '40924', 'actual_two_grams': ['ma', 'ar', 'rk', 'kb', 'bo', 'oy', 'yd', 'd2', '22', '21', '19', '97', '76'], 'predicted_two_grams': {'ar', 'ri', '19', 'oy', 'ma', 'ry', '21', '97'}, 'dice_similarity': 0.5714}, {'uid': '10074', 'actual_two_grams': ['pa', 'au', 'ul', 'lr', 're', 'en', 'nd', 'do', 'on', 'n1', '16', '61', '19', '97', '72'], 'predicted_two_grams': {'ul', '61', 'au', 're', '19', 'do', 'n1', 'on', '16', 'la', '97', 'pa', '62'}, 'dice_similarity': 0.7857}, {'uid': '18579', 'actual_two_grams': ['do', 'or', 'ri', 'is', 'sg', 'go', 'or', 'rm', 'ma', 'an', 'n2', '21', '10', '01', '19', '94', '45'], 'predicted_two_grams': {'10', 'us', 'ri', '94', '19', 'or', 'do', 'an', 'ma', '01', 'ot'}, 'dice_similarity': 0.6667}, {'uid': '56171', 'actual_two_grams': ['do', 'on', 'nn', 'na', 'ac', 'cu', 'us', 'sh', 'hm', 'ma', 'an', 'n1', '12', '20', '01', '19', '94', '47'], 'predicted_two_grams': {'94', '19', 'do', 'n1', 'on', 'an', 'na', '12', 'ma', '01'}, 'dice_similarity': 0.7143}, {'uid': '47954', 'actual_two_grams': ['ju', 'ud', 'di', 'it', 'th', 'hh', 'ho', 'ou', 'us', 'se', 'er', 'r8', '81', '16', '62', '20', '00', '00'], 'predicted_two_grams': {'di', 'th', 'er', '00', '16', 'eb', '02', '62', '20'}, 'dice_similarity': 0.5385}, {'uid': '52891', 'actual_two_grams': ['be', 'et', 'th', 'hj', 'ja', 'ac', 'ck', 'ks', 'so', 'on', 'n1', '12', '22', '20', '01', '19', '98', '85'], 'predicted_two_grams': {'ck', 'so', 'et', '19', 'n1', 'on', 'ac', '12', 'be', 'ks'}, 'dice_similarity': 0.7143}, {'uid': '11908', 'actual_two_grams': ['je', 'en', 'nn', 'ni', 'if', 'fe', 'er', 'rs', 'so', 'ol', 'lo', 'om', 'mo', 'on', 'n1', '10', '02', '25', '51', '19', '99', '91'], 'predicted_two_grams': {'ns', '10', '51', 'er', '19', 'n1', 'on', 'je', 'en', 'nn', 'so', 'ni'}, 'dice_similarity': 0.6471}, {'uid': '60412', 'actual_two_grams': ['el', 'li', 'iz', 'za', 'ab', 'be', 'et', 'th', 'hd', 'de', 'es', 'sr', 'ro', 'os', 'si', 'ie', 'er', 'rs', 's6', '62', '25', '52', '20', '00', '03'], 'predicted_two_grams': {'th', 'tt', '25', '51', '52', 'et', 'ab', '19', 'li', 'ro', 'sc', 'de', 'eb', 'be', 'co', 'ot', '02'}, 'dice_similarity': 0.4286}, {'uid': '1346', 'actual_two_grams': ['fl', 'lo', 'or', 're', 'en', 'nc', 'ce', 'eb', 'bo', 'os', 'sw', 'we', 'el', 'll', 'l4', '41', '19', '91', '19', '97', '79'], 'predicted_two_grams': {'ce', 'rr', 're', 'bo', '19', 'or', 'el', 'lo', 'll', '97', 'en', '91', 'nc'}, 'dice_similarity': 0.7273}, {'uid': '54060', 'actual_two_grams': ['ea', 'ar', 'rl', 'lw', 'wh', 'ha', 'ar', 'rt', 'to', 'on', 'n6', '69', '91', '19', '97', '73'], 'predicted_two_grams': {'ar', 'ha', '19', 'on', '97'}, 'dice_similarity': 0.5}, {'uid': '1877', 'actual_two_grams': ['wa', 'al', 'll', 'la', 'ac', 'ce', 'eb', 'bl', 'la', 'an', 'nc', 'ch', 'ha', 'ar', 'rd', 'd1', '12', '25', '51', '19', '97', '70'], 'predicted_two_grams': {'51', 'ar', 'ce', 'bl', 'ha', '19', 'an', 'ac', 'wa', 'rd', 'la', '97', 'nc', 'ch'}, 'dice_similarity': 0.8}, {'uid': '87747', 'actual_two_grams': ['ja', 'ac', 'ck', 'ki', 'ie', 'eg', 'gr', 're', 'ee', 'en', 'nb', 'ba', 'au', 'um', 'm1', '10', '01', '15', '51', '19', '99', '94'], 'predicted_two_grams': {'51', 'ck', '94', '19', 're'}, 'dice_similarity': 0.3704}, {'uid': '39750', 'actual_two_grams': ['ga', 'ar', 'ry', 'yj', 'jo', 'oh', 'hn', 'ns', 'so', 'on', 'n1', '11', '11', '18', '81', '19', '98', '86'], 'predicted_two_grams': {'ar', '19', '98', 'jo', 'on', 'oh', '11', 'ry', 'hn', 'ns', 'so'}, 'dice_similarity': 0.7857}, {'uid': '47539', 'actual_two_grams': ['lu', 'uc', 'ci', 'il', 'll', 'le', 'es', 'st', 'te', 'ev', 've', 'en', 'ns', 'so', 'on', 'n4', '41', '12', '21', '19', '94', '47'], 'predicted_two_grams': {'nl', 'il', 've', 'le', 'ev', '19', '41', '94', 'on', '12', 'te', 'st', 'en', 'ns', 'so'}, 'dice_similarity': 0.7568}, {'uid': '89059', 'actual_two_grams': ['be', 'er', 'rn', 'na', 'ar', 'rd', 'dr', 'ri', 'ic', 'ch', 'hm', 'mo', 'on', 'nd', 'd1', '12', '23', '31', '19', '97', '77'], 'predicted_two_grams': {'ar', 'ri', 'ha', 'er', '19', 'on', '23', '31', 'rd', 'rn'}, 'dice_similarity': 0.5806}, {'uid': '90854', 'actual_two_grams': ['be', 'er', 'rn', 'na', 'ad', 'de', 'et', 'tt', 'te', 'eh', 'ho', 'ol', 'll', 'le', 'en', 'nb', 'be', 'ec', 'ck', 'k2', '24', '41', '19', '98', '86'], 'predicted_two_grams': {'tt', '41', 'er', 'le', 'et', '19', 'de', 'en', 'rn'}, 'dice_similarity': 0.5455}, {'uid': '66027', 'actual_two_grams': ['st', 'te', 'ep', 'ph', 'he', 'en', 'ng', 'gr', 'ri', 'id', 'dl', 'le', 'ey', 'y5', '51', '13', '31', '19', '97', '70'], 'predicted_two_grams': {'51', 'ri', 'le', '19', 'ey', '97', 'ng'}, 'dice_similarity': 0.5185}, {'uid': '5435', 'actual_two_grams': ['ka', 'at', 'th', 'he', 'er', 'rn', 'nh', 'ha', 'an', 'nk', 'ks', 's1', '11', '11', '11', '19', '98', '81'], 'predicted_two_grams': {'th', '61', '19', 'an', '12', '11', '98', 'ka'}, 'dice_similarity': 0.5}, {'uid': '79229', 'actual_two_grams': ['be', 'er', 'rt', 'th', 'ha', 'aj', 'ja', 'am', 'me', 'es', 's3', '31', '13', '31', '19', '98', '80'], 'predicted_two_grams': {'er', '19', 'es', 'rt', '31', 'me', 'ja', '98', 'be'}, 'dice_similarity': 0.72}, {'uid': '65375', 'actual_two_grams': ['ju', 'ua', 'an', 'ni', 'it', 'ta', 'ao', 'od', 'de', 'en', 'n1', '13', '31', '19', '94', '49'], 'predicted_two_grams': {'94', '19', 'an', '31', '11', '13', 'en', 'nn', 'ni'}, 'dice_similarity': 0.56}, {'uid': '79776', 'actual_two_grams': ['el', 'li', 'iz', 'za', 'ab', 'be', 'et', 'th', 'hw', 'wa', 'as', 'sh', 'hi', 'in', 'ng', 'gt', 'to', 'on', 'n1', '12', '23', '30', '01', '19', '96', '69'], 'predicted_two_grams': {'th', 'in', 'et', 'ab', '19', 'n1', 'li', 'on', 'wa', '12', '96', '69', 'el', 'be', 'ng'}, 'dice_similarity': 0.7317}, {'uid': '36903', 'actual_two_grams': ['sh', 'ha', 'an', 'nn', 'no', 'on', 'nh', 'he', 'er', 'rn', 'na', 'an', 'nd', 'de', 'ez', 'z3', '32', '23', '31', '19', '97', '76'], 'predicted_two_grams': {'32', 'ha', 'er', '19', 'n8', 'an', 'na', 'on', 'nn', 'de', 'sh', '23', '31', '97', 'ez', 'rn'}, 'dice_similarity': 0.8108}, {'uid': '42694', 'actual_two_grams': ['be', 'ev', 've', 'er', 'rl', 'ly', 'yl', 'lu', 'us', 'sk', 'k1', '12', '21', '12', '21', '19', '98', '81'], 'predicted_two_grams': {'81', 've', 'er', 'ev', '19', '12', '21', '98', 'be', 'en'}, 'dice_similarity': 0.6923}, {'uid': '89271', 'actual_two_grams': ['fe', 'er', 'rn', 'na', 'an', 'nd', 'do', 'ol', 'la', 'am', 'mp', 'pk', 'ki', 'in', 'ns', 's1', '10', '08', '81', '19', '95', '59'], 'predicted_two_grams': {'10', '81', 'in', '19', 'do', 'an', '95', 'la', '01', 'nd'}, 'dice_similarity': 0.5625}, {'uid': '60237', 'actual_two_grams': ['ch', 'hr', 'ri', 'is', 'st', 'to', 'op', 'ph', 'he', 'er', 'rh', 'ha', 'ay', 'yd', 'do', 'on', 'n1', '11', '10', '01', '19', '97', '70'], 'predicted_two_grams': {'10', 'ri', 'ha', 'er', '19', 'yd', '11', '97', '01', 'ch', 'r1'}, 'dice_similarity': 0.5882}, {'uid': '25347', 'actual_two_grams': ['pa', 'at', 'tr', 'ri', 'ic', 'ck', 'kg', 'ga', 'as', 'ss', 's1', '10', '02', '20', '01', '19', '94', '40'], 'predicted_two_grams': {'10', 'ck', 'ic', 'ri', '94', '19', 'as', 'tr', '01', 'at', '20'}, 'dice_similarity': 0.7586}, {'uid': '45540', 'actual_two_grams': ['da', 'av', 'vi', 'id', 'dl', 'le', 'ew', 'wi', 'is', 's6', '61', '13', '31', '19', '97', '70'], 'predicted_two_grams': {'vi', 'da', 'le', 'av', '19', '31', '97', 'id', 'is'}, 'dice_similarity': 0.72}, {'uid': '25966', 'actual_two_grams': ['ca', 'ar', 'rl', 'lg', 'go', 'on', 'nz', 'za', 'al', 'le', 'ez', 'z4', '41', '18', '81', '19', '98', '81'], 'predicted_two_grams': {'81', 'ar', '41', 'le', '19', '18', '98', '48'}, 'dice_similarity': 0.56}, {'uid': '81965', 'actual_two_grams': ['ja', 'an', 'ni', 'ic', 'ce', 'eh', 'hi', 'in', 'ns', 'so', 'on', 'n4', '46', '61', '19', '94', '41'], 'predicted_two_grams': {'ck', 'ic', 'in', '41', '19', 'bb', '94', 'an', 'as', 'on', 'n4', 'aj', 'ja', 'ns', 'so', 'ni'}, 'dice_similarity': 0.7273}, {'uid': '43685', 'actual_two_grams': ['ku', 'ur', 'rt', 'tk', 'ke', 'el', 'll', 'ly', 'y1', '11', '12', '25', '51', '19', '95', '57'], 'predicted_two_grams': {'ur', '19', '53', 'ke', '12', '95', 'el', '11', 'll'}, 'dice_similarity': 0.64}, {'uid': '73499', 'actual_two_grams': ['ir', 're', 'en', 'ne', 'em', 'ma', 'ar', 'rt', 'ti', 'in', 'ne', 'ez', 'z2', '22', '25', '51', '19', '95', '52'], 'predicted_two_grams': {'51', '25', 'ar', 'in', 'ti', '19', 'em', '95', 'ma', 'ir', 'en', 'ne'}, 'dice_similarity': 0.8}, {'uid': '85184', 'actual_two_grams': ['st', 'te', 'ev', 've', 'en', 'nr', 'ra', 'am', 'mi', 'ir', 're', 'ez', 'z6', '63', '30', '01', '19', '93', '37'], 'predicted_two_grams': {'30', '61', 've', '19', 'ev', '95', 'st', 'en', '01'}, 'dice_similarity': 0.5}, {'uid': '18593', 'actual_two_grams': ['mi', 'ic', 'ch', 'he', 'el', 'll', 'le', 'ek', 'ko', 'or', 'ra', 'an', 'nd', 'do', 'o1', '11', '13', '30', '01', '19', '98', '82'], 'predicted_two_grams': {'10', 'mi', 'ra', 'le', '19', 'an', 'el', '11', 'll', '98', '01'}, 'dice_similarity': 0.6061}, {'uid': '47734', 'actual_two_grams': ['la', 'au', 'ur', 'ra', 'am', 'me', 'en', 'nd', 'do', 'oz', 'za', 'a3', '31', '17', '71', '19', '95', '53'], 'predicted_two_grams': {'ur', 'au', 'ra', 're', '19', '71', '95', 'de', 'la', 'en', 'am'}, 'dice_similarity': 0.6207}, {'uid': '16774', 'actual_two_grams': ['mo', 'on', 'ni', 'ic', 'ca', 'aj', 'ji', 'im', 'me', 'en', 'ne', 'ez', 'z7', '71', '14', '41', '19', '93', '39'], 'predicted_two_grams': {'n7', '41', '19', '93', 'on', 'en', 'ni'}, 'dice_similarity': 0.4615}]\n"
     ]
    }
   ],
   "source": [
    "# List to store decoded 2-gram scores for all test samples\n",
    "decoded_test_results_words = []\n",
    "combined_results_performance = []\n",
    "\n",
    "# Switch to evaluation mode (no gradient computation during inference)\n",
    "model.eval()\n",
    "\n",
    "# Define Threshold for filtering predictions\n",
    "threshold = DEA_CONFIG[\"FilterThreshold\"]\n",
    "\n",
    "# Loop through the test dataloader for inference\n",
    "with torch.no_grad():  # No need to compute gradients during inference\n",
    "    for data_batch, uids in tqdm(dataloader_test, desc=\"Test loop\"):\n",
    "        # Filter relevant individuals from the dataset based on UIDs\n",
    "        filtered_df = df_all[df_all[\"uid\"].isin(uids)].drop(df_all.columns[-2], axis=1) # Drop encoding column\n",
    "\n",
    "        # Extract 2-grams from actual data for comparison\n",
    "        actual_two_grams_batch = []\n",
    "        for _, entry in filtered_df.iterrows():\n",
    "            row = entry[:-1]  # Exclude UID from row\n",
    "            extracted_two_grams = extract_two_grams(\"\".join(map(str, row)))  # Extract 2-grams from the row\n",
    "            actual_two_grams_batch.append({\"uid\": entry[\"uid\"], \"two_grams\": extracted_two_grams})\n",
    "\n",
    "        # Move the batch of data to the device (e.g., GPU)\n",
    "        data_batch = data_batch.to(compute_device)\n",
    "\n",
    "        # Apply the model to get logits (raw predictions)\n",
    "        logits = model(data_batch)\n",
    "\n",
    "        # Convert logits to probabilities using sigmoid (binary classification)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "\n",
    "        # Convert probabilities into 2-gram scores (using the two_gram_dict to map to 2-gram labels)\n",
    "        batch_two_gram_scores = [\n",
    "            {two_gram_dict[j]: score.item() for j, score in enumerate(probabilities[i])}  # Map each probability to its 2-gram\n",
    "            for i in range(probabilities.size(0))  # Iterate over each sample in the batch\n",
    "        ]\n",
    "\n",
    "        # Apply threshold to filter out low-scoring 2-grams\n",
    "        batch_filtered_two_gram_scores = [\n",
    "            {two_gram: score for two_gram, score in two_gram_scores.items() if score > threshold}  # Only keep scores above threshold\n",
    "            for two_gram_scores in batch_two_gram_scores\n",
    "        ]\n",
    "\n",
    "        # Filtered 2-grams per UID in the batch\n",
    "        filtered_two_grams = [\n",
    "            {\"uid\": uid, \"two_grams\": {key for key in two_grams.keys()}}  # Only keep the 2-gram keys (no scores)\n",
    "            for uid, two_grams in zip(uids, batch_filtered_two_gram_scores)\n",
    "        ]\n",
    "\n",
    "        # Reconstruct words from the filtered 2-grams for each sample\n",
    "        batch_reconstructed_words = [\n",
    "            reconstruct_words(filtered_scores) for filtered_scores in batch_filtered_two_gram_scores\n",
    "        ]\n",
    "\n",
    "        # Append the reconstructed words to the results list\n",
    "        decoded_test_results_words.extend(batch_reconstructed_words)\n",
    "\n",
    "        # Compare predicted 2-grams with actual 2-grams and calculate performance metrics\n",
    "        for entry_two_grams_batch in actual_two_grams_batch:  # Loop through each UID in the batch\n",
    "            for entry_filtered_two_grams in filtered_two_grams:\n",
    "                if entry_two_grams_batch[\"uid\"] == entry_filtered_two_grams[\"uid\"]:\n",
    "                    # Calculate Dice similarity between actual and predicted 2-grams\n",
    "                    combined_results_performance.append({\n",
    "                        \"uid\": entry_two_grams_batch[\"uid\"],\n",
    "                        \"actual_two_grams\": entry_two_grams_batch[\"two_grams\"],  # Get actual 2-grams for this UID\n",
    "                        \"predicted_two_grams\": entry_filtered_two_grams[\"two_grams\"],  # Get predicted 2-grams for this UID\n",
    "                        \"dice_similarity\": dice_coefficient(entry_two_grams_batch[\"two_grams\"], entry_filtered_two_grams[\"two_grams\"]),\n",
    "                    })\n",
    "\n",
    "# Now `combined_results_performance` contains detailed comparison for all test samples\n",
    "print(combined_results_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Stopping execution at this cell.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Stopping execution at this cell.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I538952/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit(\"Stopping execution at this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Performance for Re-Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reidentified Individuals:')\n",
    "print(df_reidentified.head())\n",
    "print('Not Reidentified Individuals:')\n",
    "print(df_not_reidentified.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled.labelTensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, labels in dataloader_train:\n",
    "    data, labels = data.to(compute_device), labels.to(compute_device)\n",
    "    print(data.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To Decode: \",df_not_reidentified.iloc[1])\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "#torch.set_printoptions(profile=\"default\")\n",
    "print(\"Tensor: \", data_not_labeled[1])\n",
    "# Apply model\n",
    "model.eval()\n",
    "logits = model(data_not_labeled[1])\n",
    "probabilities = torch.sigmoid(logits)\n",
    "print(\"Prob: \", probabilities)\n",
    "two_gram_scores = {two_gram_dict[i]: score.item() for i, score in enumerate(probabilities)}\n",
    "threshold = 0.5\n",
    "filtered_two_gram_scores = {two_gram: score for two_gram, score in two_gram_scores.items() if score > threshold}\n",
    "print(\"Decoded 2grams: \", filtered_two_gram_scores)\n",
    "\n",
    "print(reconstruct_words(filtered_two_gram_scores))\n",
    "\n",
    "# person is: Ray Haywood 9/27/1959\n",
    "# ra -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(20, 5) # predict logits for 5 classes\n",
    "x = torch.randn(1, 20)\n",
    "print(x.shape)\n",
    "y = torch.tensor([[1., 0., 1., 0., 0.]]) # get classA and classC as active\n",
    "print(y.shape)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('Loss: {:.3f}'.format(loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
