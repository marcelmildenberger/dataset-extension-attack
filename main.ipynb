{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Record Linkage (PPRL): Investigating Dataset Extension Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:20:01) [Clang 18.1.8 ]\n",
      "PyTorch version 2.1.2\n",
      "Torchvision version 0.16.2\n",
      "Numpy version 1.24.4\n",
      "Pandas version 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import hickle as hkl\n",
    "import numpy as np\n",
    "import string\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from graphMatching.gma import run_gma\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "GLOBAL_CONFIG = {\n",
    "    \"Data\": \"./graphMatching/data/fakename_5k.tsv\",\n",
    "    \"Overlap\": 0.8,\n",
    "    \"DropFrom\": \"Both\",\n",
    "    \"DevMode\": False,  # Development Mode, saves some intermediate results to the /dev directory\n",
    "    \"BenchMode\": False,  # Benchmark Mode\n",
    "    \"Verbose\": True,  # Print Status Messages?\n",
    "    \"MatchingMetric\": \"cosine\",\n",
    "    \"Matching\": \"MinWeight\",\n",
    "    \"Workers\": -1,\n",
    "    \"SaveAliceEncs\": False,\n",
    "    \"SaveEveEncs\": False\n",
    "}\n",
    "\n",
    "ENC_CONFIG = {\n",
    "    \"AliceAlgo\": \"BloomFilter\",\n",
    "    \"AliceSecret\": \"SuperSecretSalt1337\",\n",
    "    \"AliceN\": 2,\n",
    "    \"AliceMetric\": \"dice\",\n",
    "    \"EveAlgo\": \"BloomFilter\",\n",
    "    \"EveSecret\": \"ATotallyDifferentString42\",\n",
    "    \"EveN\": 2,\n",
    "    \"EveMetric\": \"dice\",\n",
    "    # For BF encoding\n",
    "    \"AliceBFLength\": 1024,\n",
    "    \"AliceBits\": 10,\n",
    "    \"AliceDiffuse\": False,\n",
    "    \"AliceT\": 10,\n",
    "    \"AliceEldLength\": 1024,\n",
    "    \"EveBFLength\": 1024,\n",
    "    \"EveBits\": 10,\n",
    "    \"EveDiffuse\": False,\n",
    "    \"EveT\": 10,\n",
    "    \"EveEldLength\": 1024,\n",
    "    # For TMH encoding\n",
    "    \"AliceNHash\": 1024,\n",
    "    \"AliceNHashBits\": 64,\n",
    "    \"AliceNSubKeys\": 8,\n",
    "    \"Alice1BitHash\": True,\n",
    "    \"EveNHash\": 1024,\n",
    "    \"EveNHashBits\": 64,\n",
    "    \"EveNSubKeys\": 8,\n",
    "    \"Eve1BitHash\": True,\n",
    "    # For 2SH encoding\n",
    "    \"AliceNHashFunc\": 10,\n",
    "    \"AliceNHashCol\": 1000,\n",
    "    \"AliceRandMode\": \"PNG\",\n",
    "    \"EveNHashFunc\": 10,\n",
    "    \"EveNHashCol\": 1000,\n",
    "    \"EveRandMode\": \"PNG\",\n",
    "    # For PST Encoding\n",
    "    \"AlicePSTK\": 20,\n",
    "    \"AlicePSTL\": 8,\n",
    "    \"AlicePSTP\": None,\n",
    "    \"AliceCharset\": string.printable,\n",
    "    \"EvePSTK\": 20,\n",
    "    \"EvePSTL\": 8,\n",
    "    \"EvePSTP\": None,\n",
    "    \"EveCharset\": string.printable\n",
    "}\n",
    "\n",
    "EMB_CONFIG = {\n",
    "    \"Algo\": \"Node2Vec\",\n",
    "    \"AliceQuantile\": 0.9,\n",
    "    \"AliceDiscretize\": False,\n",
    "    \"AliceDim\": 128,\n",
    "    \"AliceContext\": 10,\n",
    "    \"AliceNegative\": 1,\n",
    "    \"AliceNormalize\": True,\n",
    "    \"EveQuantile\": 0.9,\n",
    "    \"EveDiscretize\": False,\n",
    "    \"EveDim\": 128,\n",
    "    \"EveContext\": 10,\n",
    "    \"EveNegative\": 1,\n",
    "    \"EveNormalize\": True,\n",
    "    # For Node2Vec\n",
    "    \"AliceWalkLen\": 100,\n",
    "    \"AliceNWalks\": 20,\n",
    "    \"AliceP\": 250,\n",
    "    \"AliceQ\": 300,\n",
    "    \"AliceEpochs\": 5,\n",
    "    \"AliceSeed\": 42,\n",
    "    \"EveWalkLen\": 100,\n",
    "    \"EveNWalks\": 20,\n",
    "    \"EveP\": 250,\n",
    "    \"EveQ\": 300,\n",
    "    \"EveEpochs\": 5,\n",
    "    \"EveSeed\": 42\n",
    "}\n",
    "\n",
    "ALIGN_CONFIG = {\n",
    "    \"RegWS\": max(0.1, GLOBAL_CONFIG[\"Overlap\"]/2), #0005\n",
    "    \"RegInit\":1, # For BF 0.25\n",
    "    \"Batchsize\": 1, # 1 = 100%\n",
    "    \"LR\": 200.0,\n",
    "    \"NIterWS\": 100,\n",
    "    \"NIterInit\": 5 ,  # 800\n",
    "    \"NEpochWS\": 100,\n",
    "    \"LRDecay\": 1,\n",
    "    \"Sqrt\": True,\n",
    "    \"EarlyStopping\": 10,\n",
    "    \"Selection\": \"None\",\n",
    "    \"MaxLoad\": None,\n",
    "    \"Wasserstein\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alice's data\n",
      "Encoding Alice's Data\n",
      "Done encoding Alice's data\n",
      "Computing Thresholds and subsetting data for Alice\n",
      "Done processing Alice's data.\n",
      "Loading Eve's data\n",
      "Encoding Eve's Data\n",
      "Done encoding Eve's data\n",
      "Computing Thresholds and subsetting data for Eve\n",
      "Done processing Eve's data.\n",
      "Embedding Alice's data. This may take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6dc625b697e452392c5f17df8cf55d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t  Loss: 7787830.5\n",
      "Epoch: 2\t  Loss: 6680338.5\n",
      "Epoch: 3\t  Loss: 5757517.0\n",
      "Epoch: 4\t  Loss: 5151742.0\n",
      "Epoch: 5\t  Loss: 5142628.0\n",
      "Done embedding Alice's data.\n",
      "Embedding Eve's data. This may take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d2e2e77d67426bb916f0aa990705c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t  Loss: 7976018.5\n",
      "Epoch: 2\t  Loss: 6470012.5\n",
      "Epoch: 3\t  Loss: 5741505.0\n",
      "Epoch: 4\t  Loss: 5289154.0\n",
      "Epoch: 5\t  Loss: 4924996.0\n",
      "Done embedding Eve's data.\n",
      "Aligning vectors. This may take a while.\n",
      "\n",
      "Computing initial mapping with convex relaxation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective after convex initialization: 49.027809\n",
      "Done [002 sec]\n",
      "\n",
      "Computing mapping with Wasserstein Procrustes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 100/100 [02:03<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  obj: 34.579  best: 34.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 100/100 [02:09<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective of  34.578 is 71.75 % of initial value. Early stopping...\n",
      "Done [275 sec]\n",
      "Done.\n",
      "Performing bipartite graph matching\n",
      "Correct: 3333 of 3333\n",
      "Success rate: 1.000000\n"
     ]
    }
   ],
   "source": [
    "reidentified_individuals, not_reidentified_individuals = run_gma(GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG, ALIGN_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reidentified_individuals = pd.DataFrame(reidentified_individuals[1:], columns=reidentified_individuals[0])\n",
    "df_not_reidentified_individuals = pd.DataFrame(not_reidentified_individuals[1:], columns=not_reidentified_individuals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reidentified Individuals:\n",
      "  GivenName   Surname    Birthday  \\\n",
      "0     Donna  Anderson    1/7/2003   \n",
      "1      Jean     Pusey   2/15/1999   \n",
      "2     Doris      Cruz   9/16/1981   \n",
      "3    Daniel      Hall   4/11/2002   \n",
      "4    Audrey    Bowman  10/17/1959   \n",
      "\n",
      "                                         bloomfilter    uid  \n",
      "0  1001100000000100000001011000001011000000100010...  96474  \n",
      "1  0010001010000010001000000010000100000000100000...  96607  \n",
      "2  1001100000000000000000000000000000001110100010...  62154  \n",
      "3  1000110000001000000001001000000010000010100010...  46041  \n",
      "4  0000010010000100000101001010000000001100110100...  93172  \n",
      "Not Reidentified Individuals:\n",
      "                                         bloomfilter    uid\n",
      "0  1000010011000000010100001110000011100110100011...  91327\n",
      "1  0000100000000000000000011010000110000000110000...  81181\n",
      "2  0001111000000101001000011100000000000000100010...  38719\n",
      "3  0001100000001001010010110011100100100000100010...  81141\n",
      "4  1000010010001000000000010000100010000100100000...  92331\n"
     ]
    }
   ],
   "source": [
    "print('Reidentified Individuals:')\n",
    "print(df_reidentified_individuals.head())  \n",
    "print('Not Reidentified Individuals:')\n",
    "print(df_not_reidentified_individuals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloomFilterDataset(Dataset):\n",
    "    def __init__(self, data, isLabeled=False, all_two_grams=None):\n",
    "        self.isLabeled = isLabeled\n",
    "        self.allTwoGrams = all_two_grams\n",
    "        self.data = data  \n",
    "        if self.isLabeled:\n",
    "            # For reidentified data, extract labels (2-grams) from names\n",
    "            self.data['label'] = self.data.apply(lambda row: self.extract_two_grams(row[0], row[1]), axis=1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        bloom_filter = self.data.iloc[idx]['bloomfilter']\n",
    "        bloom_filter_tensor = self.bloomfilter_to_tensor(bloom_filter)\n",
    "\n",
    "        if self.isLabeled:\n",
    "            label = self.data.iloc[idx]['label']\n",
    "            label_tensor = self.label_to_tensor(label)\n",
    "            return bloom_filter_tensor, label_tensor\n",
    "        else:\n",
    "            # For unlabeled data (not_reidentified_individuals.tsv), just return the Bloom Filter\n",
    "            return bloom_filter_tensor\n",
    "    \n",
    "    def extract_two_grams(self, firstname, surname):\n",
    "        full_name = f\"{surname} {firstname}\".replace('\"', '').replace('.', '').replace('/', '').strip()\n",
    "        full_name = full_name.lower()  # Normalize to lowercase for consistency\n",
    "        return [full_name[i:i+2] for i in range(len(full_name)-1) if ' ' not in full_name[i:i+2]]\n",
    "    \n",
    "    def bloomfilter_to_tensor(self, bloom_filter_str):\n",
    "        bloom_filter_array = np.array([int(bit) for bit in bloom_filter_str], dtype=np.float32)\n",
    "        return torch.tensor(bloom_filter_array)\n",
    "    \n",
    "    def label_to_tensor(self, label_two_grams):\n",
    "        label_vector = np.zeros(len(self.allTwoGrams), dtype=np.float32)\n",
    "        \n",
    "        # Set 1 for the 2-grams present in the name\n",
    "        for gram in label_two_grams:\n",
    "            if gram in self.allTwoGrams:\n",
    "                index = self.allTwoGrams.index(gram)\n",
    "                label_vector[index] = 1\n",
    "        \n",
    "        return torch.tensor(label_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate all 2-grams\n",
    "alphabet = string.ascii_lowercase\n",
    "all_two_grams = []\n",
    "for a in alphabet:\n",
    "    for b in alphabet:\n",
    "        all_two_grams.append(a+b)\n",
    "# Get a dictionary associating each 2-gram with an index\n",
    "two_gram_dict = {i: two_gram for i, two_gram in enumerate(all_two_grams)}\n",
    "# Create Datasets\n",
    "data_labeled = BloomFilterDataset(df_reidentified_individuals, isLabeled=True, all_two_grams=all_two_grams)\n",
    "data_not_labeled = BloomFilterDataset(df_not_reidentified_individuals, isLabeled=False, all_two_grams=all_two_grams)\n",
    "bloomfilter_length = len(data_labeled[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split proportions\n",
    "train_size = int(0.8 * len(data_labeled))  # 80% training\n",
    "val_size = len(data_labeled) - train_size  # 20% validation\n",
    "\n",
    "# Split dataset\n",
    "data_train, data_val = random_split(data_labeled, [train_size, val_size])\n",
    "dataloader_train = DataLoader(data_train, batch_size=16, shuffle=True)\n",
    "dataloader_val = DataLoader(data_val, batch_size=16, shuffle=True)\n",
    "dataloader_test = DataLoader(data_not_labeled, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloomFilterToTwoGramClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, num_two_grams=676):\n",
    "        super(BloomFilterToTwoGramClassifier, self).__init__()\n",
    "        \n",
    "        # Define the layers for multi-label classification of 2-grams\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),   # Input => first hidden layer\n",
    "            nn.ReLU(),                       \n",
    "            nn.Dropout(0.2),                  \n",
    "            nn.Linear(hidden_dim, hidden_dim),  # First hidden layer => second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # First hidden layer => second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),  # First hidden layer => second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, num_two_grams), # Second hidden layer => output layer\n",
    "            nn.Sigmoid()                       \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the model\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BloomFilterToTwoGramClassifier(input_dim=bloomfilter_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss function for multi-label classification\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5976abb8938641849970b6e79ef1c24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2b419b50d14a42a90378037098e132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Train loss: 0.7018, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fd27e2cd9bf420da2d6849694a4ccd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa98d6db8b364e3ebe98662c0fe28288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Train loss: 0.6931, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b8073914654a12966f51a60522e805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcef900099c94378b35a7927bbd402d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Train loss: 0.6931, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57350f6ec3d4a18bd44ecbbc2ae88aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49699ddaa9924b6a892892aca49778c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Train loss: 0.6931, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9859ee03fe4ed8b862de3e94283513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad76e3f8fddd4d06a01e0811c9d687de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Train loss: 0.6931, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fdd8bc3dc84fb18fa73e0a2d4dcaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e754fc09d3949258f4cc1e348ef47d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Train loss: 0.6931, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7acfea50f0451c955eb299bd3b202a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896012f6703f41c0a51a02f0068c91be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation loop:   0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Train loss: 0.6931, Validation loss: 0.6931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b76de5230f94afe8838d7fd6cb4f68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training loop:   0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     16\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 17\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader_train\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[0;32m~/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/torch/optim/adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 385\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Number of epochs\n",
    "num_epochs = 30\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for bloom_filters, labels in tqdm(dataloader_train, desc=\"Training loop\"):\n",
    "        # Move data to device\n",
    "        bloom_filters, labels = bloom_filters.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(bloom_filters)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * labels.size(0)\n",
    "    train_loss = running_loss / len(dataloader_train.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    #Validation\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for bloom_filters, labels in tqdm(dataloader_val, desc=\"Validation loop\"):\n",
    "            # Move data to device\n",
    "            bloom_filters, labels = bloom_filters.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(bloom_filters)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        val_loss = running_loss / len(dataloader_val.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First entry for reference (labeled data):\n",
    "# surname                                                  Hegarty\n",
    "# firstname                                    Miss. Hanora \"Nora\"\n",
    "# bloomfilter    0000000010100011000100000101000000000000100000001000000000100111011000001001100100000100000000001000000000000000001000100000000000010010000000000000100010001110110111000000000000100000000100000001010000000000100101000011000010001010000001000000000000000000001000011010011001000100000011100100000000000011000100100000110011000000000010000000000010000000000000110000000110000000000010000000011100000001000000100000001100101011001000000000010000001000000000001000010110110000000001001000100001010111010000000010000000111000000000010010110000000000001000000101010001000000001000001000010000100110000111001110000000001010011110000100000000000100000001100001100000000000010000000000000000000000100000000010000001000000000011100000000000001000101000010100001001000011000000000010001100000000100000001000001000000000100000101000000000000000000010000000100000000100001000000100000000000000011100000001001000000001100010000001000001000000000000010100100000000110101110010000010000010100000000011000001000000001110000101001000010101111\n",
    "# uid                                                          654\n",
    "# Name: 0, dtype: object\n",
    "#print('Length Labeled data:', len(data_labeled))\n",
    "#print('Length Unlabeled data:', len(data_not_labeled))\n",
    "\n",
    "#bloomfilter_tensor, label_tensor = data_labeled[0]\n",
    "\n",
    "#print('Bloom Filter Tensor:', bloomfilter_tensor)\n",
    "#print('Bloom Filter Tensor Shape:', bloomfilter_tensor.shape)\n",
    "#print('Label Tensor:', label_tensor)\n",
    "#print('Label Tensor Shape:', label_tensor.shape)\n",
    "\n",
    "#for bloomfilter_tensors, label_tensors in dataloader_train:\n",
    "#    print('Bloom Filter Tensor Shape:', bloomfilter_tensors.shape)\n",
    "#    print('Label Tensor Shape:', label_tensors.shape)\n",
    "#    print(label_tensors)\n",
    "#    break\n",
    "\n",
    "#print(str(model)[:500])\n",
    "#example_bloom, example_label = data_train[0]\n",
    "#example_out = model(example_bloom)\n",
    "#print(example_out.shape) \n",
    "#loss_function_applied = criterion(example_out, example_label)\n",
    "#print(loss_function_applied)\n",
    "#print(example_out)\n",
    "\n",
    "print(data_labeled[0])\n",
    " \n",
    "# Apply model\n",
    "result = model(bloomfilter_tensor)\n",
    "# Result = Tensor of shape 676 with prob. for each 2gram\n",
    "two_gram_scores = {two_gram_dict[i]: score.item() for i, score in enumerate(result)}\n",
    "\n",
    "threshold = 0.000000001\n",
    "filtered_two_gram_scores = {two_gram: score for two_gram, score in two_gram_scores.items() if score > threshold}\n",
    "filtered_two_gram_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
