{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving Record Linkage (PPRL): Investigating Dataset Extension Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all relevant libraries and classes used throughout the project. Key components include:\n",
    "\n",
    "- **Torch** ‚Äì for tensor operations and neural network functionality  \n",
    "- **Datasets** ‚Äì for handling training and evaluation data  \n",
    "- **PyTorch Models** ‚Äì custom and pre-defined models for the DEA  \n",
    "- **Graph Matching Attack (GMA)** ‚Äì core logic for the initial re-identification phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NumPy dot (Mac)\n",
      "System Version: 3.10.17 | packaged by conda-forge | (main, Apr 10 2025, 22:23:34) [Clang 18.1.8 ]\n",
      "PyTorch version 2.2.0\n",
      "Torchvision version 0.17.0\n",
      "Numpy version 1.24.4\n",
      "Pandas version 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "\n",
    "from utils import get_hashes, reconstruct_words, run_epoch, convert_to_two_gram_scores, filter_two_grams, calculate_performance_metrics, label_tensors_to_two_grams\n",
    "\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import hickle as hkl\n",
    "import numpy as np\n",
    "import string\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from graphMatching.gma import run_gma\n",
    "\n",
    "from datasets.bloom_filter_dataset import BloomFilterDataset\n",
    "from datasets.tab_min_hash_dataset import TabMinHashDataset\n",
    "from datasets.two_step_hash_dataset import TwoStepHashDataset\n",
    "\n",
    "from pytorch_models.bloom_filter_to_two_gram_classifier import BloomFilterToTwoGramClassifier\n",
    "from pytorch_models.tab_min_hash_to_two_gram_classifier import TabMinHashToTwoGramClassifier\n",
    "from pytorch_models.two_step_hash_to_two_gram_classifier import TwoStepHashToTwoGramClassifier\n",
    "from pytorch_models.test_model import TestModel\n",
    "\n",
    "from early_stopping.early_stopping import EarlyStopping\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Configuration and parameters for the Graph Matching Attack (GMA) and Dataset Extension Attack (DEA). For details and possible values, refer to the documentation at ```./docs/parameters.md```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "GLOBAL_CONFIG = {\n",
    "    \"Data\": \"./data/datasets/fakename_1k.tsv\",\n",
    "    \"Overlap\": 0.8,\n",
    "    \"DropFrom\": \"Eve\",\n",
    "    \"Verbose\": True,  # Print Status Messages\n",
    "    \"MatchingMetric\": \"cosine\",\n",
    "    \"Matching\": \"MinWeight\",\n",
    "    \"Workers\": -1,\n",
    "    \"SaveAliceEncs\": False,\n",
    "    \"SaveEveEncs\": False,\n",
    "    \"DevMode\": False,\n",
    "}\n",
    "\n",
    "\n",
    "DEA_CONFIG = {\n",
    "    \"DevMode\": False,\n",
    "    # BCEWithLogitsLoss / MultiLabelSoftMarginLoss\n",
    "    \"LossFunction:\": \"BCEWithLogitsLoss\",\n",
    "    # Adam / AdamW / SGD / RMSprop\n",
    "    \"Optimizer\": \"Adam\",\n",
    "    \"LearningRate\": 0.0005149157768571977,\n",
    "    # SGD only\n",
    "    \"Momentum\": 0.9,\n",
    "    \"BatchSize\": 16,\n",
    "    \"Epochs\": 27,\n",
    "    # TestSize calculated accordingly\n",
    "    \"TrainSize\": 0.8,\n",
    "    \"FilterThreshold\": 0.5,\n",
    "    \"Patience\": 10,\n",
    "    \"MinDelta\": 1e-4,\n",
    "    \"TestModel\": True,\n",
    "    # relu / leaky_relu / gelu\n",
    "    \"ActivationFunction\": \"relu\"\n",
    "}\n",
    "\n",
    "ENC_CONFIG = {\n",
    "    # TwoStepHash / TabMinHash / BloomFilter\n",
    "    \"AliceAlgo\": \"BloomFilter\",\n",
    "    \"AliceSecret\": \"SuperSecretSalt1337\",\n",
    "    \"AliceN\": 2,\n",
    "    \"AliceMetric\": \"dice\",\n",
    "    \"EveAlgo\": \"None\",\n",
    "    \"EveSecret\": \"ATotallyDifferentString42\",\n",
    "    \"EveN\": 2,\n",
    "    \"EveMetric\": \"dice\",\n",
    "    # For BF encoding\n",
    "    \"AliceBFLength\": 1024,\n",
    "    \"AliceBits\": 10,\n",
    "    \"AliceDiffuse\": False,\n",
    "    \"AliceT\": 10,\n",
    "    \"AliceEldLength\": 1024,\n",
    "    \"EveBFLength\": 1024,\n",
    "    \"EveBits\": 10,\n",
    "    \"EveDiffuse\": False,\n",
    "    \"EveT\": 10,\n",
    "    \"EveEldLength\": 1024,\n",
    "    # For TMH encoding\n",
    "    \"AliceNHash\": 1024,\n",
    "    \"AliceNHashBits\": 64,\n",
    "    \"AliceNSubKeys\": 8,\n",
    "    \"Alice1BitHash\": True,\n",
    "    \"EveNHash\": 1024,\n",
    "    \"EveNHashBits\": 64,\n",
    "    \"EveNSubKeys\": 8,\n",
    "    \"Eve1BitHash\": True,\n",
    "    # For 2SH encoding\n",
    "    \"AliceNHashFunc\": 10,\n",
    "    \"AliceNHashCol\": 1000,\n",
    "    \"AliceRandMode\": \"PNG\",\n",
    "    \"EveNHashFunc\": 10,\n",
    "    \"EveNHashCol\": 1000,\n",
    "    \"EveRandMode\": \"PNG\",\n",
    "}\n",
    "\n",
    "EMB_CONFIG = {\n",
    "    \"Algo\": \"Node2Vec\",\n",
    "    \"AliceQuantile\": 0.9,\n",
    "    \"AliceDiscretize\": False,\n",
    "    \"AliceDim\": 128,\n",
    "    \"AliceContext\": 10,\n",
    "    \"AliceNegative\": 1,\n",
    "    \"AliceNormalize\": True,\n",
    "    \"EveQuantile\": 0.9,\n",
    "    \"EveDiscretize\": False,\n",
    "    \"EveDim\": 128,\n",
    "    \"EveContext\": 10,\n",
    "    \"EveNegative\": 1,\n",
    "    \"EveNormalize\": True,\n",
    "    # For Node2Vec\n",
    "    \"AliceWalkLen\": 100,\n",
    "    \"AliceNWalks\": 20,\n",
    "    \"AliceP\": 250,\n",
    "    \"AliceQ\": 300,\n",
    "    \"AliceEpochs\": 5,\n",
    "    \"AliceSeed\": 42,\n",
    "    \"EveWalkLen\": 100,\n",
    "    \"EveNWalks\": 20,\n",
    "    \"EveP\": 250,\n",
    "    \"EveQ\": 300,\n",
    "    \"EveEpochs\": 5,\n",
    "    \"EveSeed\": 42\n",
    "}\n",
    "\n",
    "ALIGN_CONFIG = {\n",
    "    \"RegWS\": max(0.1, GLOBAL_CONFIG[\"Overlap\"]/2), #0005\n",
    "    \"RegInit\":1, # For BF 0.25\n",
    "    \"Batchsize\": 1, # 1 = 100%\n",
    "    \"LR\": 200.0,\n",
    "    \"NIterWS\": 100,\n",
    "    \"NIterInit\": 5 ,  # 800\n",
    "    \"NEpochWS\": 100,\n",
    "    \"LRDecay\": 1,\n",
    "    \"Sqrt\": True,\n",
    "    \"EarlyStopping\": 10,\n",
    "    \"Selection\": \"None\",\n",
    "    \"MaxLoad\": None,\n",
    "    \"Wasserstein\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Data Preparation: Load or Compute Graph Matching Attack (GMA) Results\n",
    "\n",
    "This code snippet either loads previously computed Graph Matching Attack (GMA) results from disk or runs the attack if no saved data is found.\n",
    "\n",
    "1. **Generate Configuration Hashes:**  \n",
    "   The function `get_hashes` creates unique hash values based on the encoding and embedding configurations. These are used to create distinct filenames for the data.\n",
    "\n",
    "2. **Create File Paths:**  \n",
    "   Based on the configuration hashes, paths are generated for:\n",
    "   - Reidentified individuals\n",
    "   - Not reidentified individuals\n",
    "   - All individuals in Alice‚Äôs dataset (with encoding)\n",
    "\n",
    "3. **Load Results from Disk (if available):**  \n",
    "   If the `.h5` files already exist, they are loaded using `hickle` and converted into `pandas.DataFrames`.  \n",
    "   The data format assumes that the first row contains the column headers, and the rest is the data ‚Äî hence the slicing `[1:]` and `columns=...`.\n",
    "\n",
    "4. **Run GMA If Data Is Not Available:**  \n",
    "   If the files are missing, the GMA is executed via `run_gma()`. The results are again converted to `DataFrames`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously saved attack results...\n"
     ]
    }
   ],
   "source": [
    "# Get unique hash identifiers for the encoding and embedding configurations\n",
    "eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash = get_hashes(GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG)\n",
    "\n",
    "# Define file paths based on the configuration hashes\n",
    "path_reidentified = f\"./data/available_to_eve/reidentified_individuals_{eve_enc_hash}_{alice_enc_hash}_{eve_emb_hash}_{alice_emb_hash}.h5\"\n",
    "path_not_reidentified = f\"./data/available_to_eve/not_reidentified_individuals_{eve_enc_hash}_{alice_enc_hash}_{eve_emb_hash}_{alice_emb_hash}.h5\"\n",
    "path_all = f\"./data/dev/alice_data_complete_with_encoding_{eve_enc_hash}_{alice_enc_hash}_{eve_emb_hash}_{alice_emb_hash}.h5\"\n",
    "\n",
    "# Check if the output files already exist\n",
    "if os.path.isfile(path_reidentified) and os.path.isfile(path_not_reidentified) and os.path.isfile(path_all):\n",
    "    # Load previously saved attack results\n",
    "    print(\"Loading previously saved attack results...\")\n",
    "    reidentified_data = hkl.load(path_reidentified)\n",
    "    not_reidentified_data = hkl.load(path_not_reidentified)\n",
    "    all_data = hkl.load(path_all)\n",
    "\n",
    "else:\n",
    "    # Run Graph Matching Attack if files are not found\n",
    "    reidentified_data, not_reidentified_data, all_data = run_gma(\n",
    "        GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG, ALIGN_CONFIG, DEA_CONFIG,\n",
    "        eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash\n",
    "    )\n",
    "\n",
    "# Convert lists to DataFrames\n",
    "df_reidentified = pd.DataFrame(reidentified_data[1:], columns=reidentified_data[0])\n",
    "df_not_reidentified = pd.DataFrame(not_reidentified_data[1:], columns=not_reidentified_data[0])\n",
    "df_all = pd.DataFrame(all_data[1:], columns=all_data[0])\n",
    "df_not_reidentified_labeled = df_all[df_all[\"uid\"].isin(df_not_reidentified[\"uid\"])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî§ Create 2-Gram Dictionary (Letters & Digits)\n",
    "\n",
    "This code creates a comprehensive dictionary of all possible **2-grams** (two-character combinations) that consist of lowercase letters and digits.\n",
    "\n",
    "1. **Character Sets:**\n",
    "   - `string.ascii_lowercase`: the lowercase English alphabet ('a' to 'z')\n",
    "   - `string.digits`: the digits '0' to '9'\n",
    "\n",
    "2. **2-Gram Types Generated:**\n",
    "   - **Letter-Letter (LL):** All combinations like `'aa'`, `'ab'`, ..., `'zz'` (26√ó26 = 676)\n",
    "   - **Digit-Digit (DD):** All combinations like `'00'`, `'01'`, ..., `'99'` (10√ó10 = 100)\n",
    "   - **Letter-Digit (LD):** All combinations like `'a0'`, `'a1'`, ..., `'z9'` (26√ó10 = 260)\n",
    "\n",
    "3. **Combining All 2-Grams:**\n",
    "   - All three types are concatenated into a single list.\n",
    "\n",
    "4. **Indexed Dictionary:**\n",
    "   - The `enumerate()` function is used to assign each 2-gram a unique index in `two_gram_dict`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate a dictionary of all possible 2-grams from letters and digits ---\n",
    "\n",
    "# Lowercase alphabet: 'a' to 'z'\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "# Digits: '0' to '9'\n",
    "digits = string.digits\n",
    "\n",
    "# Generate all letter-letter 2-grams (e.g., 'aa', 'ab', ..., 'zz')\n",
    "letter_letter_grams = [a + b for a in alphabet for b in alphabet]\n",
    "\n",
    "# Generate all digit-digit 2-grams (e.g., '00', '01', ..., '99')\n",
    "digit_digit_grams = [d1 + d2 for d1 in digits for d2 in digits]\n",
    "\n",
    "# Generate all letter-digit 2-grams (e.g., 'a0', 'a1', ..., 'z9')\n",
    "letter_digit_grams = [l + d for l in alphabet for d in digits]\n",
    "\n",
    "# Combine all generated 2-grams into one list\n",
    "all_two_grams = letter_letter_grams + letter_digit_grams + digit_digit_grams\n",
    "\n",
    "# Create a dictionary mapping index to each 2-gram\n",
    "two_gram_dict = {i: two_gram for i, two_gram in enumerate(all_two_grams)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß© Dataset Creation Based on Alice‚Äôs Encoding Scheme\n",
    "\n",
    "This section initializes the dataset objects depending on which encoding method Alice used. Each encoding requires a different preprocessing strategy for compatibility with downstream neural models.\n",
    "\n",
    "### 1. Bloom Filter (`\"BloomFilter\"`)\n",
    "- Uses binary Bloom filters to represent identifiers.\n",
    "- Loads `BloomFilterDataset` objects.\n",
    "- Stores the bit-length of the bloom filter.\n",
    "\n",
    "### 2. Tabulation MinHash (`\"TabMinHash\"`)\n",
    "- Applies a MinHash-based encoding.\n",
    "- Loads `TabMinHashDataset`.\n",
    "- Captures the length of each encoded vector.\n",
    "\n",
    "### 3. Two-Step Hash with One-Hot Encoding (`\"TwoStepHash\"`)\n",
    "- Extracts all **unique hash values** to build a consistent one-hot vector space.\n",
    "- Constructs datasets using `TwoStepHashDatasetOneHotEncoding`.\n",
    "\n",
    "> ‚öôÔ∏è All dataset constructors are passed:\n",
    "> - Whether the data is labeled\n",
    "> - The full 2-gram list (used as feature tokens)\n",
    "> - Additional encoding-specific configurations\n",
    "> - Dev mode toggle (for debugging or smaller runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1Ô∏è Bloom Filter Encoding\n",
    "if ENC_CONFIG[\"AliceAlgo\"] == \"BloomFilter\":\n",
    "    data_labeled = BloomFilterDataset(\n",
    "        df_reidentified,\n",
    "        is_labeled=True,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    data_test = BloomFilterDataset(\n",
    "        df_not_reidentified_labeled,\n",
    "        is_labeled=True,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    bloomfilter_length = len(df_reidentified[\"bloomfilter\"][0])\n",
    "\n",
    "# 2Ô∏è Tabulation MinHash Encoding\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TabMinHash\":\n",
    "    data_labeled = TabMinHashDataset(\n",
    "        df_reidentified,\n",
    "        is_labeled=True,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    data_test = TabMinHashDataset(\n",
    "        df_not_reidentified_labeled,\n",
    "        is_labeled=True,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    tabminhash_length = len(df_reidentified[\"tabminhash\"][0])\n",
    "\n",
    "# 3 Two-Step Hash Encoding (One-Hot Encoding Mode)\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\":\n",
    "    # Collect all unique integers across both reidentified and non-reidentified data\n",
    "    unique_ints_reid = set().union(*df_reidentified[\"twostephash\"])\n",
    "    unique_ints_not_reid = set().union(*df_not_reidentified_labeled[\"twostephash\"])\n",
    "    unique_ints_sorted = sorted(unique_ints_reid.union(unique_ints_not_reid))\n",
    "    unique_integers_dict = {i: val for i, val in enumerate(unique_ints_sorted)}\n",
    "\n",
    "    data_labeled = TwoStepHashDataset(\n",
    "        df_reidentified,\n",
    "        is_labeled=True,\n",
    "        all_integers=unique_ints_sorted,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )\n",
    "    data_test = TwoStepHashDataset(\n",
    "        df_not_reidentified_labeled,\n",
    "        is_labeled=True,\n",
    "        all_integers=unique_ints_sorted,\n",
    "        all_two_grams=all_two_grams,\n",
    "        dev_mode=GLOBAL_CONFIG[\"DevMode\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting & Loader Setup\n",
    "\n",
    "After preprocessing the encoded data, we divide it into training, validation, and test sets using PyTorch's `DataLoader` and `random_split`.\n",
    "\n",
    "### Dataset Proportions\n",
    "- The proportion for the training set is defined in `DEA_CONFIG[\"TrainSize\"]`.\n",
    "- The remainder is used for validation.\n",
    "\n",
    "### Splitting\n",
    "- `data_labeled` (the reidentified individuals) is split into:\n",
    "  - `data_train` for training\n",
    "  - `data_val` for validation\n",
    "- `data_not_labeled` (unidentified individuals) is used exclusively for testing.\n",
    "\n",
    "### Dataloader Configuration\n",
    "- **Training Loader**: shuffled for learning generalization.\n",
    "- **Validation Loader**: also shuffled to vary batches during evaluation.\n",
    "- **Test Loader**: also shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset split proportions\n",
    "train_size = int(DEA_CONFIG[\"TrainSize\"] * len(data_labeled))\n",
    "val_size = len(data_labeled) - train_size\n",
    "\n",
    "# Split the reidentified dataset into training and validation sets\n",
    "data_train, data_val = random_split(data_labeled, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training, validation, and testing\n",
    "dataloader_train = DataLoader(\n",
    "    data_train,\n",
    "    batch_size=DEA_CONFIG[\"BatchSize\"],\n",
    "    shuffle=True  # Important for training\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    data_val,\n",
    "    batch_size=DEA_CONFIG[\"BatchSize\"],\n",
    "    shuffle=True  # Allows variation in validation batches\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    data_test,\n",
    "    batch_size=DEA_CONFIG[\"BatchSize\"],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instantiation Based on Encoding Scheme\n",
    "\n",
    "The neural network model is selected dynamically based on the encoding technique used for Alice‚Äôs data.\n",
    "\n",
    "### Supported Models:\n",
    "\n",
    "- **BloomFilter** ‚Üí `BloomFilterToTwoGramClassifier`  \n",
    "  - Input: Binary vector (Bloom filter)  \n",
    "  - Output: 2-gram prediction\n",
    "\n",
    "- **TabMinHash** ‚Üí `TabMinHashToTwoGramClassifier`  \n",
    "  - Input: Tabulated MinHash signature  \n",
    "  - Output: 2-gram prediction\n",
    "\n",
    "- **TwoStepHash** ‚Üí `TwoStepHashToTwoGramClassifier`  \n",
    "  - Input: Length of the unique integers present\n",
    "  - Output: 2-gram predicition\n",
    "    \n",
    "Each model outputs predictions over the set of all possible 2-grams (`all_two_grams`), and the input dimension is dynamically configured based on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model based on selected encoding scheme\n",
    "\n",
    "if DEA_CONFIG[\"TestModel\"]:\n",
    "    if ENC_CONFIG[\"AliceAlgo\"] == \"BloomFilter\":\n",
    "        model = TestModel(\n",
    "            input_dim=bloomfilter_length,\n",
    "            output_dim=len(all_two_grams),\n",
    "            hidden_layer=2048,\n",
    "            num_layers=1,\n",
    "            dropout_rate=0.220451802221184,\n",
    "            activation_fn=\"relu\"\n",
    "        )\n",
    "    elif ENC_CONFIG[\"AliceAlgo\"] == \"TabMinHash\":\n",
    "        model = TestModel(\n",
    "            input_dim=bloomfilter_length,\n",
    "            output_dim=len(all_two_grams),\n",
    "            hidden_layer=2048,\n",
    "            num_layers=1,\n",
    "            dropout_rate=0.220451802221184,\n",
    "            activation_fn=\"relu\"\n",
    "        )\n",
    "    elif ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\":\n",
    "        model = TestModel(\n",
    "            input_dim=bloomfilter_length,\n",
    "            output_dim=len(all_two_grams),\n",
    "            hidden_layer=2048,\n",
    "            num_layers=1,\n",
    "            dropout_rate=0.220451802221184,\n",
    "            activation_fn=\"relu\"\n",
    "        )\n",
    "\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"BloomFilter\":\n",
    "    model = BloomFilterToTwoGramClassifier(\n",
    "        input_dim=bloomfilter_length,\n",
    "        output_dim=len(all_two_grams)\n",
    "    )\n",
    "\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TabMinHash\":\n",
    "    model = TabMinHashToTwoGramClassifier(\n",
    "        input_dim=tabminhash_length,\n",
    "        output_dim=len(all_two_grams)\n",
    "    )\n",
    "\n",
    "elif ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\":\n",
    "    model = TwoStepHashToTwoGramClassifier(\n",
    "        input_dim=len(unique_ints_sorted),\n",
    "        output_dim=len(all_two_grams)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Environment Setup\n",
    "This code initializes the core components needed for training a neural network model.\n",
    "\n",
    "1. TensorBoard Setup\n",
    "    - Creates unique run name by combining:\n",
    "    - Loss function type\n",
    "    - Optimizer choice\n",
    "    - Alice's algorithm\n",
    "    - Initializes TensorBoard writer in runs directory\n",
    "2. Device Configuration\n",
    "    - Automatically selects GPU if available, falls back to CPU\n",
    "    - Moves model to selected device\n",
    "3. Loss Functions\n",
    "    - `BCEWithLogitsLoss`: Binary Cross Entropy with Logits\n",
    "    - `MultiLabelSoftMarginLoss`: Multi-Label Soft Margin Loss\n",
    "4. Optimizers:\n",
    "    - `Adam`: Adaptive Moment Estimation\n",
    "    - `AdamW`: Adam with Weight Decay\n",
    "    - `SGD`: Stochastic Gradient Descent (with momentum)\n",
    "    - `RMSprop`: Root Mean Square Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup tensorboard logging\n",
    "run_name = \"\".join([\n",
    "    DEA_CONFIG[\"LossFunction:\"],\n",
    "    DEA_CONFIG[\"Optimizer\"],\n",
    "    ENC_CONFIG[\"AliceAlgo\"],\n",
    "    DEA_CONFIG[\"ActivationFunction\"],\n",
    "])\n",
    "tb_writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "# Setup compute device (GPU/CPU)\n",
    "compute_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(compute_device)\n",
    "\n",
    "# Initialize loss function\n",
    "match DEA_CONFIG[\"LossFunction:\"]:\n",
    "    case \"BCEWithLogitsLoss\":\n",
    "        criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "    case \"MultiLabelSoftMarginLoss\":\n",
    "        criterion = nn.MultiLabelSoftMarginLoss(reduction='mean')\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported loss function: {DEA_CONFIG['LossFunction:']}\")\n",
    "\n",
    "# Initialize optimizer\n",
    "match DEA_CONFIG[\"Optimizer\"]:\n",
    "    case \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=DEA_CONFIG[\"LearningRate\"])\n",
    "    case \"AdamW\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=DEA_CONFIG[\"LearningRate\"])\n",
    "    case \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(),\n",
    "                            lr=DEA_CONFIG[\"LearningRate\"],\n",
    "                            momentum=DEA_CONFIG[\"Momentum\"])\n",
    "    case \"RMSprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=DEA_CONFIG[\"LearningRate\"])\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported optimizer: {DEA_CONFIG['Optimizer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Early Stopping\n",
    "\n",
    "The function `train_model` orchestrates the training process for the neural network, including both training and validation phases for each epoch. It also utilizes **early stopping** to halt training when the validation loss fails to improve over multiple epochs, avoiding overfitting.\n",
    "\n",
    "### Key Phases:\n",
    "1. **Training Phase**: \n",
    "   - The model is trained on the `dataloader_train`, computing the training loss using the specified loss function (`criterion`) and optimizer. Gradients are calculated, and the model parameters are updated.\n",
    "  \n",
    "2. **Validation Phase**:\n",
    "   - The model is evaluated on the `dataloader_val` without updating weights. The validation loss is computed to track model performance on unseen data.\n",
    "\n",
    "3. **Logging**: \n",
    "   - Training and validation losses are logged to both the console and **TensorBoard** for tracking model performance during training.\n",
    "\n",
    "4. **Early Stopping**: \n",
    "   - If the validation loss does not improve after a certain number of epochs (defined by `DEA_CONFIG[\"Patience\"]`), the training process is halted to prevent overfitting.\n",
    "\n",
    "### Helper Functions:\n",
    "- `run_epoch`: Handles a single epoch, either for training or validation, depending on the flag `is_training`.\n",
    "- `log_metrics`: Logs the training and validation losses to the console and TensorBoard for each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 106.13it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 569.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27 - Train loss: 0.1502, Validation loss: 0.0686\n",
      "best_loss updated from  inf  to  0.06859889850020409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 138.12it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 578.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/27 - Train loss: 0.0624, Validation loss: 0.0602\n",
      "best_loss updated from  0.06859889850020409  to  0.060156600549817085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 135.93it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 570.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/27 - Train loss: 0.0533, Validation loss: 0.0535\n",
      "best_loss updated from  0.060156600549817085  to  0.05348928198218346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 146.96it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 625.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/27 - Train loss: 0.0428, Validation loss: 0.0463\n",
      "best_loss updated from  0.05348928198218346  to  0.04633831158280373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 155.23it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 634.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/27 - Train loss: 0.0327, Validation loss: 0.0410\n",
      "best_loss updated from  0.04633831158280373  to  0.040998317301273346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 152.62it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 674.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/27 - Train loss: 0.0247, Validation loss: 0.0370\n",
      "best_loss updated from  0.040998317301273346  to  0.03702921494841575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 155.27it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 613.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/27 - Train loss: 0.0183, Validation loss: 0.0344\n",
      "best_loss updated from  0.03702921494841575  to  0.03444989062845707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 155.71it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 282.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/27 - Train loss: 0.0136, Validation loss: 0.0336\n",
      "Early stopper counter incremented from  0  to  1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 154.01it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 613.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/27 - Train loss: 0.0102, Validation loss: 0.0321\n",
      "best_loss updated from  0.03444989062845707  to  0.03213000614196062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 150.51it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 643.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/27 - Train loss: 0.0079, Validation loss: 0.0313\n",
      "Early stopper counter incremented from  0  to  1 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 143.64it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 683.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/27 - Train loss: 0.0062, Validation loss: 0.0318\n",
      "Early stopper counter incremented from  1  to  2 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 154.79it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 624.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/27 - Train loss: 0.0050, Validation loss: 0.0324\n",
      "Early stopper counter incremented from  2  to  3 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 156.13it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 595.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/27 - Train loss: 0.0041, Validation loss: 0.0319\n",
      "Early stopper counter incremented from  3  to  4 / 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:00<00:00, 155.18it/s]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 731.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/27 - Train loss: 0.0034, Validation loss: 0.0329\n",
      "Early stopper counter incremented from  4  to  5 / 5\n",
      "Early stopping triggered at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader_train, dataloader_val, criterion, optimizer, device):\n",
    "    train_losses, val_losses = [], []\n",
    "    early_stopper = EarlyStopping(patience=DEA_CONFIG[\"Patience\"], min_delta=DEA_CONFIG[\"MinDelta\"], verbose=GLOBAL_CONFIG[\"Verbose\"])\n",
    "\n",
    "    for epoch in range(DEA_CONFIG[\"Epochs\"]):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = run_epoch(\n",
    "            model, dataloader_train, criterion, optimizer,\n",
    "            device, is_training=True, verbose=GLOBAL_CONFIG[\"Verbose\"]\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = run_epoch(\n",
    "            model, dataloader_val, criterion, optimizer,\n",
    "            device, is_training=False, verbose=GLOBAL_CONFIG[\"Verbose\"]\n",
    "        )\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Logging\n",
    "        log_metrics(train_loss, val_loss, epoch, DEA_CONFIG[\"Epochs\"])\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stopper(val_loss):\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def log_metrics(train_loss, val_loss, epoch, total_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{total_epochs} - \"\n",
    "          f\"Train loss: {train_loss:.4f}, \"\n",
    "          f\"Validation loss: {val_loss:.4f}\")\n",
    "    tb_writer.add_scalar(\"Loss/train\", train_loss, epoch + 1)\n",
    "    tb_writer.add_scalar(\"Loss/validation\", val_loss, epoch + 1)\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model, dataloader_train, dataloader_val,\n",
    "    criterion, optimizer, compute_device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Visualization over Epochs\n",
    "\n",
    "This code snippet generates a plot to visualize the **training loss** and **validation loss** across epochs. It's useful for tracking model performance during training and evaluating if overfitting is occurring (i.e., when validation loss starts increasing while training loss continues to decrease).\n",
    "\n",
    "### Key Elements:\n",
    "1. **Plotting the Losses**: \n",
    "   - The `train_losses` and `val_losses` are plotted over the epochs. \n",
    "   - The **blue line** represents the training loss, and the **red line** represents the validation loss.\n",
    "\n",
    "2. **Legend**: \n",
    "   - A legend is added to distinguish between training and validation losses.\n",
    "\n",
    "3. **Title and Labels**: \n",
    "   - The plot is titled \"Training and Validation Loss over Epochs\" for context.\n",
    "   - **X-axis** represents the epoch number, and **Y-axis** represents the loss value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation losses over epochs\n",
    "plt.plot(train_losses, label='Training loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation loss', color='red')\n",
    "\n",
    "# Adding a legend to the plot\n",
    "plt.legend()\n",
    "\n",
    "# Setting the title and labels for clarity\n",
    "plt.title(\"Training and Validation Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference and 2-Gram Comparison\n",
    "\n",
    "This code performs inference on the test data and compares the predicted 2-grams with the actual 2-grams, providing a performance evaluation based on the **Dice similarity coefficient**.\n",
    "\n",
    "### Key Steps:\n",
    "\n",
    "1. **Prepare for Evaluation**:\n",
    "   - The model is switched to **evaluation mode** (`model.eval()`), ensuring no gradient computation.\n",
    "   \n",
    "2. **Thresholding**:\n",
    "   - A threshold (`DEA_CONFIG[\"FilterThreshold\"]`) is applied to filter out low-probability predictions, retaining only the most confident predictions.\n",
    "\n",
    "3. **Inference and 2-Gram Scoring**:\n",
    "   - The model is applied to the batch, and the **logits** are converted into probabilities using the **sigmoid function**.\n",
    "   - The probabilities are then mapped to **2-gram scores**, and scores below the threshold are discarded.\n",
    "\n",
    "4. **Reconstructing Words**:\n",
    "   - For each sample in the batch, **2-grams** are reconstructed into words based on the filtered scores.\n",
    "\n",
    "5. **Performance Metrics**:\n",
    "   - The actual 2-grams (from the test dataset) are compared with the predicted 2-grams, and the **Dice similarity coefficient** is calculated for each sample.\n",
    "\n",
    "### Result:\n",
    "- The code generates a list `combined_results_performance`, which contains a detailed comparison for each UID, including:\n",
    "  - **Actual 2-grams** (from the test data)\n",
    "  - **Predicted 2-grams** (from the model)\n",
    "  - **Dice similarity** score indicating how similar the actual and predicted 2-grams are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec6339e8a864208b506965de3c151d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test loop:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'uid': '38221', 'actual_two_grams': ['an', 'hn', 'jo', 'la', 'nn', 'no', 'oh', 'ol', 'n5', '00', '12', '20', '51'], 'filtered_two_grams': ['an', 'jo', 'la', 'oh', '00', '20'], 'reconstructed_words': ['an', 'joh', 'la', '00', '20']}, {'uid': '31256', 'actual_two_grams': ['an', 'de', 'ea', 'eo', 'er', 'ge', 'nd', 'on', 'or', 'rg', 'rs', 'so', 'n5', '19', '51', '55', '92', '99'], 'filtered_two_grams': ['an', 'de', 'eo', 'er', 'ge', 'nd', 'on', 'or', 'rg', 'rs', 'so', '19', '51', '92', '99'], 'reconstructed_words': ['andeon', 'erge', 'orso', '192', '51', '99']}, {'uid': '89557', 'actual_two_grams': ['be', 'er', 'ju', 'ng', 'ob', 'ro', 'rt', 'tj', 'un', 'g3', '19', '28', '32', '66', '81', '96'], 'filtered_two_grams': ['be', 'er', 'ro', 'rt', '19', '81', '96'], 'reconstructed_words': ['bero', 'rt', '196', '81']}, {'uid': '77287', 'actual_two_grams': ['en', 'ev', 'im', 'ke', 'ms', 'ns', 'si', 've', 's1', '11', '19', '86', '98'], 'filtered_two_grams': ['en', 'ev', 'ke', 'ns', 'si', 've', 's1', '11', '19', '86', '98'], 'reconstructed_words': ['ensi', 'eve', 'ke', 's11986']}, {'uid': '16782', 'actual_two_grams': ['an', 'ea', 'er', 'ge', 'in', 'li', 'ng', 'nl', 'se', 'r5', '12', '19', '21', '51', '56', '95'], 'filtered_two_grams': ['an', 'in', 'li', 'ng', '12', '19', '95'], 'reconstructed_words': ['ang', 'in', 'li', '12', '195']}, {'uid': '4564', 'actual_two_grams': ['al', 'at', 'er', 'ew', 'he', 'le', 'll', 'ma', 'th', 'tt', 'wa', 'ww', 'r1', '11', '12', '19', '26', '48', '61', '94'], 'filtered_two_grams': ['al', 'at', 'er', 'ew', 'he', 'le', 'll', 'ma', 'th', 'tt', '11', '12', '19', '94'], 'reconstructed_words': ['aler', 'athew', 'll', 'ma', 'tt', '112', '194']}, {'uid': '27855', 'actual_two_grams': ['ao', 'at', 'ee', 'en', 'hl', 'ka', 'le', 'ns', 'sa', 'th', 'o3', '01', '10', '19', '31', '44', '94'], 'filtered_two_grams': ['ee', 'en', 'ka', 'le', 'th', '01', '19', '94'], 'reconstructed_words': ['een', 'ka', 'le', 'th', '0194']}, {'uid': '55004', 'actual_two_grams': ['bu', 'db', 'ed', 'fr', 'on', 're', 'rt', 'to', 'ur', 'n5', '01', '10', '19', '51', '59', '95'], 'filtered_two_grams': ['on', 're', 'rt', 'to', 'ur', '01', '10', '19', '51', '95'], 'reconstructed_words': ['on', 're', 'rto', 'ur', '010', '1951']}, {'uid': '84890', 'actual_two_grams': ['be', 'er', 'hi', 'it', 'ob', 'ro', 'rt', 'te', 'tw', 'wh', 'e1', '11', '16', '19', '49', '61', '94'], 'filtered_two_grams': ['be', 'er', 'ro', 'te', '16', '19', '94'], 'reconstructed_words': ['bero', 'te', '16', '194']}, {'uid': '60367', 'actual_two_grams': ['en', 'es', 'eu', 'ev', 'ge', 'ne', 'ns', 'st', 'te', 'ug', 've', 's1', '11', '12', '19', '21', '87', '98'], 'filtered_two_grams': ['en', 'es', 'ev', 'ne', 'ns', 'st', 'te', 've', 's1', '12', '19', '21', '98'], 'reconstructed_words': ['enesteve', 'ns12198']}, {'uid': '89428', 'actual_two_grams': ['ab', 'bn', 'ea', 'ey', 'hi', 'ie', 'ne', 'op', 'ph', 'so', 'y4', '11', '19', '21', '42', '50', '95'], 'filtered_two_grams': ['ne', '19', '41', '95'], 'reconstructed_words': ['ne', '195', '41']}, {'uid': '15958', 'actual_two_grams': ['ar', 'ez', 'ha', 'in', 'ma', 'ne', 'nm', 'on', 'ro', 'rt', 'sh', 'ti', 'z3', '11', '19', '31', '53', '95'], 'filtered_two_grams': ['ar', 'ez', 'ha', 'in', 'ma', 'ne', 'on', 'ro', 'rt', 'sh', 'ti', '11', '19', '31', '95'], 'reconstructed_words': ['aronez', 'ha', 'in', 'ma', 'rti', 'sh', '1195', '31']}, {'uid': '62708', 'actual_two_grams': ['ah', 'ev', 'gs', 'hu', 'in', 'li', 'ne', 'ng', 'ul', 'va', 's3', '13', '19', '31', '84', '98'], 'filtered_two_grams': ['in', 'li', 'ne', 'ng', 'ul', '13', '19', '31', '98'], 'reconstructed_words': ['ine', 'li', 'ng', 'ul', '13198']}, {'uid': '11247', 'actual_two_grams': ['ak', 'an', 'ee', 'en', 'gi', 'ia', 'in', 'ir', 'ke', 'na', 'ni', 'rg', 'vi', 'n3', '19', '29', '32', '59', '91', '95'], 'filtered_two_grams': ['an', 'en', 'gi', 'in', 'na', 'vi', '19', '95'], 'reconstructed_words': ['ana', 'en', 'gin', 'vi', '195']}, {'uid': '46767', 'actual_two_grams': ['ar', 'aw', 'ch', 'cr', 'dc', 'fo', 'ha', 'ic', 'or', 'ra', 'rd', 'ri', 'wf', 'd3', '12', '19', '21', '31', '94', '99'], 'filtered_two_grams': ['ar', 'ch', 'ha', 'ic', 'or', 'rd', 'ri', '12', '19', '21', '94', '99'], 'reconstructed_words': ['ard', 'cha', 'ic', 'ori', '12194', '99']}, {'uid': '14765', 'actual_two_grams': ['es', 'je', 'le', 'st', 'su', 'tl', 'tt', 'tu', 'us', 'ut', 'e1', '12', '19', '25', '39', '51', '93'], 'filtered_two_grams': ['es', 'le', '19', '25', '93'], 'reconstructed_words': ['es', 'le', '193', '25']}, {'uid': '56270', 'actual_two_grams': ['ar', 'dj', 'dw', 'ed', 'hn', 'jo', 'ns', 'oh', 'on', 'rd', 'so', 'wa', 'n2', '11', '19', '21', '22', '60', '96'], 'filtered_two_grams': ['ar', 'hn', 'jo', 'ns', 'oh', 'on', 'rd', 'so', 'wa', '19', '21', '96'], 'reconstructed_words': ['ard', 'hnsoh', 'jon', 'wa', '196', '21']}, {'uid': '17606', 'actual_two_grams': ['ar', 'de', 'en', 'es', 'is', 'ni', 'nn', 'pa', 'rz', 'se', 'sp', 'za', 'a6', '11', '19', '61', '73', '97'], 'filtered_two_grams': ['ar', 'de', 'en', 'es', 'is', 'nn', '11', '19', '97'], 'reconstructed_words': ['ar', 'denn', 'es', 'is', '1197']}, {'uid': '42674', 'actual_two_grams': ['ar', 'ch', 'es', 'ha', 'in', 'le', 'li', 'mo', 'na', 'ol', 'rl', 'sm', 'a1', '12', '19', '27', '38', '71', '93'], 'filtered_two_grams': ['ar', 'ch', 'es', 'ha', 'in', 'le', 'li', 'rl', '12', '19', '21', '71', '93'], 'reconstructed_words': ['arles', 'cha', 'in', 'li', '12193', '71']}, {'uid': '11834', 'actual_two_grams': ['am', 'bu', 'el', 'es', 'ja', 'll', 'me', 're', 'rr', 'sb', 'ur', 'l1', '01', '10', '12', '19', '21', '83', '98'], 'filtered_two_grams': ['am', 'el', 'es', 'll', 're', '12', '19', '21', '98'], 'reconstructed_words': ['am', 'ell', 'es', 're', '12198']}, {'uid': '98952', 'actual_two_grams': ['co', 'do', 'ez', 'hy', 'or', 'ot', 'ro', 'rt', 'te', 'th', 'yc', 'z6', '01', '19', '20', '62', '84', '98'], 'filtered_two_grams': ['or', 'ot', 'ro', 'th', '01', '19', '20', '98'], 'reconstructed_words': ['oroth', '0198', '20']}, {'uid': '37359', 'actual_two_grams': ['co', 'ec', 'er', 'ie', 'in', 'li', 'll', 'ns', 'ol', 'pi', 're', 'rr', 's9', '15', '19', '37', '51', '91', '93'], 'filtered_two_grams': ['co', 'er', 'in', 'li', 'll', 'ol', 're', '19', '93'], 'reconstructed_words': ['colin', 'ere', 'll', '193']}, {'uid': '6445', 'actual_two_grams': ['bs', 'co', 'di', 'hc', 'it', 'ju', 'mb', 'om', 'th', 'ud', 's7', '19', '24', '39', '41', '72', '93'], 'filtered_two_grams': ['it', 'th', '19', '24', '41', '93'], 'reconstructed_words': ['ith', '193', '241']}, {'uid': '63428', 'actual_two_grams': ['am', 'as', 'be', 'er', 'ga', 'mb', 'on', 'rg', 'st', 'to', 'n5', '12', '19', '21', '51', '71', '97'], 'filtered_two_grams': ['am', 'as', 'be', 'er', 'on', 'st', 'to', '12', '19', '21', '97'], 'reconstructed_words': ['am', 'aston', 'ber', '12197']}, {'uid': '91004', 'actual_two_grams': ['ar', 'av', 'da', 'ed', 'en', 'is', 'le', 'ne', 'rl', 'vi', 's1', '00', '02', '12', '20', '21', '22'], 'filtered_two_grams': ['ar', 'av', 'da', 'ed', 'en', 'is', 'le', 'ne', 'vi', 's1', '00', '02', '12', '20', '21', '22'], 'reconstructed_words': ['ar', 'avis120021', 'da', 'ed', 'ene', 'le', '22']}, {'uid': '37287', 'actual_two_grams': ['ch', 'ep', 'hn', 'ho', 'ic', 'jo', 'ls', 'ni', 'ol', 'os', 'ph', 'se', 's5', '14', '19', '41', '51', '76', '97'], 'filtered_two_grams': ['ch', 'ep', 'jo', 'ls', 'ni', 'ph', 'se', '14', '19', '41', '51', '97'], 'reconstructed_words': ['ch', 'eph', 'jo', 'lse', 'ni', '14197', '51']}, {'uid': '86051', 'actual_two_grams': ['am', 'ca', 'co', 'ec', 'en', 'he', 'il', 'le', 'll', 'mi', 'oh', 'n1', '01', '02', '10', '19', '20', '62', '96'], 'filtered_two_grams': ['am', 'en', 'il', 'le', 'll', 'mi', '01', '02', '10', '19', '20', '96'], 'reconstructed_words': ['amilen', 'll', '01020', '196']}, {'uid': '90446', 'actual_two_grams': ['an', 'be', 'er', 'nr', 'ob', 'ro', 'rt', 'ry', 'ts', 'ya', 's8', '19', '81', '91', '96', '99'], 'filtered_two_grams': ['an', 'er', 'ob', 'ro', 'ry', 'ya', '19', '96'], 'reconstructed_words': ['an', 'erob', 'rya', '196']}, {'uid': '71593', 'actual_two_grams': ['ar', 'ay', 'cl', 'kc', 'la', 'ma', 'on', 'rk', 'to', 'yt', 'n8', '19', '41', '82', '84', '98'], 'filtered_two_grams': ['ar', 'la', 'ma', 'on', '19', '41', '81', '82', '98'], 'reconstructed_words': ['ar', 'la', 'ma', 'on', '1981', '41', '82']}, {'uid': '76831', 'actual_two_grams': ['co', 'eg', 'es', 'gr', 'in', 'ne', 'nn', 'or', 'ov', 'ri', 'ro', 've', 's3', '11', '19', '31', '33', '52', '95'], 'filtered_two_grams': ['es', 'in', 'ne', 'ro', '19', '31', '95'], 'reconstructed_words': ['es', 'ine', 'ro', '195', '31']}, {'uid': '28481', 'actual_two_grams': ['br', 'cl', 'db', 'ff', 'fo', 'if', 'li', 'no', 'or', 'rd', 'ru', 'un', 'o5', '19', '25', '51', '52', '59', '95'], 'filtered_two_grams': ['ff', 'fo', 'li', 'or', 'rd', '19', '51'], 'reconstructed_words': ['fford', 'li', '19', '51']}, {'uid': '83691', 'actual_two_grams': ['aw', 'cy', 'hi', 'ia', 'il', 'ls', 'nt', 'on', 'so', 'th', 'wi', 'yn', 'n1', '11', '19', '46', '94'], 'filtered_two_grams': ['il', 'on', 'so', 'wi', 'n1', '11', '19', '94'], 'reconstructed_words': ['il', 'on1194', 'so', 'wi']}, {'uid': '68297', 'actual_two_grams': ['ad', 'al', 'da', 'ew', 'gu', 'il', 'ls', 'lu', 'on', 'pe', 'so', 'ua', 'up', 'wi', 'n1', '00', '12', '20', '21', '22'], 'filtered_two_grams': ['al', 'da', 'il', 'on', 'pe', 'so', 'n1', '00', '12', '20', '21', '22'], 'reconstructed_words': ['al', 'da', 'il', 'on1200', 'pe', 'so', '21', '22']}, {'uid': '68866', 'actual_two_grams': ['at', 'av', 'da', 'dm', 'id', 'ma', 'ta', 'vi', 'a4', '19', '27', '42', '71', '97'], 'filtered_two_grams': ['av', 'da', 'id', 'ma', 'vi', '19', '41', '71', '97'], 'reconstructed_words': ['avida', 'ma', '1971', '41']}, {'uid': '43685', 'actual_two_grams': ['el', 'ke', 'ku', 'll', 'ly', 'rt', 'tk', 'ur', 'y1', '11', '12', '19', '25', '51', '57', '95'], 'filtered_two_grams': ['el', 'ke', 'll', 'ly', 'ur', '11', '19', '51', '95'], 'reconstructed_words': ['elly', 'ke', 'ur', '11951']}, {'uid': '18844', 'actual_two_grams': ['av', 'da', 'dm', 'er', 'id', 'il', 'le', 'll', 'mi', 'vi', 'r6', '19', '25', '50', '51', '62', '95'], 'filtered_two_grams': ['av', 'da', 'er', 'id', 'il', 'le', 'll', 'mi', 'vi', '19', '51', '95'], 'reconstructed_words': ['avida', 'er', 'ile', 'll', 'mi', '1951']}, {'uid': '15011', 'actual_two_grams': ['ep', 'er', 'he', 'in', 'nh', 'or', 'pw', 'ri', 'rt', 'th', 'wo', 'h4', '19', '28', '42', '81', '92', '99'], 'filtered_two_grams': ['er', 'he', 'in', 'ri', 'th', '19', '28', '81', '99'], 'reconstructed_words': ['erin', 'he', 'th', '199', '281']}, {'uid': '57159', 'actual_two_grams': ['an', 'es', 'fr', 'ge', 'hu', 'kh', 'nk', 'ra', 'ug', 's1', '11', '19', '87', '98'], 'filtered_two_grams': ['an', 'es', 'fr', 'ra', 's1', '11', '19', '98'], 'reconstructed_words': ['an', 'es1198', 'fra']}, {'uid': '1237', 'actual_two_grams': ['aa', 'an', 'au', 'dr', 'er', 'nd', 'ra', 'sa', 'ue', 'r1', '02', '10', '19', '24', '41', '74', '97'], 'filtered_two_grams': ['an', 'er', 'nd', 'ra', 'sa', '01', '10', '19', '97'], 'reconstructed_words': ['and', 'era', 'sa', '010', '197']}, {'uid': '61389', 'actual_two_grams': ['am', 'fl', 'if', 'ja', 'ly', 'mi', 'nn', 'yn', 'n6', '19', '25', '51', '62', '77', '97'], 'filtered_two_grams': ['am', '19', '25', '51', '77', '97'], 'reconstructed_words': ['am', '1977', '251']}, {'uid': '85467', 'actual_two_grams': ['am', 'dw', 'ia', 'il', 'li', 'll', 'lo', 'ms', 'oy', 'wi', 'yd', 's1', '12', '19', '21', '52', '91', '95'], 'filtered_two_grams': ['am', 'ia', 'il', 'li', 'll', 'ms', 'wi', 's1', '12', '19', '95'], 'reconstructed_words': ['ams12', 'ia', 'ili', 'll', 'wi', '195']}, {'uid': '57782', 'actual_two_grams': ['ar', 'en', 'ev', 'fa', 'nf', 'ns', 'or', 'rn', 'rt', 'st', 'sw', 'te', 'th', 've', 'wo', 'h1', '12', '19', '29', '82', '91', '98'], 'filtered_two_grams': ['ar', 'en', 'st', '12', '19', '91', '98'], 'reconstructed_words': ['ar', 'en', 'st', '12', '191', '98']}, {'uid': '22328', 'actual_two_grams': ['dr', 'ed', 'ee', 'es', 'ev', 'il', 'ld', 'mi', 're', 've', 's1', '08', '10', '19', '71', '81', '97'], 'filtered_two_grams': ['es', 'il', 'mi', 're', 've', 's1', '10', '19', '81', '97'], 'reconstructed_words': ['es10', 'il', 'mi', 're', 've', '197', '81']}, {'uid': '96819', 'actual_two_grams': ['an', 'br', 'er', 'ey', 'je', 'le', 'nt', 'ra', 'rr', 'ry', 'tl', 'yb', 'y8', '19', '31', '66', '83', '96'], 'filtered_two_grams': ['an', 'er', 'le', 'ra', 'ry', '19', '31', '96'], 'reconstructed_words': ['an', 'era', 'le', 'ry', '196', '31']}, {'uid': '63022', 'actual_two_grams': ['au', 'co', 'er', 'lc', 'os', 'pa', 'pe', 'sp', 'ul', 'r6', '19', '61', '69', '91', '96'], 'filtered_two_grams': ['au', 'er', 'pa', 'ul', '16', '19', '61', '96'], 'reconstructed_words': ['aul', 'er', 'pa', '16196']}, {'uid': '29446', 'actual_two_grams': ['ac', 'an', 'ck', 'eg', 'gu', 'ie', 'ja', 'ki', 'ma', 'uz', 'zm', 'n1', '01', '11', '13', '19', '30', '47', '94'], 'filtered_two_grams': ['an', 'ck', 'ie', 'ja', 'ma', 'n1', '11', '19', '94'], 'reconstructed_words': ['an1194', 'ck', 'ie', 'ja', 'ma']}, {'uid': '72014', 'actual_two_grams': ['av', 'da', 'dw', 'hi', 'id', 'it', 'te', 'vi', 'wh', 'e4', '19', '27', '42', '71', '73', '97'], 'filtered_two_grams': ['av', 'da', 'id', 'te', 'vi', '19', '71', '97'], 'reconstructed_words': ['avida', 'te', '1971']}, {'uid': '56171', 'actual_two_grams': ['ac', 'an', 'cu', 'do', 'hm', 'ma', 'na', 'nn', 'on', 'sh', 'us', 'n1', '01', '12', '19', '20', '47', '94'], 'filtered_two_grams': ['an', 'do', 'ma', 'na', 'nn', 'on', 'sh', 'n1', '01', '12', '19', '94'], 'reconstructed_words': ['ana', 'donn12', 'ma', 'sh', '0194']}, {'uid': '78943', 'actual_two_grams': ['ag', 'ba', 'ce', 'eb', 'ey', 'gl', 'jo', 'le', 'oy', 'yc', 'y7', '19', '29', '51', '72', '91', '95'], 'filtered_two_grams': ['ey', 'le', '19', '29', '91', '95'], 'reconstructed_words': ['ey', 'le', '191', '295']}, {'uid': '76710', 'actual_two_grams': ['an', 'as', 'er', 'he', 'ho', 'ma', 'nt', 'om', 'rm', 'th', 's1', '11', '12', '19', '28', '38', '81', '93'], 'filtered_two_grams': ['an', 'as', 'er', 'he', 'ma', 'th', '11', '19', '28', '81', '93'], 'reconstructed_words': ['an', 'as', 'er', 'he', 'ma', 'th', '1193', '281']}, {'uid': '85538', 'actual_two_grams': ['ac', 'av', 'ck', 'da', 'dh', 'et', 'ha', 'id', 'ke', 'tt', 'vi', 't6', '19', '31', '63', '70', '97'], 'filtered_two_grams': ['av', 'da', 'ha', 'id', 'vi', '19', '31', '97'], 'reconstructed_words': ['avida', 'ha', '197', '31']}, {'uid': '31765', 'actual_two_grams': ['be', 'el', 'ew', 'is', 'le', 'll', 'sb', 'wi', 'l5', '19', '51', '55', '77', '97'], 'filtered_two_grams': ['el', 'ew', 'is', 'le', 'll', 'wi', '19', '51', '97'], 'reconstructed_words': ['elewis', 'll', '197', '51']}, {'uid': '41681', 'actual_two_grams': ['ad', 'an', 'ck', 'da', 'di', 'ic', 'is', 'ki', 'la', 'nd', 'ol', 'on', 'so', 'yo', 'n8', '19', '31', '69', '83', '96'], 'filtered_two_grams': ['an', 'ck', 'ic', 'la', 'nd', 'on', '19', '31', '69', '96'], 'reconstructed_words': ['and', 'ck', 'ic', 'la', 'on', '1969', '31']}, {'uid': '66449', 'actual_two_grams': ['an', 'be', 'et', 'in', 'ma', 'nm', 'tt', 'ty', 'yi', 'n1', '00', '01', '12', '20', '26', '62'], 'filtered_two_grams': ['an', 'be', 'et', 'in', 'ma', 'tt', 'n1', '00', '01', '12', '20'], 'reconstructed_words': ['an12001', 'bett', 'in', 'ma']}, {'uid': '29998', 'actual_two_grams': ['ad', 'am', 'da', 'ds', 'ei', 'go', 'in', 'ld', 'mg', 'ol', 'st', 'te', 'n8', '11', '19', '31', '79', '83', '97'], 'filtered_two_grams': ['in', 'st', '11', '19', '97'], 'reconstructed_words': ['in', 'st', '1197']}, {'uid': '60430', 'actual_two_grams': ['al', 'ch', 'er', 'lt', 'ly', 'nc', 'rl', 'te', 'wa', 'yn', 'h3', '11', '19', '21', '32', '48', '94'], 'filtered_two_grams': ['al', 'er', 'te', 'wa', '11', '19', '31', '94'], 'reconstructed_words': ['al', 'er', 'te', 'wa', '1194', '31']}, {'uid': '26139', 'actual_two_grams': ['ay', 'cc', 'cr', 'ct', 'ec', 'he', 'mc', 'or', 'ra', 'rm', 'to', 'y7', '01', '10', '19', '67', '71', '96'], 'filtered_two_grams': ['or', 'ra', 'to', '01', '10', '19', '71', '96'], 'reconstructed_words': ['ora', 'to', '010', '196', '71']}, {'uid': '61112', 'actual_two_grams': ['an', 'co', 'dy', 'er', 'ma', 'nd', 'oo', 'op', 'pe', 'yc', 'r3', '11', '19', '31', '38', '93'], 'filtered_two_grams': ['an', 'co', 'er', 'ma', 'oo', 'pe', '19', '31', '38', '93'], 'reconstructed_words': ['an', 'coo', 'er', 'ma', 'pe', '1931', '38']}, {'uid': '24302', 'actual_two_grams': ['ap', 'at', 'ee', 'en', 'er', 'hl', 'ka', 'le', 'na', 'nn', 'pe', 'pp', 'th', 'r3', '11', '19', '21', '32', '77', '97'], 'filtered_two_grams': ['ee', 'en', 'er', 'le', 'nn', 'th', '19', '97'], 'reconstructed_words': ['eenn', 'er', 'le', 'th', '197']}, {'uid': '78196', 'actual_two_grams': ['an', 'fa', 'ff', 'if', 'ny', 'ta', 'ti', 'yt', 'n4', '14', '19', '41', '96', '99'], 'filtered_two_grams': ['an', '14', '19', '41', '96', '99'], 'reconstructed_words': ['an', '14196', '99']}, {'uid': '11704', 'actual_two_grams': ['al', 'au', 'dl', 'do', 'er', 'la', 'ld', 'na', 'on', 'ue', 'r9', '19', '31', '92', '93', '99'], 'filtered_two_grams': ['al', 'do', 'er', 'la', 'ld', 'na', 'on', '19', '31', '91', '92', '99'], 'reconstructed_words': ['ala', 'dona', 'er', 'ld', '191', '31', '92', '99']}, {'uid': '83246', 'actual_two_grams': ['ar', 'ep', 'er', 'ha', 'hh', 'jo', 'os', 'pe', 'ph', 'rp', 'se', 'r3', '19', '34', '41', '58', '95'], 'filtered_two_grams': ['ar', 'ep', 'er', 'jo', 'os', 'ph', 'se', '19', '95'], 'reconstructed_words': ['ar', 'eph', 'er', 'jose', '195']}, {'uid': '68304', 'actual_two_grams': ['am', 'ar', 'ca', 'en', 'es', 'ja', 'me', 'nj', 'rm', 's6', '13', '19', '31', '61', '70', '97'], 'filtered_two_grams': ['am', 'ar', 'ca', 'en', 'es', 'ja', 'me', '19', '31', '97'], 'reconstructed_words': ['amen', 'ar', 'ca', 'es', 'ja', '197', '31']}, {'uid': '83181', 'actual_two_grams': ['co', 'hi', 'il', 'ip', 'li', 'll', 'ot', 'ph', 'ps', 'sc', 'tp', 'tt', 's3', '19', '35', '39', '51', '93'], 'filtered_two_grams': ['co', 'il', 'li', 'll', '19', '31', '93'], 'reconstructed_words': ['co', 'ili', 'll', '1931']}, {'uid': '8446', 'actual_two_grams': ['gp', 'hi', 'in', 'ip', 'ir', 'ng', 'ph', 'pp', 'ps', 'rv', 'vi', 's1', '01', '10', '11', '19', '85', '98'], 'filtered_two_grams': ['hi', 'in', 's1', '01', '10', '19', '98'], 'reconstructed_words': ['hin', 's10198']}, {'uid': '22099', 'actual_two_grams': ['ar', 'be', 'et', 'go', 'rg', 'tt', 'ty', 'ya', 'o6', '18', '19', '37', '61', '81', '93'], 'filtered_two_grams': ['ar', 'be', 'et', 'tt', '18', '19', '81', '93'], 'reconstructed_words': ['ar', 'bett', '18193']}, {'uid': '20798', 'actual_two_grams': ['di', 'ed', 'er', 'hw', 'il', 'it', 'ke', 'lk', 'me', 'on', 're', 'rs', 'so', 'th', 'wi', 'n4', '19', '48', '81', '88', '98'], 'filtered_two_grams': ['er', 'on', 'rs', 'so', 'th', '19', '41', '81', '98'], 'reconstructed_words': ['erson', 'th', '1981', '41']}, {'uid': '76922', 'actual_two_grams': ['ar', 'dl', 'do', 'dw', 'ed', 'le', 'ou', 'rd', 'ux', 'wa', 'x1', '00', '02', '03', '10', '20', '22'], 'filtered_two_grams': ['ar', 'do', 'rd', 'wa', '00', '01', '02', '03', '10', '20'], 'reconstructed_words': ['ardo', 'wa', '0010203']}, {'uid': '10366', 'actual_two_grams': ['ai', 'el', 'ga', 'in', 'jo', 'lg', 'oe', 'n6', '19', '60', '69', '91', '96'], 'filtered_two_grams': ['el', 'in', 'jo', '19', '60', '61', '91', '96'], 'reconstructed_words': ['el', 'in', 'jo', '191', '60', '61', '96']}, {'uid': '49899', 'actual_two_grams': ['ek', 'im', 'is', 'ki', 'lo', 'mu', 'ou', 'ra', 'se', 'ui', 'ur', 'a2', '12', '19', '21', '79', '97'], 'filtered_two_grams': ['is', 'ra', '12', '19', '21', '97'], 'reconstructed_words': ['is', 'ra', '12197']}, {'uid': '50587', 'actual_two_grams': ['ab', 'ar', 'ba', 'br', 'da', 'en', 'es', 'nd', 'ne', 're', 'rn', 's1', '11', '12', '19', '21', '46', '94'], 'filtered_two_grams': ['ar', 'da', 'en', 'es', 'nd', 're', 's1', '11', '12', '19', '21'], 'reconstructed_words': ['arenda', 'es11219']}, {'uid': '34570', 'actual_two_grams': ['al', 'an', 'fl', 'la', 'ly', 'nf', 'y9', '19', '29', '42', '91', '92', '94'], 'filtered_two_grams': ['al', 'an', 'la', '19', '29', '42', '91', '94'], 'reconstructed_words': ['alan', '191', '2942']}, {'uid': '82543', 'actual_two_grams': ['an', 'ar', 'da', 'et', 'ga', 'ma', 'nt', 're', 'rg', 'td', 't1', '07', '10', '19', '54', '71', '95'], 'filtered_two_grams': ['an', 'ar', 'et', 'ga', 'ma', 're', 'rg', '01', '10', '19', '71', '95'], 'reconstructed_words': ['an', 'aret', 'ga', 'ma', 'rg', '010', '195', '71']}, {'uid': '31743', 'actual_two_grams': ['ab', 'bu', 'gg', 'gs', 'is', 'li', 'sa', 'ug', 's7', '19', '28', '72', '81', '98'], 'filtered_two_grams': ['is', 'li', '19', '81', '98'], 'reconstructed_words': ['is', 'li', '1981']}, {'uid': '35122', 'actual_two_grams': ['ar', 'at', 'ea', 'ew', 'he', 'ma', 'rs', 'sh', 'th', 'tt', 'ws', 's1', '01', '10', '16', '19', '61', '89', '98'], 'filtered_two_grams': ['ar', 'at', 'ew', 'he', 'ma', 'th', 'tt', 's1', '10', '16', '19', '61', '89'], 'reconstructed_words': ['ar', 'athew', 'ma', 'tt', 's10', '1619', '89']}, {'uid': '14974', 'actual_two_grams': ['aw', 'ch', 'el', 'er', 'es', 'ls', 're', 'sa', 'sc', 'te', 'we', 'h9', '00', '03', '20', '42', '94'], 'filtered_two_grams': ['be', 'el', 'er', 'es', 're', '00', '19', '20'], 'reconstructed_words': ['bel', 'eres', '00', '19', '20']}, {'uid': '30463', 'actual_two_grams': ['ar', 'du', 'kd', 'ma', 'nn', 'rk', 'un', 'n4', '15', '19', '41', '51', '59', '95'], 'filtered_two_grams': ['ar', 'ma', 'rk', '19', '41', '51', '95'], 'reconstructed_words': ['ark', 'ma', '1951', '41']}, {'uid': '14557', 'actual_two_grams': ['en', 'er', 'fe', 'fl', 'if', 'je', 'ly', 'ni', 'nn', 'rf', 'yn', 'n3', '11', '19', '31', '33', '93', '99'], 'filtered_two_grams': ['en', 'er', 'je', 'ni', 'nn', '19', '31', '99'], 'reconstructed_words': ['eni', 'er', 'je', 'nn', '199', '31']}, {'uid': '52993', 'actual_two_grams': ['cn', 'ee', 'el', 'en', 'ey', 'he', 'le', 'mc', 'ne', 'nm', 'y5', '19', '25', '45', '51', '52', '94'], 'filtered_two_grams': ['ee', 'el', 'en', 'ey', 'he', 'le', 'ne', '19', '25', '51', '94'], 'reconstructed_words': ['eeleney', 'he', '194', '251']}, {'uid': '26342', 'actual_two_grams': ['di', 'ed', 'em', 'in', 'jo', 'me', 'na', 'os', 'se', 'a9', '19', '31', '89', '93', '98'], 'filtered_two_grams': ['in', 'jo', 'se', '19', '31', '89', '98'], 'reconstructed_words': ['in', 'jo', 'se', '1989', '31']}, {'uid': '82052', 'actual_two_grams': ['ab', 'ad', 'ar', 'ba', 'di', 'en', 'ie', 'ka', 'na', 're', 'e1', '11', '14', '19', '38', '41', '93'], 'filtered_two_grams': ['ar', 'en', '11', '19', '41', '93'], 'reconstructed_words': ['ar', 'en', '1193', '41']}, {'uid': '55980', 'actual_two_grams': ['an', 'dr', 'ew', 'fr', 'nd', 'os', 're', 'ro', 'st', 'wf', 't4', '19', '21', '22', '42', '56', '95'], 'filtered_two_grams': ['an', 'dr', 'ew', 'nd', 'ro', '19', '21', '22', '42', '95'], 'reconstructed_words': ['andro', 'ew', '195', '21', '22', '42']}, {'uid': '82097', 'actual_two_grams': ['ar', 'bb', 'eb', 'jo', 'ma', 'ow', 'ry', 'we', 'yj', 'b6', '19', '49', '67', '71', '94'], 'filtered_two_grams': ['ar', 'ma', 'ow', 'ry', 'we', '19', '61', '71', '94'], 'reconstructed_words': ['ary', 'ma', 'owe', '194', '61', '71']}, {'uid': '42123', 'actual_two_grams': ['am', 'es', 'hi', 'it', 'ja', 'me', 'sw', 'te', 'wh', 'e1', '00', '01', '15', '20', '52'], 'filtered_two_grams': ['am', 'es', 'hi', 'ja', 'me', '00', '20', '51'], 'reconstructed_words': ['ames', 'hi', 'ja', '00', '20', '51']}, {'uid': '85617', 'actual_two_grams': ['av', 'aw', 'da', 'dl', 'id', 'la', 'on', 'so', 'vi', 'ws', 'n7', '19', '51', '75', '91', '99'], 'filtered_two_grams': ['av', 'da', 'id', 'la', 'on', 'so', 'vi', '19', '51'], 'reconstructed_words': ['avida', 'la', 'on', 'so', '19', '51']}, {'uid': '79459', 'actual_two_grams': ['as', 'ch', 'hi', 'ho', 'hu', 'in', 'ma', 'ns', 'om', 'sh', 'tc', 'th', 'ut', 's7', '19', '29', '72', '90', '91', '99'], 'filtered_two_grams': ['as', 'hi', 'ho', 'in', 'ma', 'om', 'sh', 'th', 's7', '19', '29', '91', '99'], 'reconstructed_words': ['ashin', 'homa', 'th', 's7', '191', '299']}, {'uid': '19764', 'actual_two_grams': ['ar', 'ea', 'kl', 'le', 'ma', 'rk', 'a6', '01', '10', '19', '61', '95', '99'], 'filtered_two_grams': ['ar', 'le', 'ma', 'rk', '10', '19', '61', '95', '99'], 'reconstructed_words': ['ark', 'le', 'ma', '10', '195', '61', '99']}, {'uid': '62424', 'actual_two_grams': ['am', 'ar', 'da', 'ez', 'in', 'li', 'ma', 'nd', 'ne', 'rt', 'ti', 'z9', '01', '19', '20', '55', '92', '95'], 'filtered_two_grams': ['am', 'ar', 'da', 'ez', 'in', 'li', 'ma', 'nd', 'ne', 'rt', 'ti', '01', '19', '20', '55', '95'], 'reconstructed_words': ['amartinda', 'ez', 'li', 'ne', '01955', '20']}, {'uid': '37552', 'actual_two_grams': ['co', 'fu', 'or', 'rr', 'ru', 'ry', 'sc', 'uf', 'us', 'y1', '12', '19', '25', '51', '93', '99'], 'filtered_two_grams': ['19', '21', '51', '99'], 'reconstructed_words': ['199', '21', '51']}, {'uid': '48691', 'actual_two_grams': ['ar', 'ch', 'dw', 'en', 'ha', 'ic', 'rd', 're', 'ri', 'rr', 'wa', 'n4', '17', '19', '41', '71', '72', '97'], 'filtered_two_grams': ['ar', 'ch', 'en', 'ha', 'ic', 'rd', 're', 'ri', '19', '71', '72', '97'], 'reconstructed_words': ['ard', 'cha', 'en', 'ic', 're', 'ri', '1971', '72']}, {'uid': '92285', 'actual_two_grams': ['bu', 'ep', 'et', 'hb', 'jo', 'ke', 'os', 'ph', 'rk', 'se', 'tt', 'ur', 't3', '17', '19', '31', '71', '97'], 'filtered_two_grams': ['ep', 'jo', 'os', 'se', '19', '71', '97'], 'reconstructed_words': ['ep', 'jose', '1971']}, {'uid': '58169', 'actual_two_grams': ['al', 'an', 'en', 'fr', 'ka', 'le', 'll', 'nk', 'ra', 'n9', '19', '40', '91', '94', '99'], 'filtered_two_grams': ['al', 'an', 'en', 'fr', 'le', 'll', 'ra', '19', '91', '94'], 'reconstructed_words': ['alen', 'an', 'fra', 'll', '191', '94']}, {'uid': '41341', 'actual_two_grams': ['ah', 'bo', 'de', 'eb', 'ho', 'ht', 'mp', 'om', 'on', 'or', 'ps', 'ra', 'so', 'th', 'n9', '11', '19', '41', '91', '94'], 'filtered_two_grams': ['ah', 'bo', 'de', 'ho', 'on', 'so', 'th', '11', '19', '91', '94'], 'reconstructed_words': ['ahon', 'bo', 'de', 'so', 'th', '1191', '94']}, {'uid': '5435', 'actual_two_grams': ['an', 'at', 'er', 'ha', 'he', 'ka', 'ks', 'nh', 'nk', 'rn', 'th', 's1', '11', '19', '81', '98'], 'filtered_two_grams': ['at', 'er', 'he', 'ka', 'th', '11', '19', '81', '98'], 'reconstructed_words': ['ather', 'ka', '11981']}, {'uid': '28824', 'actual_two_grams': ['ar', 'be', 'ca', 'cc', 'eb', 'ec', 'ol', 'os', 're', 'ro', 'so', 'l3', '11', '19', '31', '39', '93'], 'filtered_two_grams': ['ar', 'be', 'ca', 'eb', 'ec', 're', 'ro', '11', '19', '31', '93'], 'reconstructed_words': ['arebeca', 'ro', '11931']}, {'uid': '36903', 'actual_two_grams': ['an', 'de', 'er', 'ez', 'ha', 'he', 'na', 'nd', 'nh', 'nn', 'no', 'on', 'rn', 'sh', 'z3', '19', '23', '31', '32', '76', '97'], 'filtered_two_grams': ['an', 'de', 'er', 'ha', 'he', 'na', 'nd', 'nn', 'on', 'rn', 'sh', '19', '23', '31', '97'], 'reconstructed_words': ['ana', 'dernd', 'ha', 'he', 'nn', 'on', 'sh', '197', '231']}, {'uid': '42624', 'actual_two_grams': ['am', 'fl', 'ly', 'mf', 'nn', 'sa', 'yn', 'n3', '18', '19', '31', '81', '89', '98'], 'filtered_two_grams': ['am', '18', '19', '81', '87', '98'], 'reconstructed_words': ['am', '181987']}, {'uid': '60333', 'actual_two_grams': ['ar', 'at', 'ca', 'ew', 'he', 'lm', 'ma', 'ol', 'ro', 'th', 'tt', 'ws', 's1', '12', '19', '21', '45', '91', '94'], 'filtered_two_grams': ['ar', 'at', 'ew', 'he', 'ma', 'ro', 'th', 'tt', '12', '19', '94'], 'reconstructed_words': ['aro', 'athew', 'ma', 'tt', '12', '194']}, {'uid': '94663', 'actual_two_grams': ['ar', 'en', 'et', 'ga', 'la', 'ma', 're', 'rg', 'rs', 'se', 'tl', 'n2', '19', '29', '91', '92', '99'], 'filtered_two_grams': ['ar', 'en', 'et', 'ga', 'ma', 're', 'rg', '19', '91', '99'], 'reconstructed_words': ['aren', 'et', 'ga', 'ma', 'rg', '191', '99']}, {'uid': '44784', 'actual_two_grams': ['ac', 'al', 'ce', 'ck', 'es', 'ic', 'ks', 'li', 'st', 'ta', 's4', '19', '21', '42', '65', '96'], 'filtered_two_grams': ['ac', 'al', 'ce', 'ck', 'es', 'ic', 'st', '19', '22', '65', '96'], 'reconstructed_words': ['acest', 'al', 'ck', 'ic', '1965', '22']}, {'uid': '12636', 'actual_two_grams': ['ac', 'cq', 'ej', 'el', 'es', 'in', 'ja', 'jo', 'li', 'ne', 'on', 'qu', 'ue', 's1', '11', '12', '19', '21', '22', '41', '94'], 'filtered_two_grams': ['ac', 'el', 'es', 'in', 'ja', 'jo', 'li', 'ne', 'on', 's1', '12', '19', '21'], 'reconstructed_words': ['ac', 'elines1219', 'ja', 'jon']}, {'uid': '79403', 'actual_two_grams': ['ac', 'cs', 'de', 'er', 'is', 'ny', 'sa', 'sn', 'ss', 'yd', 'r7', '19', '23', '31', '50', '72', '95'], 'filtered_two_grams': ['de', 'er', 'is', 'sa', '19', '23', '31', '95'], 'reconstructed_words': ['der', 'isa', '195', '231']}, {'uid': '67990', 'actual_two_grams': ['ar', 'br', 'ea', 'it', 'lb', 'on', 'pe', 'ri', 'rl', 'to', 'tt', 'n6', '19', '21', '53', '62', '95'], 'filtered_two_grams': ['ar', 'on', 'to', '19', '53', '95'], 'reconstructed_words': ['ar', 'on', 'to', '1953']}, {'uid': '1984', 'actual_two_grams': ['am', 'ar', 'de', 'ed', 'ep', 'es', 'ie', 'mi', 'mm', 'pa', 're', 'sa', 's1', '11', '16', '19', '60', '61', '96'], 'filtered_two_grams': ['ar', 'es', 'ie', 're', 's1', '19', '61', '96'], 'reconstructed_words': ['ares1961', 'ie']}, {'uid': '17565', 'actual_two_grams': ['at', 'ep', 'er', 'je', 'me', 'om', 'on', 'pa', 'ro', 'rs', 'so', 'te', 'tt', 'n5', '19', '51', '55', '66', '96'], 'filtered_two_grams': ['er', 'on', 'rs', 'so', '19', '51', '96'], 'reconstructed_words': ['erson', '196', '51']}, {'uid': '38865', 'actual_two_grams': ['de', 'en', 'hi', 'il', 'ip', 'jo', 'li', 'll', 'or', 'ph', 'pj', 'rd', 'n4', '11', '19', '41', '73', '97'], 'filtered_two_grams': ['en', 'il', 'li', 'll', '11', '19', '41', '97'], 'reconstructed_words': ['en', 'ili', 'll', '1197', '41']}, {'uid': '73499', 'actual_two_grams': ['ar', 'em', 'en', 'ez', 'in', 'ir', 'ma', 'ne', 're', 'rt', 'ti', 'z2', '19', '22', '25', '51', '52', '95'], 'filtered_two_grams': ['ar', 'em', 'en', 'ez', 'in', 'ir', 'ma', 'ne', 're', 'rt', 'z1', '19', '25', '51', '52', '95'], 'reconstructed_words': ['arema', 'enez1951', 'in', 'irt', '252']}, {'uid': '81604', 'actual_two_grams': ['ar', 'ca', 'cc', 'er', 'es', 'ey', 'le', 'mc', 'rv', 'sl', 've', 'we', 'ym', 'r8', '19', '29', '49', '82', '91', '94'], 'filtered_two_grams': ['ar', 'ca', 'er', 'le', '19', '91', '94'], 'reconstructed_words': ['ar', 'ca', 'er', 'le', '191', '94']}, {'uid': '55766', 'actual_two_grams': ['es', 'ge', 'hn', 'jo', 'ns', 'oh', 'rg', 'st', 'tu', 'ur', 's8', '19', '27', '46', '71', '82', '94'], 'filtered_two_grams': ['es', 'jo', 'ns', 'oh', 'st', '19', '46', '71', '94'], 'reconstructed_words': ['est', 'joh', 'ns', '1946', '71']}, {'uid': '93915', 'actual_two_grams': ['ae', 'af', 'ch', 'el', 'fa', 'ic', 'lp', 'op', 'ov', 'po', 'ra', 'vi', 'h1', '11', '13', '19', '31', '62', '96'], 'filtered_two_grams': ['ch', 'el', 'ic', 'ra', '11', '13', '19', '31', '96'], 'reconstructed_words': ['ch', 'el', 'ic', 'ra', '113196']}, {'uid': '60245', 'actual_two_grams': ['bu', 'hn', 'jo', 'mp', 'nb', 'oh', 'um', 'p3', '19', '28', '32', '53', '81', '95'], 'filtered_two_grams': ['19', '81', '95'], 'reconstructed_words': ['195', '81']}, {'uid': '88712', 'actual_two_grams': ['ar', 'br', 'de', 'eb', 'ed', 'en', 'et', 'ge', 'ja', 'ng', 'on', 're', 'so', 'ts', 'n9', '19', '21', '22', '60', '92', '96'], 'filtered_two_grams': ['de', 'en', 'on', 're', '19', '96'], 'reconstructed_words': ['den', 'on', 're', '196']}, {'uid': '47395', 'actual_two_grams': ['al', 'df', 'do', 'er', 'fe', 'gu', 'ld', 'na', 'on', 'rg', 'us', 's9', '01', '19', '20', '74', '92', '97'], 'filtered_two_grams': ['al', 'do', 'er', 'ld', 'na', 'on', '01', '19', '97'], 'reconstructed_words': ['aldona', 'er', '0197']}, {'uid': '5051', 'actual_two_grams': ['an', 'eh', 'ep', 'er', 'ha', 'he', 'hm', 'ie', 'ma', 'ni', 'ph', 'rs', 'sh', 'st', 'te', 'n8', '19', '28', '81', '82', '83', '98'], 'filtered_two_grams': ['an', 'eh', 'ep', 'er', 'ha', 'he', 'ie', 'ni', 'sh', 'st', 'te', '19', '28', '81', '98'], 'reconstructed_words': ['anieha', 'ep', 'er', 'he', 'sh', 'ste', '1981', '28']}, {'uid': '25041', 'actual_two_grams': ['am', 'en', 'ev', 'ia', 'il', 'li', 'll', 'ms', 'ns', 'on', 'so', 'st', 'te', 've', 'wi', 'n1', '12', '19', '28', '78', '81', '97'], 'filtered_two_grams': ['am', 'en', 'ev', 'ia', 'il', 'li', 'll', 'ns', 'on', 'so', 'st', 've', 'wi', 'n1', '19', '28', '81', '97'], 'reconstructed_words': ['am', 'enson197', 'eve', 'ia', 'ili', 'll', 'st', 'wi', '281']}, {'uid': '26766', 'actual_two_grams': ['an', 'da', 'el', 'ie', 'll', 'lm', 'ls', 'ma', 'ni', 'pe', 'sp', 'n9', '19', '29', '84', '91', '92', '98'], 'filtered_two_grams': ['an', 'da', 'el', 'ie', 'll', 'ls', 'ma', 'ni', '19', '91', '98'], 'reconstructed_words': ['aniells', 'da', 'ma', '191', '98']}, {'uid': '76654', 'actual_two_grams': ['an', 'dy', 'en', 'nd', 'nk', 'sw', 'wa', 'we', 'ys', 'k8', '19', '21', '22', '69', '82', '96'], 'filtered_two_grams': ['an', 'en', '19', '21', '22', '81', '96'], 'reconstructed_words': ['an', 'en', '196', '21', '22', '81']}, {'uid': '58761', 'actual_two_grams': ['bc', 'bo', 'co', 'el', 'll', 'ob', 'or', 're', 'rr', 'l1', '06', '10', '19', '61', '80', '98'], 'filtered_two_grams': ['el', 'll', 'or', '01', '10', '19', '61'], 'reconstructed_words': ['ell', 'or', '010', '19', '61']}, {'uid': '30287', 'actual_two_grams': ['am', 'an', 'cl', 'el', 'ev', 'la', 'le', 'mo', 'nc', 'nd', 'on', 'ra', 've', 'd1', '12', '19', '25', '51', '90', '99'], 'filtered_two_grams': ['am', 'an', 'la', 'le', 'ra', '19', '99'], 'reconstructed_words': ['am', 'an', 'la', 'le', 'ra', '199']}, {'uid': '70517', 'actual_two_grams': ['am', 'ar', 'br', 'ce', 'cl', 'eg', 'el', 'en', 'ga', 'la', 'll', 'mb', 'nc', 're', 'l6', '11', '19', '21', '62', '85', '98'], 'filtered_two_grams': ['am', 'ar', 'eg', 'en', 'la', 'll', 'nc', 're', '11', '19', '21', '98'], 'reconstructed_words': ['am', 'areg', 'enc', 'la', 'll', '1198', '21']}, {'uid': '41963', 'actual_two_grams': ['ar', 'ca', 'cc', 'er', 'hy', 'je', 'mc', 'rr', 'rt', 'ry', 'th', 'ym', 'y5', '11', '19', '31', '53', '62', '96'], 'filtered_two_grams': ['ar', 'er', 'rr', 'rt', 'th', '19', '31', '96'], 'reconstructed_words': ['arrth', 'er', '196', '31']}, {'uid': '42267', 'actual_two_grams': ['an', 'do', 'hy', 'ma', 'or', 'ot', 'ro', 'th', 'yh', 'ym', 'n8', '11', '19', '21', '82', '98', '99'], 'filtered_two_grams': ['an', 'do', 'ma', 'ro', 'th', '11', '19', '21', '82', '98', '99'], 'reconstructed_words': ['an', 'do', 'ma', 'ro', 'th', '119821', '99']}, {'uid': '29681', 'actual_two_grams': ['am', 'el', 'll', 'lp', 'mu', 'ow', 'po', 'sa', 'ue', 'we', 'l2', '11', '19', '21', '94', '99'], 'filtered_two_grams': ['am', 'el', 'll', 'ow', 'sa', 'we', '11', '19', '21', '94'], 'reconstructed_words': ['am', 'ell', 'owe', 'sa', '1194', '21']}, {'uid': '99334', 'actual_two_grams': ['an', 'dm', 'er', 'go', 'ig', 'ma', 'od', 'oo', 'ri', 'rr', 'te', 'n9', '00', '02', '20', '92'], 'filtered_two_grams': ['er', 'ri', 'rr', '00', '01', '02', '20', '91'], 'reconstructed_words': ['eri', 'rr', '001', '020', '91']}, {'uid': '35737', 'actual_two_grams': ['af', 'am', 'ar', 'fo', 'ma', 'ot', 'ra', 'ta', 'ti', 'i9', '19', '79', '81', '97', '98'], 'filtered_two_grams': ['ar', 'ma', '19', '81', '91', '97'], 'reconstructed_words': ['ar', 'ma', '191', '81', '97']}, {'uid': '21360', 'actual_two_grams': ['as', 'el', 'er', 'he', 'le', 'lm', 'ma', 'ol', 'so', 'th', 'r3', '19', '35', '51', '94', '99'], 'filtered_two_grams': ['as', 'el', 'er', 'he', 'le', 'ma', 'th', '19', '31', '51', '94', '99'], 'reconstructed_words': ['as', 'eler', 'he', 'ma', 'th', '194', '31', '51', '99']}, {'uid': '85782', 'actual_two_grams': ['an', 'av', 'el', 'ge', 'is', 'li', 'ls', 'ng', 'og', 'sa', 'vo', 'g6', '01', '19', '20', '62', '94', '99'], 'filtered_two_grams': ['an', 'el', 'is', 'li', 'sa', '01', '19', '20', '94'], 'reconstructed_words': ['an', 'elisa', '0194', '20']}, {'uid': '32508', 'actual_two_grams': ['ah', 'ea', 'ew', 'hl', 'is', 'le', 'wi', 's3', '11', '19', '21', '32', '66', '96'], 'filtered_two_grams': ['is', 'le', 'wi', '19', '23', '31', '66', '96'], 'reconstructed_words': ['is', 'le', 'wi', '1966', '231']}, {'uid': '58376', 'actual_two_grams': ['ae', 'ch', 'el', 'ha', 'ic', 'kn', 'lk', 'll', 'mi', 'no', 'ol', 'l1', '02', '10', '19', '27', '71', '89', '98'], 'filtered_two_grams': ['ae', 'ch', 'el', 'ha', 'ic', 'll', 'mi', '10', '19', '71', '98'], 'reconstructed_words': ['aell', 'cha', 'ic', 'mi', '10', '198', '71']}, {'uid': '23513', 'actual_two_grams': ['be', 'co', 'er', 'il', 'lb', 'me', 'os', 'rt', 'sm', 'tc', 'wi', 'e8', '19', '42', '71', '87', '94'], 'filtered_two_grams': ['am', 'be', 'co', 'er', 'il', '19', '71', '81', '94'], 'reconstructed_words': ['am', 'ber', 'co', 'il', '194', '71', '81']}, {'uid': '20671', 'actual_two_grams': ['at', 'er', 'in', 'ki', 'ns', 'rr', 'ry', 'te', 'tk', 'wa', 'yw', 's1', '12', '19', '21', '22', '66', '96'], 'filtered_two_grams': ['er', 'in', 'rr', 'ry', 'wa', 's1', '12', '19', '21', '22', '66', '96'], 'reconstructed_words': ['erry', 'in', 'wa', 's121966', '22']}, {'uid': '94011', 'actual_two_grams': ['ab', 'be', 'el', 'es', 'et', 'gh', 'he', 'hh', 'hu', 'iz', 'li', 'th', 'ug', 'za', 's5', '19', '25', '51', '52', '67', '96'], 'filtered_two_grams': ['be', 'el', 'es', 'et', 'he', 'li', 'th', '19', '52', '96'], 'reconstructed_words': ['beli', 'es', 'ethe', '196', '52']}, {'uid': '13716', 'actual_two_grams': ['al', 'br', 'dg', 'et', 'ge', 'id', 'lt', 'on', 'ri', 'to', 'tw', 'wa', 'n1', '11', '15', '19', '51', '54', '95'], 'filtered_two_grams': ['al', 'on', 'ri', 'to', 'n1', '19', '51', '54', '95'], 'reconstructed_words': ['al', 'on1951', 'ri', 'to', '54']}, {'uid': '71912', 'actual_two_grams': ['eg', 'eo', 'er', 'ge', 'gl', 'lo', 'or', 'ov', 'rg', 've', 'r3', '19', '21', '32', '62', '96'], 'filtered_two_grams': ['er', 'ge', 'or', 'rg', '19', '21', '22', '32', '96'], 'reconstructed_words': ['erge', 'or', '196', '21', '22', '32']}, {'uid': '10217', 'actual_two_grams': ['co', 'ec', 'er', 'ho', 'ne', 'op', 'os', 'pe', 'sn', 'r1', '02', '10', '19', '21', '57', '95'], 'filtered_two_grams': ['co', 'er', 'ne', 'pe', 'r1', '10', '19', '21', '95'], 'reconstructed_words': ['co', 'er10', 'ne', 'pe', '195', '21']}, {'uid': '91751', 'actual_two_grams': ['al', 'ao', 'ea', 'il', 'lm', 'ma', 'ne', 'on', 'vi', 'l3', '16', '19', '31', '61', '96', '99'], 'filtered_two_grams': ['al', 'il', 'lm', 'ma', 'ne', 'on', 'vi', '16', '19', '31', '61', '96', '99'], 'reconstructed_words': ['alma', 'il', 'ne', 'on', 'vi', '16196', '31', '99']}, {'uid': '13554', 'actual_two_grams': ['an', 'as', 'ba', 'ho', 'ma', 'ne', 'om', 'sb', 'th', 'e1', '11', '12', '19', '27', '42', '71', '94'], 'filtered_two_grams': ['an', 'as', 'ma', 'th', '11', '19', '71', '94'], 'reconstructed_words': ['an', 'as', 'ma', 'th', '1194', '71']}, {'uid': '81389', 'actual_two_grams': ['bb', 'bi', 'do', 'ed', 'in', 'jo', 'ns', 'ob', 'oe', 's6', '19', '41', '64', '67', '96'], 'filtered_two_grams': ['in', 'jo', 'ns', '19', '41', '96'], 'reconstructed_words': ['ins', 'jo', '196', '41']}, {'uid': '87747', 'actual_two_grams': ['ac', 'au', 'ba', 'ck', 'ee', 'eg', 'en', 'gr', 'ie', 'ja', 'ki', 'nb', 're', 'um', 'm1', '01', '10', '15', '19', '51', '94', '99'], 'filtered_two_grams': ['ac', 'gr', 're', '10', '19', '51', '94', '99'], 'reconstructed_words': ['ac', 'gre', '10', '194', '51', '99']}, {'uid': '20184', 'actual_two_grams': ['ah', 'ar', 'cl', 'es', 'hy', 'la', 'me', 'ra', 'ym', 's9', '18', '19', '54', '81', '91', '95'], 'filtered_two_grams': ['ar', 'cl', 'es', 'la', 'ra', '18', '19', '81', '95'], 'reconstructed_words': ['ara', 'cla', 'es', '18195']}, {'uid': '88065', 'actual_two_grams': ['ai', 'al', 'an', 'cc', 'cl', 'in', 'la', 'mc', 'nm', 'n6', '16', '19', '49', '61', '94'], 'filtered_two_grams': ['al', 'an', 'in', 'la', '16', '19', '61', '94'], 'reconstructed_words': ['alan', 'in', '16194']}, {'uid': '66027', 'actual_two_grams': ['dl', 'en', 'ep', 'ey', 'gr', 'he', 'id', 'le', 'ng', 'ph', 'ri', 'st', 'te', 'y5', '13', '19', '31', '51', '70', '97'], 'filtered_two_grams': ['en', 'ey', 'he', 'le', 'ph', 'ri', 'st', '19', '31', '51', '70', '97'], 'reconstructed_words': ['en', 'ey', 'he', 'le', 'ph', 'ri', 'st', '1970', '31', '51']}, {'uid': '14212', 'actual_two_grams': ['ak', 'do', 'eg', 'ie', 'kr', 'na', 'nn', 'on', 'ri', 'g1', '11', '12', '19', '21', '44', '94'], 'filtered_two_grams': ['ie', 'nn', 'on', 'ri', '11', '12', '19', '21', '94'], 'reconstructed_words': ['ie', 'nn', 'on', 'ri', '112194']}, {'uid': '3821', 'actual_two_grams': ['ay', 'be', 'do', 'er', 'ha', 'ob', 'oh', 'on', 'ro', 'rt', 'to', 'yd', 'n5', '11', '19', '51', '70', '97'], 'filtered_two_grams': ['be', 'er', 'ha', 'ob', 'on', 'ro', 'rt', 'to', '11', '19', '97'], 'reconstructed_words': ['berob', 'ha', 'on', 'rto', '1197']}, {'uid': '98417', 'actual_two_grams': ['al', 'ch', 'en', 'et', 'gr', 'ha', 'he', 'll', 'nh', 're', 'tc', 'l5', '00', '02', '20', '52'], 'filtered_two_grams': ['al', 'ch', 'en', 'gr', 'he', 'll', 're', 'th', '00', '01', '02', '20', '52'], 'reconstructed_words': ['all', 'chen', 'gre', 'th', '001', '020', '52']}, {'uid': '85160', 'actual_two_grams': ['al', 'au', 'ea', 'et', 'gi', 'in', 'le', 'na', 'ne', 'ou', 'rn', 'to', 'ur', 'u1', '00', '02', '12', '20', '22', '25', '52'], 'filtered_two_grams': ['al', 'in', 'le', 'na', 'ne', 'ur', '00', '02', '12', '20', '22', '25'], 'reconstructed_words': ['ale', 'ina', 'ne', 'ur', '0020', '1225']}, {'uid': '45540', 'actual_two_grams': ['av', 'da', 'dl', 'ew', 'id', 'is', 'le', 'vi', 'wi', 's6', '13', '19', '31', '61', '70', '97'], 'filtered_two_grams': ['av', 'da', 'id', 'is', 'le', 'vi', '19', '31', '97'], 'reconstructed_words': ['avida', 'is', 'le', '197', '31']}, {'uid': '24000', 'actual_two_grams': ['al', 'be', 'er', 'ha', 'll', 'ob', 'ro', 'rt', 'th', 'l6', '19', '24', '41', '47', '62', '94'], 'filtered_two_grams': ['al', 'be', 'er', 'll', 'ob', 'ro', 'rt', 'th', '19', '24', '41', '94'], 'reconstructed_words': ['all', 'berob', 'rth', '1941', '24']}, {'uid': '73037', 'actual_two_grams': ['at', 'es', 'ey', 'ia', 'le', 'or', 'sl', 'to', 'vi', 'we', 'yv', 'r1', '12', '19', '21', '22', '93', '99'], 'filtered_two_grams': ['es', 'ia', 'le', 'or', '12', '19', '21', '22', '93', '99'], 'reconstructed_words': ['es', 'ia', 'le', 'or', '12193', '22', '99']}, {'uid': '98254', 'actual_two_grams': ['am', 'an', 'es', 'ja', 'la', 'ma', 'me', 'na', 'nn', 'sl', 'a5', '19', '48', '58', '81', '94'], 'filtered_two_grams': ['am', 'an', 'es', 'ja', 'me', '19', '81', '94'], 'reconstructed_words': ['ames', 'an', 'ja', '194', '81']}, {'uid': '43082', 'actual_two_grams': ['er', 'ez', 'il', 'lo', 'op', 'pe', 'ri', 'rr', 'te', 'z9', '12', '19', '21', '64', '91', '96'], 'filtered_two_grams': ['er', 'il', 'lo', 'pe', 'ri', 'rr', '19', '21', '96'], 'reconstructed_words': ['erilo', 'pe', 'rr', '196', '21']}, {'uid': '42844', 'actual_two_grams': ['dd', 'di', 'ed', 'ew', 'hi', 'ie', 'it', 'te', 'wh', 'e8', '19', '29', '60', '82', '91', '96'], 'filtered_two_grams': ['di', 'ed', 'hi', 'it', '19', '29', '81', '91', '96'], 'reconstructed_words': ['dit', 'ed', 'hi', '191', '296', '81']}, {'uid': '14166', 'actual_two_grams': ['ad', 'am', 'de', 'do', 'el', 'ga', 'ia', 'il', 'lg', 'li', 'll', 'md', 'wi', 'o4', '01', '19', '30', '43', '73', '97'], 'filtered_two_grams': ['am', 'el', 'ia', 'il', 'li', 'll', 'wi', '01', '19', '97'], 'reconstructed_words': ['am', 'elia', 'ill', 'wi', '0197']}, {'uid': '7242', 'actual_two_grams': ['ak', 'ba', 'eb', 'eo', 'er', 'ge', 'ke', 'or', 'rg', 'r3', '15', '19', '31', '47', '51', '94'], 'filtered_two_grams': ['ba', 'er', 'ge', 'or', 'rg', 'r3', '15', '19', '51', '94'], 'reconstructed_words': ['ba', 'erge', 'or3', '15194']}, {'uid': '83035', 'actual_two_grams': ['an', 'dl', 'es', 'ey', 'le', 'my', 'nd', 'rt', 'st', 'ta', 'tl', 'yr', 'y4', '18', '19', '41', '51', '81', '95'], 'filtered_two_grams': ['an', 'es', 'ey', 'le', 'st', '19', '41', '81', '95'], 'reconstructed_words': ['an', 'est', 'ey', 'le', '195', '41', '81']}, {'uid': '56667', 'actual_two_grams': ['ee', 'ej', 'es', 'jo', 'le', 'ne', 'on', 's7', '19', '21', '40', '72', '94'], 'filtered_two_grams': ['ee', 'es', 'jo', 'le', 'ne', 'on', '19', '40', '94'], 'reconstructed_words': ['ees', 'jone', 'le', '1940']}, {'uid': '93383', 'actual_two_grams': ['ab', 'as', 'ba', 'ia', 'lv', 'ss', 'sy', 'vi', 'yl', 's9', '19', '88', '91', '98', '99'], 'filtered_two_grams': ['as', 'ia', 'vi', '19', '91', '98'], 'reconstructed_words': ['as', 'ia', 'vi', '191', '98']}, {'uid': '75074', 'actual_two_grams': ['ag', 'av', 'dn', 'ed', 'es', 'gr', 'na', 'ra', 've', 's4', '15', '19', '37', '41', '51', '93'], 'filtered_two_grams': ['es', 'ra', 've', '15', '19', '41', '51', '93'], 'reconstructed_words': ['es', 'ra', 've', '15193', '41']}, {'uid': '90900', 'actual_two_grams': ['at', 'ce', 'ee', 'el', 'en', 'ge', 'ic', 'ng', 'pa', 'ri', 'tr', 'l2', '11', '19', '21', '89', '98'], 'filtered_two_grams': ['at', 'ce', 'el', 'en', 'ge', 'ic', 'ng', 'pa', 'ri', 'tr', '11', '19', '21', '98'], 'reconstructed_words': ['atricel', 'enge', 'pa', '1198', '21']}, {'uid': '91182', 'actual_two_grams': ['ar', 'ek', 'en', 'go', 'il', 'ki', 'le', 'lg', 'ma', 'ne', 'or', 're', 'rl', 'e7', '19', '51', '75', '95', '99'], 'filtered_two_grams': ['ar', 'en', 'le', 'ma', 'ne', 're', '19', '51', '95', '99'], 'reconstructed_words': ['arene', 'le', 'ma', '1951', '99']}, {'uid': '885', 'actual_two_grams': ['al', 'an', 'de', 'el', 'es', 'ld', 'lv', 'ma', 'nu', 'ue', 'va', 's1', '11', '12', '19', '29', '44', '91', '94'], 'filtered_two_grams': ['al', 'el', 'ld', 'ma', '11', '19', '29', '91', '94'], 'reconstructed_words': ['ald', 'el', 'ma', '1191', '294']}, {'uid': '73665', 'actual_two_grams': ['ac', 'bj', 'co', 'es', 'ja', 'jo', 'ne', 'ob', 'on', 's2', '19', '26', '37', '61', '93'], 'filtered_two_grams': ['ac', 'co', 'es', 'ja', 'jo', 'ne', 'on', '19', '37', '61', '93'], 'reconstructed_words': ['acones', 'ja', 'jo', '1937', '61']}, {'uid': '35174', 'actual_two_grams': ['es', 'ip', 'ky', 'ms', 'pe', 'si', 'ym', 's1', '01', '12', '19', '20', '52', '95'], 'filtered_two_grams': ['es', 's1', '01', '19', '20', '95'], 'reconstructed_words': ['es195', '01', '20']}, {'uid': '65425', 'actual_two_grams': ['el', 'ev', 'ls', 'ly', 'ne', 'nn', 'on', 'so', 've', 'yn', 'n7', '19', '28', '72', '81', '89', '98'], 'filtered_two_grams': ['el', 'ev', 'ne', 'nn', 'on', 'so', 've', '19', '81', '98'], 'reconstructed_words': ['el', 'eve', 'ne', 'nn', 'on', 'so', '1981']}, {'uid': '65375', 'actual_two_grams': ['an', 'ao', 'de', 'en', 'it', 'ju', 'ni', 'od', 'ta', 'ua', 'n1', '13', '19', '31', '49', '94'], 'filtered_two_grams': ['an', 'en', 'ni', '19', '23', '31', '94'], 'reconstructed_words': ['ani', 'en', '194', '231']}, {'uid': '24062', 'actual_two_grams': ['am', 'en', 'ev', 'ha', 'in', 'li', 'ml', 'nh', 'st', 'te', 've', 'n1', '12', '18', '19', '21', '49', '81', '94'], 'filtered_two_grams': ['am', 'en', 'ev', 'in', 'li', 'st', 'te', 've', '12', '19', '81', '94'], 'reconstructed_words': ['am', 'en', 'eve', 'in', 'li', 'ste', '12', '194', '81']}, {'uid': '40324', 'actual_two_grams': ['eh', 'eo', 'er', 'ge', 'he', 'og', 'or', 'rg', 'rz', 'zo', 'g1', '18', '19', '54', '81', '95'], 'filtered_two_grams': ['er', 'ge', 'he', 'or', 'rg', '19', '81', '95'], 'reconstructed_words': ['erge', 'he', 'or', '195', '81']}, {'uid': '70108', 'actual_two_grams': ['an', 'as', 'ca', 'hn', 'jo', 'nc', 'no', 'oh', 'ov', 'sa', 'va', 'a3', '19', '34', '41', '90', '99'], 'filtered_two_grams': ['an', 'as', 'jo', '19', '31', '41', '99'], 'reconstructed_words': ['an', 'as', 'jo', '199', '31', '41']}, {'uid': '77547', 'actual_two_grams': ['an', 'ch', 'da', 'el', 'he', 'ie', 'it', 'll', 'lm', 'mi', 'ni', 'tc', 'l8', '11', '19', '44', '81', '94'], 'filtered_two_grams': ['an', 'ch', 'el', 'he', 'ie', 'it', 'll', 'mi', 'ni', '11', '19', '81', '94'], 'reconstructed_words': ['aniell', 'che', 'it', 'mi', '1194', '81']}, {'uid': '43882', 'actual_two_grams': ['an', 'es', 'nt', 'or', 're', 'rr', 'ry', 'to', 'ya', 's4', '01', '10', '19', '41', '57', '95'], 'filtered_two_grams': ['an', 'or', 're', 'ry', 'ya', '10', '19', '41', '95'], 'reconstructed_words': ['an', 'ore', 'rya', '10', '195', '41']}, {'uid': '7332', 'actual_two_grams': ['as', 'do', 'er', 'gl', 'il', 'la', 'le', 'll', 'mi', 'ou', 'sm', 'ug', 'r8', '19', '29', '74', '82', '91', '97'], 'filtered_two_grams': ['as', 'do', 'er', 'gl', 'il', 'la', 'le', 'll', 'mi', 'ou', '19', '74', '91', '97'], 'reconstructed_words': ['as', 'dou', 'er', 'gla', 'ile', 'll', 'mi', '191', '74', '97']}, {'uid': '78487', 'actual_two_grams': ['aa', 'al', 'am', 'an', 'av', 'da', 'll', 'lo', 'ma', 'nd', 'ne', 'on', 'va', 'e7', '19', '24', '41', '66', '72', '96'], 'filtered_two_grams': ['al', 'am', 'an', 'da', 'ma', 'on', '19', '96'], 'reconstructed_words': ['al', 'aman', 'da', 'on', '196']}, {'uid': '71943', 'actual_two_grams': ['ar', 'el', 'ke', 'la', 'll', 'ly', 'rr', 'ry', 'yk', 'y9', '17', '19', '71', '72', '91', '97'], 'filtered_two_grams': ['ar', 'el', 'la', 'll', 'rr', 'ry', '19', '71', '72', '97'], 'reconstructed_words': ['arry', 'ela', 'll', '1971', '72']}, {'uid': '85676', 'actual_two_grams': ['ac', 'ar', 'ca', 'ce', 'ey', 'il', 'll', 'lo', 'ri', 'rr', 'st', 'ta', 'yc', 'o4', '19', '48', '81', '83', '98'], 'filtered_two_grams': ['ar', 'il', 'll', 'lo', 'ri', '19', '41', '81', '98'], 'reconstructed_words': ['arillo', '1981', '41']}, {'uid': '36896', 'actual_two_grams': ['ah', 'de', 'di', 'en', 'er', 'he', 'in', 'iv', 'na', 'nd', 'on', 'rs', 'so', 'vi', 'n4', '00', '03', '19', '20', '41', '92'], 'filtered_two_grams': ['de', 'en', 'er', 'he', 'in', 'nd', 'on', 'rs', 'so', '00', '19', '20'], 'reconstructed_words': ['dend', 'erson', 'he', 'in', '00', '19', '20']}, {'uid': '46581', 'actual_two_grams': ['an', 'cd', 'da', 'el', 'ie', 'im', 'ju', 'li', 'mc', 'ni', 'ul', 'l1', '15', '19', '51', '59', '95'], 'filtered_two_grams': ['an', 'el', 'ie', 'li', 'ni', 'ul', '19', '51', '95'], 'reconstructed_words': ['anieli', 'ul', '1951']}, {'uid': '45776', 'actual_two_grams': ['an', 'ar', 'gr', 'io', 'ma', 'ng', 'nt', 'on', 'ra', 'ri', 't9', '19', '21', '22', '72', '92', '97'], 'filtered_two_grams': ['an', 'ar', 'ma', '19', '21', '22', '97'], 'reconstructed_words': ['an', 'ar', 'ma', '197', '21', '22']}, {'uid': '15493', 'actual_two_grams': ['al', 'el', 'lo', 'ls', 'ne', 'nz', 'on', 'so', 'zo', 'n1', '12', '19', '22', '26', '61', '98', '99'], 'filtered_two_grams': ['al', 'el', 'ne', 'on', 'so', 'n1', '12', '19', '21', '22', '61', '98', '99'], 'reconstructed_words': ['al', 'el', 'ne', 'on12198', 'so', '22', '61', '99']}, {'uid': '68295', 'actual_two_grams': ['au', 'en', 'er', 'la', 'lu', 'nl', 'ra', 're', 'ue', 'ur', 'a5', '19', '29', '52', '81', '91', '98'], 'filtered_two_grams': ['au', 'en', 'la', 'ra', 're', 'ur', '19', '29', '91', '98'], 'reconstructed_words': ['aura', 'en', 'la', 're', '191', '298']}, {'uid': '22536', 'actual_two_grams': ['ej', 'en', 'hn', 'ie', 'je', 'jo', 'ni', 'nn', 'ns', 'oh', 'on', 'so', 'n1', '00', '12', '20', '29', '92'], 'filtered_two_grams': ['en', 'hn', 'ie', 'jo', 'ni', 'nn', 'ns', 'oh', 'on', 'sj', 'so', 'n1', '00', '20', '29', '91'], 'reconstructed_words': ['enie', 'hnnsjoh', 'on1', 'so', '00', '20', '291']}, {'uid': '55632', 'actual_two_grams': ['al', 'an', 'el', 'hm', 'lp', 'ma', 'nu', 'ph', 'ra', 'ue', 'l1', '11', '12', '19', '27', '61', '71', '96'], 'filtered_two_grams': ['al', 'an', 'el', 'ma', 'ra', '11', '19', '71', '96'], 'reconstructed_words': ['al', 'an', 'el', 'ma', 'ra', '1196', '71']}, {'uid': '9889', 'actual_two_grams': ['co', 'er', 'fi', 'he', 'is', 'ot', 'sc', 'sh', 'tf', 'tt', 'r5', '16', '19', '51', '61', '70', '97'], 'filtered_two_grams': ['er', 'he', 'sh', 'tt', '16', '19', '61', '97'], 'reconstructed_words': ['er', 'he', 'sh', 'tt', '16197']}, {'uid': '66642', 'actual_two_grams': ['am', 'at', 'er', 'mm', 'my', 'on', 'pa', 'rs', 'so', 'ta', 'te', 'tt', 'yp', 'n3', '14', '19', '31', '41', '66', '96'], 'filtered_two_grams': ['er', 'on', 'so', '19', '31', '41', '96'], 'reconstructed_words': ['er', 'on', 'so', '196', '31', '41']}, {'uid': '79838', 'actual_two_grams': ['ee', 'eg', 'en', 'go', 'gr', 'or', 're', 'ry', 'yg', 'n1', '12', '19', '22', '24', '41', '61', '96'], 'filtered_two_grams': ['eg', 'en', 'gr', 'or', 're', '12', '19', '21', '24', '41', '96'], 'reconstructed_words': ['egren', 'or', '12196', '241']}, {'uid': '71416', 'actual_two_grams': ['ac', 'ck', 'en', 'et', 'hj', 'ja', 'ke', 'ks', 'ne', 'nn', 'on', 'so', 'th', 'n4', '11', '19', '21', '42', '85', '98'], 'filtered_two_grams': ['ac', 'ck', 'en', 'et', 'ja', 'ke', 'ne', 'nn', 'on', 'so', 'th', '19', '85', '98'], 'reconstructed_words': ['ackeneth', 'ja', 'nn', 'on', 'so', '1985']}, {'uid': '58601', 'actual_two_grams': ['as', 'ee', 'el', 'es', 'et', 'la', 'll', 'st', 'sw', 'te', 'we', 't4', '11', '19', '21', '42', '58', '95'], 'filtered_two_grams': ['as', 'el', 'es', 'll', 'st', 'te', 'we', '11', '19', '58', '95'], 'reconstructed_words': ['astell', 'es', 'we', '11958']}, {'uid': '41575', 'actual_two_grams': ['am', 'as', 'el', 'ia', 'il', 'li', 'll', 'ma', 'mm', 'se', 'wi', 'i9', '14', '19', '41', '86', '91', '98'], 'filtered_two_grams': ['am', 'el', 'ia', 'il', 'li', 'll', 'wi', '14', '19', '41', '91', '98'], 'reconstructed_words': ['am', 'elia', 'ill', 'wi', '14191', '98']}, {'uid': '86017', 'actual_two_grams': ['an', 'at', 'de', 'ea', 'el', 'll', 'na', 're', 'ty', 'yr', 'l1', '07', '10', '19', '53', '71', '95'], 'filtered_two_grams': ['an', 'de', 'ea', 'el', 'll', '10', '19', '53', '71', '95'], 'reconstructed_words': ['an', 'dea', 'ell', '10', '1953', '71']}, {'uid': '85413', 'actual_two_grams': ['ar', 'dg', 'ed', 'ge', 'la', 'le', 'rr', 'ru', 'ry', 'tl', 'ut', 'yr', 'e6', '14', '19', '41', '61', '84', '98'], 'filtered_two_grams': ['ar', 'le', 'ry', '19', '41', '98'], 'reconstructed_words': ['ary', 'le', '198', '41']}, {'uid': '80327', 'actual_two_grams': ['as', 'ca', 'hn', 'jo', 'lu', 'ns', 'oh', 'on', 'sj', 'so', 'uc', 'n5', '01', '10', '19', '51', '87', '98'], 'filtered_two_grams': ['as', 'hn', 'jo', 'ns', 'oh', 'on', 'so', '01', '10', '19', '98'], 'reconstructed_words': ['asohns', 'jon', '010', '198']}, {'uid': '88030', 'actual_two_grams': ['an', 'da', 'el', 'er', 'ho', 'ie', 'lh', 'ni', 'ow', 'ry', 'we', 'y9', '12', '19', '21', '91', '92', '99'], 'filtered_two_grams': ['an', 'da', 'el', 'ie', 'ni', '12', '19', '21', '91', '99'], 'reconstructed_words': ['aniel', 'da', '12191', '99']}, {'uid': '29690', 'actual_two_grams': ['af', 'do', 'ff', 'fo', 'hy', 'or', 'ot', 'rd', 'ro', 'st', 'ta', 'th', 'ys', 'd8', '19', '61', '86', '89', '98'], 'filtered_two_grams': ['do', 'or', '19', '81', '98'], 'reconstructed_words': ['dor', '1981']}, {'uid': '81600', 'actual_two_grams': ['an', 'ea', 'em', 'er', 'je', 'me', 'my', 'ns', 're', 'ym', 's1', '11', '12', '19', '21', '22', '37', '93'], 'filtered_two_grams': ['an', 'er', 's1', '12', '19', '21', '22'], 'reconstructed_words': ['an', 'er', 's1219', '22']}, {'uid': '69208', 'actual_two_grams': ['an', 'en', 'er', 'fe', 'if', 'je', 'ma', 'ni', 'nn', 'no', 'om', 'ro', 'rr', 'o6', '11', '19', '61', '99'], 'filtered_two_grams': ['an', 'en', 'er', 'je', 'ma', 'ni', 'nn', 'ro', '19', '99'], 'reconstructed_words': ['ani', 'enn', 'ero', 'je', 'ma', '199']}, {'uid': '95560', 'actual_two_grams': ['at', 'em', 'il', 'ka', 'ly', 'mi', 'tz', 'yk', 'z7', '11', '19', '54', '71', '95'], 'filtered_two_grams': ['em', 'il', 'mi', '19', '95'], 'reconstructed_words': ['emil', '195']}, {'uid': '78679', 'actual_two_grams': ['ak', 'an', 'as', 'ck', 'ha', 'ic', 'is', 'ki', 'kl', 'la', 'nd', 'ri', 'sh', 'st', 'tr', 'd6', '19', '44', '61', '66', '94'], 'filtered_two_grams': ['an', 'as', 'ck', 'ic', 'la', 'nd', 'ri', 'st', 'tr', '19', '61', '94'], 'reconstructed_words': ['and', 'astrick', 'la', '194', '61']}, {'uid': '54630', 'actual_two_grams': ['an', 'cm', 'er', 'ga', 'ic', 'mo', 'or', 'rg', 'ri', 'n2', '19', '21', '56', '91', '95'], 'filtered_two_grams': ['an', 'er', 'ga', 'ic', 'or', 'ri', '19', '95'], 'reconstructed_words': ['an', 'eric', 'ga', 'or', '195']}, {'uid': '66514', 'actual_two_grams': ['as', 'ch', 'es', 'ha', 'is', 'se', 'si', 'sk', 'k4', '11', '19', '41', '48', '94'], 'filtered_two_grams': ['as', 'ch', 'es', 'ha', '11', '19', '41', '94'], 'reconstructed_words': ['as', 'cha', 'es', '11941']}, {'uid': '93305', 'actual_two_grams': ['am', 'an', 'di', 'er', 'ia', 'il', 'le', 'll', 'mi', 'na', 'r3', '01', '19', '30', '33', '50', '95'], 'filtered_two_grams': ['am', 'an', 'er', 'il', 'le', 'll', 'mi', '01', '13', '19', '30', '31', '95'], 'reconstructed_words': ['amiler', 'an', 'll', '0130', '195', '31']}, {'uid': '44215', 'actual_two_grams': ['al', 'an', 'gh', 'ht', 'ig', 'la', 'nw', 'ri', 'wr', 't1', '01', '13', '19', '30', '88', '98'], 'filtered_two_grams': ['al', 'an', 'gh', 'ht', 'ig', 'la', 'ri', 'wr', 't1', '01', '11', '19', '30', '98'], 'reconstructed_words': ['alan', 'ght1198', 'ig', 'ri', 'wr', '01', '30']}, {'uid': '34408', 'actual_two_grams': ['ab', 'an', 'be', 'el', 'et', 'ge', 'la', 'ng', 'ts', 'tt', 's3', '00', '20', '29', '32', '92'], 'filtered_two_grams': ['ab', 'an', 'be', 'el', 'et', 'la', 'tt', '00', '20', '29', '31', '91'], 'reconstructed_words': ['abelan', 'ett', '00', '20', '291', '31']}]\n",
      "Average Precision: 0.9724990943274524\n",
      "Average Recall: 0.532365034940586\n",
      "Average F1 Score: 0.6778772887849642\n",
      "Average Dice Similarity: 0.6778781094527362\n"
     ]
    }
   ],
   "source": [
    "# List to store decoded 2-gram scores for all test samples\n",
    "decoded_test_results_words = []\n",
    "result = []\n",
    "total_precision = total_recall = total_f1 = total_dice = 0.0\n",
    "n = len(dataloader_test.dataset)\n",
    "\n",
    "# Switch to evaluation mode (no gradient computation during inference)\n",
    "model.eval()\n",
    "\n",
    "# Define Threshold for filtering predictions\n",
    "threshold = DEA_CONFIG[\"FilterThreshold\"]\n",
    "\n",
    "# Loop through the test dataloader for inference\n",
    "with torch.no_grad():  # No need to compute gradients during inference\n",
    "    for data, labels, uid in tqdm(dataloader_test, desc=\"Test loop\") if GLOBAL_CONFIG[\"Verbose\"] else dataloader_test:\n",
    "\n",
    "        actual_two_grams = label_tensors_to_two_grams(two_gram_dict, labels)\n",
    "\n",
    "        # Move data to device and make predictions\n",
    "        data = data.to(compute_device)\n",
    "        logits = model(data)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "\n",
    "        # Convert probabilities into 2-gram scores\n",
    "        batch_two_gram_scores = convert_to_two_gram_scores(two_gram_dict, probabilities)\n",
    "\n",
    "        # Filter out low-scoring 2-grams\n",
    "        batch_filtered_two_gram_scores = filter_two_grams(batch_two_gram_scores, threshold)\n",
    "\n",
    "        # Calculate performance metrics for evaluation\n",
    "        dice, precision, recall, f1 = calculate_performance_metrics(\n",
    "            actual_two_grams, batch_filtered_two_gram_scores)\n",
    "        total_dice += dice\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "\n",
    "        # Reconstruct words from the filtered 2-grams for each sample\n",
    "        batch_reconstructed_words = [\n",
    "            reconstruct_words(filtered_scores) for filtered_scores in batch_filtered_two_gram_scores\n",
    "        ]\n",
    "\n",
    "        for two_grams, two_grams_predicted, reconstructed_words, uid in zip(actual_two_grams, batch_filtered_two_gram_scores, batch_reconstructed_words, uid):\n",
    "            # Create a dictionary to store the results for each test sample\n",
    "            result_dict = {\n",
    "                \"uid\": uid,\n",
    "                \"actual_two_grams\": two_grams,\n",
    "                \"filtered_two_grams\": two_grams_predicted,\n",
    "                \"reconstructed_words\": reconstructed_words\n",
    "            }\n",
    "            # Append the result dictionary to the combined results list\n",
    "            result.append(result_dict)\n",
    "\n",
    "        average_precision = total_precision / n\n",
    "        average_recall = total_recall / n\n",
    "        average_f1 = total_f1 / n\n",
    "        average_dice = total_dice / n\n",
    "\n",
    "\n",
    "# Now `combined_results_performance` contains detailed comparison for all test samples\n",
    "print(result)\n",
    "print (f\"Average Precision: {average_precision}\")\n",
    "print (f\"Average Recall: {average_recall}\")\n",
    "print (f\"Average F1 Score: {average_f1}\")\n",
    "print (f\"Average Dice Similarity: {average_dice}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "Stopping execution at this cell.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Stopping execution at this cell.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/I538952/Desktop/master/4-semester-thesis/dataset-extension-attack/.conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "sys.exit(\"Stopping execution at this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Performance for Re-Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
