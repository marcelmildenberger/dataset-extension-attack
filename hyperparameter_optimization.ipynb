{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.10.16 | packaged by conda-forge | (main, Dec  5 2024, 14:20:01) [Clang 18.1.8 ]\n",
      "PyTorch version 2.1.2\n",
      "Torchvision version 0.16.2\n",
      "Numpy version 1.24.4\n",
      "Pandas version 2.0.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "import ray\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt # For data viz\n",
    "import pandas as pd\n",
    "import hickle as hkl\n",
    "import numpy as np\n",
    "import string\n",
    "import sys\n",
    "\n",
    "from ray.air import session\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from graphMatching.gma import run_gma\n",
    "\n",
    "from datasets.bloom_filter_dataset import BloomFilterDataset\n",
    "from datasets.tab_min_hash_dataset import TabMinHashDataset\n",
    "from datasets.two_step_hash_dataset_padding import TwoStepHashDatasetPadding\n",
    "from datasets.two_step_hash_dataset_frequency_string import TwoStepHashDatasetFrequencyString\n",
    "from datasets.two_step_hash_dataset_one_hot_encoding import TwoStepHashDatasetOneHotEncoding\n",
    "\n",
    "from pytorch_models_hyperparameter_optimization.base_model import BaseModel\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Torchvision version', torchvision.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print('Pandas version', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run GMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "GLOBAL_CONFIG = {\n",
    "    \"Data\": \"./data/datasets/fakename_5k.tsv\",\n",
    "    \"Overlap\": 0.68,\n",
    "    \"DropFrom\": \"Both\",\n",
    "    \"Verbose\": True,  # Print Status Messages\n",
    "    \"MatchingMetric\": \"cosine\",\n",
    "    \"Matching\": \"MinWeight\",\n",
    "    \"Workers\": -1,\n",
    "    \"SaveAliceEncs\": False,\n",
    "    \"SaveEveEncs\": False,\n",
    "    \"DevMode\": True,\n",
    "}\n",
    "\n",
    "\n",
    "DEA_CONFIG = {\n",
    "    #Padding / FrequencyString / OneHotEncoding\n",
    "    \"TSHMode\": \"OneHotEncoding\",\n",
    "    \"DevMode\": False,\n",
    "    # BCEWithLogitsLoss / MultiLabelSoftMarginLoss\n",
    "    \"LossFunction:\": \"BCEWithLogitsLoss\",\n",
    "    # Adam / AdamW / SGD / RMSprop\n",
    "    \"Optimizer\": \"AdamW\",\n",
    "    \"LearningRate\": 0.001,\n",
    "    # SGD only\n",
    "    \"Momentum\": 0.9,\n",
    "    \"BatchSize\": 32,\n",
    "    \"Epochs\": 10,\n",
    "    # TestSize calculated accordingly\n",
    "    \"TrainSize\": 0.8,\n",
    "    \"FilterThreshold\": 0.5,\n",
    "    # ReLU / LeakyReLU\n",
    "    \"ActivationFunction\": \"ReLU\",\n",
    "}\n",
    "\n",
    "ENC_CONFIG = {\n",
    "    # TwoStepHash / TabMinHash / BloomFilter\n",
    "    \"AliceAlgo\": \"BloomFilter\",\n",
    "    \"AliceSecret\": \"SuperSecretSalt1337\",\n",
    "    \"AliceN\": 2,\n",
    "    \"AliceMetric\": \"dice\",\n",
    "    \"EveAlgo\": \"None\",\n",
    "    \"EveSecret\": \"ATotallyDifferentString42\",\n",
    "    \"EveN\": 2,\n",
    "    \"EveMetric\": \"dice\",\n",
    "    # For BF encoding\n",
    "    \"AliceBFLength\": 1024,\n",
    "    \"AliceBits\": 10,\n",
    "    \"AliceDiffuse\": False,\n",
    "    \"AliceT\": 10,\n",
    "    \"AliceEldLength\": 1024,\n",
    "    \"EveBFLength\": 1024,\n",
    "    \"EveBits\": 10,\n",
    "    \"EveDiffuse\": False,\n",
    "    \"EveT\": 10,\n",
    "    \"EveEldLength\": 1024,\n",
    "    # For TMH encoding\n",
    "    \"AliceNHash\": 1024,\n",
    "    \"AliceNHashBits\": 64,\n",
    "    \"AliceNSubKeys\": 8,\n",
    "    \"Alice1BitHash\": True,\n",
    "    \"EveNHash\": 1024,\n",
    "    \"EveNHashBits\": 64,\n",
    "    \"EveNSubKeys\": 8,\n",
    "    \"Eve1BitHash\": True,\n",
    "    # For 2SH encoding\n",
    "    \"AliceNHashFunc\": 10,\n",
    "    \"AliceNHashCol\": 1000,\n",
    "    \"AliceRandMode\": \"PNG\",\n",
    "    \"EveNHashFunc\": 10,\n",
    "    \"EveNHashCol\": 1000,\n",
    "    \"EveRandMode\": \"PNG\",\n",
    "}\n",
    "\n",
    "EMB_CONFIG = {\n",
    "    \"Algo\": \"Node2Vec\",\n",
    "    \"AliceQuantile\": 0.9,\n",
    "    \"AliceDiscretize\": False,\n",
    "    \"AliceDim\": 128,\n",
    "    \"AliceContext\": 10,\n",
    "    \"AliceNegative\": 1,\n",
    "    \"AliceNormalize\": True,\n",
    "    \"EveQuantile\": 0.9,\n",
    "    \"EveDiscretize\": False,\n",
    "    \"EveDim\": 128,\n",
    "    \"EveContext\": 10,\n",
    "    \"EveNegative\": 1,\n",
    "    \"EveNormalize\": True,\n",
    "    # For Node2Vec\n",
    "    \"AliceWalkLen\": 100,\n",
    "    \"AliceNWalks\": 20,\n",
    "    \"AliceP\": 250,\n",
    "    \"AliceQ\": 300,\n",
    "    \"AliceEpochs\": 5,\n",
    "    \"AliceSeed\": 42,\n",
    "    \"EveWalkLen\": 100,\n",
    "    \"EveNWalks\": 20,\n",
    "    \"EveP\": 250,\n",
    "    \"EveQ\": 300,\n",
    "    \"EveEpochs\": 5,\n",
    "    \"EveSeed\": 42\n",
    "}\n",
    "\n",
    "ALIGN_CONFIG = {\n",
    "    \"RegWS\": max(0.1, GLOBAL_CONFIG[\"Overlap\"]/2), #0005\n",
    "    \"RegInit\":1, # For BF 0.25\n",
    "    \"Batchsize\": 1, # 1 = 100%\n",
    "    \"LR\": 200.0,\n",
    "    \"NIterWS\": 100,\n",
    "    \"NIterInit\": 5 ,  # 800\n",
    "    \"NEpochWS\": 100,\n",
    "    \"LRDecay\": 1,\n",
    "    \"Sqrt\": True,\n",
    "    \"EarlyStopping\": 10,\n",
    "    \"Selection\": \"None\",\n",
    "    \"MaxLoad\": None,\n",
    "    \"Wasserstein\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Alice's data\n",
      "Encoding Alice's Data\n",
      "Done encoding Alice's data\n",
      "Computing Thresholds and subsetting data for Alice\n",
      "Done processing Alice's data.\n",
      "Loading Eve's data\n",
      "Encoding Eve's Data\n",
      "Done encoding Eve's data\n",
      "Computing Thresholds and subsetting data for Eve\n",
      "Done processing Eve's data.\n",
      "Embedding Alice's data. This may take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8947e299ad964a2b84f95a8f912eaeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t  Loss: 7378193.5\n",
      "Epoch: 2\t  Loss: 6173532.5\n",
      "Epoch: 3\t  Loss: 5401820.0\n",
      "Epoch: 4\t  Loss: 4854888.0\n",
      "Epoch: 5\t  Loss: 4693982.0\n",
      "Done embedding Alice's data.\n",
      "Embedding Eve's data. This may take a while...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af74d26046240eeb4261e66da775d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t  Loss: 7314272.0\n",
      "Epoch: 2\t  Loss: 6158541.0\n",
      "Epoch: 3\t  Loss: 5406573.0\n",
      "Epoch: 4\t  Loss: 4696072.0\n",
      "Epoch: 5\t  Loss: 4706232.0\n",
      "Done embedding Eve's data.\n",
      "Aligning vectors. This may take a while.\n",
      "\n",
      "Computing initial mapping with convex relaxation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective after convex initialization: 51.708599\n",
      "Done [001 sec]\n",
      "\n",
      "Computing mapping with Wasserstein Procrustes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1  obj: 39.344  best: 39.344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|██████████| 100/100 [16:20<00:00,  9.81s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective of  39.343 is 77.47 % of initial value. Early stopping...\n",
      "Done [1024 sec]\n",
      "Done.\n",
      "Performing bipartite graph matching\n",
      "Correct: 2573 of 2575\n",
      "Success rate: 0.999223\n"
     ]
    }
   ],
   "source": [
    "eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash = get_hashes(GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG)\n",
    "\n",
    "if(os.path.isfile(\"./data/available_to_eve/reidentified_individuals_%s_%s_%s_%s.h5\" % (eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash)) & os.path.isfile(\"./data/available_to_eve/not_reidentified_individuals_%s_%s_%s_%s.h5\" % (eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash))):\n",
    "    #Load Disk From Data\n",
    "    reidentified_individuals = hkl.load('./data/available_to_eve/reidentified_individuals_%s_%s_%s_%s.h5' % (eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash))\n",
    "    df_reidentified_individuals = pd.DataFrame(reidentified_individuals[1:], columns=reidentified_individuals[0])\n",
    "\n",
    "    not_reidentified_individuals = hkl.load('./data/available_to_eve/not_reidentified_individuals_%s_%s_%s_%s.h5' % (eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash))\n",
    "    df_not_reidentified_individuals = pd.DataFrame(not_reidentified_individuals[1:], columns=not_reidentified_individuals[0])\n",
    "\n",
    "    all_individuals = hkl.load('./data/dev/alice_data_complete_with_encoding_%s_%s_%s_%s.h5' % (eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash))\n",
    "    df_all_individuals = pd.DataFrame(all_individuals[1:], columns=all_individuals[0])\n",
    "\n",
    "else:\n",
    "    reidentified_individuals, not_reidentified_individuals, all_individuals = run_gma(GLOBAL_CONFIG, ENC_CONFIG, EMB_CONFIG, ALIGN_CONFIG, DEA_CONFIG, eve_enc_hash, alice_enc_hash, eve_emb_hash, alice_emb_hash)\n",
    "\n",
    "    df_reidentified_individuals = pd.DataFrame(reidentified_individuals[1:], columns=reidentified_individuals[0])\n",
    "    df_not_reidentified_individuals = pd.DataFrame(not_reidentified_individuals[1:], columns=not_reidentified_individuals[0])\n",
    "    df_all_individuals = pd.DataFrame(all_individuals[1:], columns=all_individuals[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the 2-grams with dictionary\n",
    "\n",
    "#Generate all 2-grams\n",
    "alphabet = string.ascii_lowercase\n",
    "\n",
    "# Generate all letter-letter 2-grams (aa-zz)\n",
    "alphabet = string.ascii_lowercase\n",
    "letter_letter_grams = [a + b for a in alphabet for b in alphabet]\n",
    "\n",
    "# Generate all digit-digit 2-grams (00-99)\n",
    "digits = string.digits\n",
    "digit_digit_grams = [d1 + d2 for d1 in digits for d2 in digits]\n",
    "\n",
    "# Generate all letter-digit 2-grams (a0-z9)\n",
    "letter_digit_grams = [l + d for l in alphabet for d in digits]\n",
    "\n",
    "# Combine all sets\n",
    "all_two_grams = letter_letter_grams  + letter_digit_grams + digit_digit_grams\n",
    "\n",
    "# Get a dictionary associating each 2-gram with an index\n",
    "two_gram_dict = {i: two_gram for i, two_gram in enumerate(all_two_grams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Datasets based on chosen encoding\n",
    "if ENC_CONFIG[\"AliceAlgo\"] == \"BloomFilter\":\n",
    "    data_labeled = BloomFilterDataset(df_reidentified_individuals, is_labeled=True, all_two_grams=all_two_grams, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    data_not_labeled = BloomFilterDataset(df_not_reidentified_individuals, is_labeled=False, all_two_grams=all_two_grams, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    bloomfilter_length = len(df_reidentified_individuals[\"bloomfilter\"][0])\n",
    "\n",
    "if ENC_CONFIG[\"AliceAlgo\"] == \"TabMinHash\":\n",
    "    data_labeled = TabMinHashDataset(df_reidentified_individuals, is_labeled=True, all_two_grams=all_two_grams, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    data_not_labeled = TabMinHashDataset(df_not_reidentified_individuals, is_labeled=False, all_two_grams=all_two_grams, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    tabminhash_length = len(df_reidentified_individuals[\"tabminhash\"][0])\n",
    "\n",
    "if (ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\") & (DEA_CONFIG[\"TSHMode\"] == \"Padding\"):\n",
    "    max_length_reidentified = df_reidentified_individuals[\"twostephash\"].apply(lambda x: len(list(x))).max()\n",
    "    max_length_not_reidentified = df_not_reidentified_individuals[\"twostephash\"].apply(lambda x: len(list(x))).max()\n",
    "    max_twostephash_length = max(max_length_reidentified, max_length_not_reidentified)\n",
    "    data_labeled = TwoStepHashDatasetPadding(df_reidentified_individuals, is_labeled=True, all_two_grams=all_two_grams, max_set_size=max_twostephash_length, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    data_not_labeled = TwoStepHashDatasetPadding(df_not_reidentified_individuals, is_labeled=False, all_two_grams=all_two_grams, max_set_size=max_twostephash_length, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "\n",
    "if (ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\") & (DEA_CONFIG[\"TSHMode\"] == \"FrequencyString\"):\n",
    "    max_length_reidentified = df_reidentified_individuals[\"twostephash\"].apply(lambda x: max(x)).max()\n",
    "    max_length_not_reidentified = df_not_reidentified_individuals[\"twostephash\"].apply(lambda x: max(x)).max()\n",
    "    max_twostephash_length = max(max_length_reidentified, max_length_not_reidentified)\n",
    "    data_labeled = TwoStepHashDatasetFrequencyString(df_reidentified_individuals, is_labeled=True, all_two_grams=all_two_grams, frequency_string_length=max_twostephash_length, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    data_not_labeled = TwoStepHashDatasetFrequencyString(df_not_reidentified_individuals, is_labeled=False, all_two_grams=all_two_grams, frequency_string_length=max_twostephash_length, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "\n",
    "if (ENC_CONFIG[\"AliceAlgo\"] == \"TwoStepHash\") & (DEA_CONFIG[\"TSHMode\"] == \"OneHotEncoding\"):\n",
    "    unique_integers_reidentified = set().union(*df_reidentified_individuals[\"twostephash\"])\n",
    "    unique_integers_not_reidentified = set().union(*df_not_reidentified_individuals[\"twostephash\"])\n",
    "    unique_integers_sorted = sorted(unique_integers_reidentified.union(unique_integers_not_reidentified))\n",
    "    unique_integers_dict = {i: val for i, val in enumerate(unique_integers_sorted)}\n",
    "    data_labeled = TwoStepHashDatasetOneHotEncoding(df_reidentified_individuals, is_labeled=True, all_integers=unique_integers_sorted, all_two_grams=all_two_grams, dev_mode=GLOBAL_CONFIG[\"DevMode\"])\n",
    "    data_not_labeled = TwoStepHashDatasetOneHotEncoding(df_not_reidentified_individuals, is_labeled=False, all_integers=unique_integers_sorted, all_two_grams=all_two_grams, dev_mode=GLOBAL_CONFIG[\"DevMode\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split proportions\n",
    "train_size = int(DEA_CONFIG[\"TrainSize\"] * len(data_labeled))\n",
    "val_size = len(data_labeled) - train_size\n",
    "\n",
    "#Split dataset of reidentified individuals\n",
    "data_train, data_val = random_split(data_labeled, [train_size, val_size])\n",
    "\n",
    "# Create dataloader\n",
    "dataloader_train = DataLoader(data_train, batch_size=DEA_CONFIG[\"BatchSize\"], shuffle=True)\n",
    "dataloader_val = DataLoader(data_val, batch_size=DEA_CONFIG[\"BatchSize\"], shuffle=True)\n",
    "dataloader_test = DataLoader(data_not_labeled, batch_size=DEA_CONFIG[\"BatchSize\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    model = BaseModel(\n",
    "    input_dim=bloomfilter_length,\n",
    "    num_two_grams=len(all_two_grams),\n",
    "    num_layers=config[\"num_layers\"],\n",
    "    hidden_layer_size=config[\"hidden_layer_size\"],\n",
    "    dropout_rate=config[\"dropout_rate\"],\n",
    "    activation_fn=config[\"activation_fn\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Define possible loss functions\n",
    "    loss_functions = {\n",
    "    \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss(),\n",
    "    \"MultiLabelSoftMarginLoss\": nn.MultiLabelSoftMarginLoss()\n",
    "    }\n",
    "\n",
    "    criterion = loss_functions[config[\"loss_fn\"]]\n",
    "\n",
    "    optimizers = {\n",
    "        \"Adam\": optim.Adam(model.parameters(), lr=config[\"lr\"]),\n",
    "        \"SGD\": optim.SGD(model.parameters(), lr=config[\"lr\"], momentum=0.9),\n",
    "        \"RMSprop\": optim.RMSprop(model.parameters(), lr=config[\"lr\"])\n",
    "    }\n",
    "\n",
    "    optimizer = optimizers[config[\"optimizer\"]]\n",
    "\n",
    "    for epoch in range(config[\"epochs\"]):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data, labels, _ in dataloader_train:\n",
    "            # Move data to device\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "        train_loss = running_loss / len(dataloader_train.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        #Calculate true training loss?\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, labels, _ in dataloader_val:\n",
    "                # Move data to device\n",
    "                data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(data)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "            val_loss = running_loss / len(dataloader_val.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "    # Switch to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define Threshhold\n",
    "    threshold = DEA_CONFIG[\"FilterThreshold\"]\n",
    "\n",
    "    # Loop through the test dataloader\n",
    "    with torch.no_grad():  # No need to compute gradients during inference\n",
    "        for data_batch, uids in dataloader_test:\n",
    "            # Filter relevant individuals from df_all_individuals\n",
    "            filtered_df = df_all_individuals[df_all_individuals[\"uid\"].isin(uids)].drop(df_all_individuals.columns[-2], axis=1) # Drop encoding column\n",
    "\n",
    "            actual_two_grams_batch = []\n",
    "            for _, entry in filtered_df.iterrows():\n",
    "                row = entry[:-1] # Exclude UID\n",
    "                extracted_two_grams = extract_two_grams(\"\".join(map(str, row)))\n",
    "                actual_two_grams_batch.append({\"uid\": entry[\"uid\"], \"two_grams\": extracted_two_grams})\n",
    "\n",
    "            # Move data to device\n",
    "            data_batch = data_batch.to(device)\n",
    "\n",
    "            # Apply model\n",
    "            logits = model(data_batch)\n",
    "\n",
    "            # Convert logits to probabilities using sigmoid (for binary classification)\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "\n",
    "            # Convert probabilities into 2-gram scores (use two_gram_dict as before)\n",
    "            batch_two_gram_scores = [\n",
    "                {two_gram_dict[j]: score.item() for j, score in enumerate(probabilities[i])} #2: For each sample, go through all predicted probabilities (scores)\n",
    "                for i in range(probabilities.size(0))  # 1: Iterate over each sample in the batch\n",
    "            ]\n",
    "\n",
    "            # Apply threshold to filter 2-gram scores (values above threshold are kept)\n",
    "            batch_filtered_two_gram_scores = [\n",
    "                {two_gram: score for two_gram, score in two_gram_scores.items() if score > threshold}\n",
    "                for two_gram_scores in batch_two_gram_scores\n",
    "            ]\n",
    "\n",
    "            filtered_two_grams = [\n",
    "            {\"uid\": uid, \"two_grams\": {key for key in two_grams.keys()}}\n",
    "            for uid, two_grams in zip(uids, batch_filtered_two_gram_scores)\n",
    "            ]\n",
    "\n",
    "            sum_dice = 0\n",
    "            for entry_two_grams_batch in actual_two_grams_batch:  # Loop through each uid in the batch\n",
    "                for entry_filtered_two_grams in filtered_two_grams:\n",
    "                    if entry_two_grams_batch[\"uid\"] == entry_filtered_two_grams[\"uid\"]:\n",
    "                        dice_sim = dice_coefficient(entry_two_grams_batch[\"two_grams\"], entry_filtered_two_grams[\"two_grams\"])\n",
    "                        sum_dice += dice_sim\n",
    "    tune.report({\"dice\": sum(val_losses)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-07 13:28:43</td></tr>\n",
       "<tr><td>Running for: </td><td>00:51:29.39        </td></tr>\n",
       "<tr><td>Memory:      </td><td>19.7/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=22<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: 18.698141894409957<br>Logical resource usage: 12.0/12 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status    </th><th>loc            </th><th>activation_fn  </th><th style=\"text-align: right;\">  dropout_rate</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">  hidden_layer_size</th><th>loss_fn             </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th>optimizer  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     dice</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_812f6cdb</td><td>RUNNING   </td><td>127.0.0.1:38904</td><td>gelu           </td><td style=\"text-align: right;\">      0.215536</td><td style=\"text-align: right;\">      22</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000466552</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_b67d0faf</td><td>RUNNING   </td><td>127.0.0.1:38923</td><td>relu           </td><td style=\"text-align: right;\">      0.219514</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000160653</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_ad2da1e7</td><td>RUNNING   </td><td>127.0.0.1:38942</td><td>relu           </td><td style=\"text-align: right;\">      0.205408</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000518076</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_d1dee343</td><td>RUNNING   </td><td>127.0.0.1:38954</td><td>relu           </td><td style=\"text-align: right;\">      0.202641</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000487905</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_c6252baa</td><td>RUNNING   </td><td>127.0.0.1:38967</td><td>relu           </td><td style=\"text-align: right;\">      0.132444</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000408372</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_18b47492</td><td>RUNNING   </td><td>127.0.0.1:39029</td><td>relu           </td><td style=\"text-align: right;\">      0.156246</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000569473</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_033e1317</td><td>RUNNING   </td><td>127.0.0.1:39048</td><td>relu           </td><td style=\"text-align: right;\">      0.151622</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">               2048</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.00043994 </td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_18666b56</td><td>RUNNING   </td><td>127.0.0.1:39066</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.134918</td><td style=\"text-align: right;\">      22</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">4.90103e-05</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_aae5bf9c</td><td>RUNNING   </td><td>127.0.0.1:39091</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.152782</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">4.62118e-05</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_680afeb6</td><td>RUNNING   </td><td>127.0.0.1:39124</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.150558</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">4.46912e-05</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_7e4e08b4</td><td>RUNNING   </td><td>127.0.0.1:39188</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.144463</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">5.14791e-05</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_925a42bf</td><td>PENDING   </td><td>               </td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.400417</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">4.08993e-05</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>train_model_9141e23d</td><td>TERMINATED</td><td>127.0.0.1:38069</td><td>relu           </td><td style=\"text-align: right;\">      0.197526</td><td style=\"text-align: right;\">      17</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">0.000746735</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       986.9    </td><td style=\"text-align: right;\">11.7171  </td></tr>\n",
       "<tr><td>train_model_1086e9cf</td><td>TERMINATED</td><td>127.0.0.1:38083</td><td>gelu           </td><td style=\"text-align: right;\">      0.484414</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">1.50876e-05</td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.32627</td><td style=\"text-align: right;\">20.1345  </td></tr>\n",
       "<tr><td>train_model_5f3697f6</td><td>TERMINATED</td><td>127.0.0.1:38096</td><td>relu           </td><td style=\"text-align: right;\">      0.164811</td><td style=\"text-align: right;\">      18</td><td style=\"text-align: right;\">                256</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">0.000834977</td><td style=\"text-align: right;\">           6</td><td>RMSprop    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       969.697  </td><td style=\"text-align: right;\"> 1.16333 </td></tr>\n",
       "<tr><td>train_model_8b8c6407</td><td>TERMINATED</td><td>127.0.0.1:38110</td><td>gelu           </td><td style=\"text-align: right;\">      0.437972</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">                128</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">1.96671e-05</td><td style=\"text-align: right;\">           2</td><td>RMSprop    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       968.174  </td><td style=\"text-align: right;\"> 3.388   </td></tr>\n",
       "<tr><td>train_model_f5efe3ff</td><td>TERMINATED</td><td>127.0.0.1:38133</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.262907</td><td style=\"text-align: right;\">      28</td><td style=\"text-align: right;\">               1024</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">3.41243e-05</td><td style=\"text-align: right;\">           7</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       948.841  </td><td style=\"text-align: right;\">19.4176  </td></tr>\n",
       "<tr><td>train_model_9e52898c</td><td>TERMINATED</td><td>127.0.0.1:38168</td><td>gelu           </td><td style=\"text-align: right;\">      0.370337</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">1.33267e-05</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       949.164  </td><td style=\"text-align: right;\"> 8.31897 </td></tr>\n",
       "<tr><td>train_model_91df3420</td><td>TERMINATED</td><td>127.0.0.1:38177</td><td>gelu           </td><td style=\"text-align: right;\">      0.106872</td><td style=\"text-align: right;\">      12</td><td style=\"text-align: right;\">                128</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000125048</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.43471</td><td style=\"text-align: right;\"> 1.14032 </td></tr>\n",
       "<tr><td>train_model_f5dfe504</td><td>TERMINATED</td><td>127.0.0.1:38191</td><td>gelu           </td><td style=\"text-align: right;\">      0.199153</td><td style=\"text-align: right;\">      17</td><td style=\"text-align: right;\">               2048</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">0.00120042 </td><td style=\"text-align: right;\">           1</td><td>Adam       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       930.998  </td><td style=\"text-align: right;\"> 0.334211</td></tr>\n",
       "<tr><td>train_model_cb7bcf06</td><td>TERMINATED</td><td>127.0.0.1:38202</td><td>gelu           </td><td style=\"text-align: right;\">      0.374433</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">                128</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">2.19581e-05</td><td style=\"text-align: right;\">           6</td><td>Adam       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.59675</td><td style=\"text-align: right;\"> 3.63728 </td></tr>\n",
       "<tr><td>train_model_be2fc166</td><td>TERMINATED</td><td>127.0.0.1:38215</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.345755</td><td style=\"text-align: right;\">      14</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.00125639 </td><td style=\"text-align: right;\">           7</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       914.862  </td><td style=\"text-align: right;\"> 9.6771  </td></tr>\n",
       "<tr><td>train_model_f0c775fa</td><td>TERMINATED</td><td>127.0.0.1:38223</td><td>gelu           </td><td style=\"text-align: right;\">      0.377592</td><td style=\"text-align: right;\">      19</td><td style=\"text-align: right;\">                512</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">3.4808e-05 </td><td style=\"text-align: right;\">           4</td><td>Adam       </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        14.0056 </td><td style=\"text-align: right;\"> 1.77317 </td></tr>\n",
       "<tr><td>train_model_1b27053d</td><td>TERMINATED</td><td>127.0.0.1:38260</td><td>relu           </td><td style=\"text-align: right;\">      0.442363</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">                512</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">0.000295919</td><td style=\"text-align: right;\">           2</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         4.88927</td><td style=\"text-align: right;\"> 6.924   </td></tr>\n",
       "<tr><td>train_model_cace990c</td><td>TERMINATED</td><td>127.0.0.1:38301</td><td>relu           </td><td style=\"text-align: right;\">      0.436816</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">                512</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">2.74125e-05</td><td style=\"text-align: right;\">           2</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         5.04672</td><td style=\"text-align: right;\">11.0947  </td></tr>\n",
       "<tr><td>train_model_0264b923</td><td>TERMINATED</td><td>127.0.0.1:38346</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.47078 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">               1024</td><td>BCEWithLogitsLoss   </td><td style=\"text-align: right;\">4.93634e-05</td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       879.982  </td><td style=\"text-align: right;\">13.8659  </td></tr>\n",
       "<tr><td>train_model_7c75c56d</td><td>TERMINATED</td><td>127.0.0.1:38356</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.270511</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.00929146 </td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       896.909  </td><td style=\"text-align: right;\"> 8.29145 </td></tr>\n",
       "<tr><td>train_model_16309a42</td><td>TERMINATED</td><td>127.0.0.1:38369</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.279534</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.00632681 </td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       900.261  </td><td style=\"text-align: right;\">11.7404  </td></tr>\n",
       "<tr><td>train_model_27f96e16</td><td>TERMINATED</td><td>127.0.0.1:38381</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.27265 </td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">8.55149e-05</td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       902.784  </td><td style=\"text-align: right;\">20.1039  </td></tr>\n",
       "<tr><td>train_model_007e4ca0</td><td>TERMINATED</td><td>127.0.0.1:38406</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.279077</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.00719973 </td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        44.3591 </td><td style=\"text-align: right;\">10.3746  </td></tr>\n",
       "<tr><td>train_model_70e78572</td><td>TERMINATED</td><td>127.0.0.1:38518</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.283776</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">8.15781e-05</td><td style=\"text-align: right;\">           5</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        44.6973 </td><td style=\"text-align: right;\">20.0841  </td></tr>\n",
       "<tr><td>train_model_fef594bd</td><td>TERMINATED</td><td>127.0.0.1:38549</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.280602</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000103601</td><td style=\"text-align: right;\">           7</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        59.3188 </td><td style=\"text-align: right;\">20.0916  </td></tr>\n",
       "<tr><td>train_model_3e3cfd2a</td><td>TERMINATED</td><td>127.0.0.1:38604</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.269547</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.00608838 </td><td style=\"text-align: right;\">           7</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        59.841  </td><td style=\"text-align: right;\">17.3212  </td></tr>\n",
       "<tr><td>train_model_6d51035d</td><td>TERMINATED</td><td>127.0.0.1:38624</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.281072</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">8.31436e-05</td><td style=\"text-align: right;\">           7</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        60.103  </td><td style=\"text-align: right;\">20.0873  </td></tr>\n",
       "<tr><td>train_model_88e4af77</td><td>TERMINATED</td><td>127.0.0.1:38669</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.281304</td><td style=\"text-align: right;\">      29</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">6.94553e-05</td><td style=\"text-align: right;\">           7</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        60.6644 </td><td style=\"text-align: right;\">20.083   </td></tr>\n",
       "<tr><td>train_model_130f847f</td><td>TERMINATED</td><td>127.0.0.1:38682</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.244154</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">7.71589e-05</td><td style=\"text-align: right;\">           7</td><td>RMSprop    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.8885 </td><td style=\"text-align: right;\"> 1.61429 </td></tr>\n",
       "<tr><td>train_model_c7a82cf2</td><td>TERMINATED</td><td>127.0.0.1:38699</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.332874</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">7.71976e-05</td><td style=\"text-align: right;\">           4</td><td>RMSprop    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.86285</td><td style=\"text-align: right;\"> 1.60476 </td></tr>\n",
       "<tr><td>train_model_aee12543</td><td>TERMINATED</td><td>127.0.0.1:38713</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.322396</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">9.3151e-05 </td><td style=\"text-align: right;\">           4</td><td>RMSprop    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.41153</td><td style=\"text-align: right;\"> 1.59878 </td></tr>\n",
       "<tr><td>train_model_b00e383f</td><td>TERMINATED</td><td>127.0.0.1:38725</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.332052</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">8.10767e-05</td><td style=\"text-align: right;\">           4</td><td>RMSprop    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.44942</td><td style=\"text-align: right;\"> 1.60027 </td></tr>\n",
       "<tr><td>train_model_7b08a3a0</td><td>TERMINATED</td><td>127.0.0.1:38738</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.313065</td><td style=\"text-align: right;\">      26</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000239097</td><td style=\"text-align: right;\">           4</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        37.5138 </td><td style=\"text-align: right;\">18.0079  </td></tr>\n",
       "<tr><td>train_model_de9abfc0</td><td>TERMINATED</td><td>127.0.0.1:38762</td><td>leaky_relu     </td><td style=\"text-align: right;\">      0.496446</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000259305</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        32.6139 </td><td style=\"text-align: right;\">18.6961  </td></tr>\n",
       "<tr><td>train_model_a121fbcb</td><td>TERMINATED</td><td>127.0.0.1:38776</td><td>gelu           </td><td style=\"text-align: right;\">      0.498089</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">1.08456e-05</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        34.6767 </td><td style=\"text-align: right;\">18.6964  </td></tr>\n",
       "<tr><td>train_model_2604b1e6</td><td>TERMINATED</td><td>127.0.0.1:38789</td><td>gelu           </td><td style=\"text-align: right;\">      0.234702</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000199618</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        33.8177 </td><td style=\"text-align: right;\">18.7134  </td></tr>\n",
       "<tr><td>train_model_c61e3f25</td><td>TERMINATED</td><td>127.0.0.1:38813</td><td>gelu           </td><td style=\"text-align: right;\">      0.497269</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000174467</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        32.0014 </td><td style=\"text-align: right;\">18.6981  </td></tr>\n",
       "<tr><td>train_model_dbd3f1f6</td><td>TERMINATED</td><td>127.0.0.1:38837</td><td>gelu           </td><td style=\"text-align: right;\">      0.227309</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">1.11218e-05</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        26.7767 </td><td style=\"text-align: right;\">15.9467  </td></tr>\n",
       "<tr><td>train_model_c605917d</td><td>TERMINATED</td><td>127.0.0.1:38856</td><td>gelu           </td><td style=\"text-align: right;\">      0.227478</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000182146</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        31.9544 </td><td style=\"text-align: right;\">18.717   </td></tr>\n",
       "<tr><td>train_model_abe4c412</td><td>TERMINATED</td><td>127.0.0.1:38886</td><td>gelu           </td><td style=\"text-align: right;\">      0.221504</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">               1024</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000226289</td><td style=\"text-align: right;\">           3</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        34.6854 </td><td style=\"text-align: right;\">18.6903  </td></tr>\n",
       "<tr><td>train_model_0e7ac3bb</td><td>TERMINATED</td><td>127.0.0.1:38990</td><td>relu           </td><td style=\"text-align: right;\">      0.197267</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000491209</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.97939</td><td style=\"text-align: right;\">15.9279  </td></tr>\n",
       "<tr><td>train_model_5e4ced4d</td><td>TERMINATED</td><td>127.0.0.1:39010</td><td>relu           </td><td style=\"text-align: right;\">      0.186743</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">                256</td><td>MultiLabelSoftM_71e0</td><td style=\"text-align: right;\">0.000452501</td><td style=\"text-align: right;\">           6</td><td>SGD        </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.4381 </td><td style=\"text-align: right;\">15.9089  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (38 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 12:37:22,349 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7909 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 12:53:34,401 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7884 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 12:53:34,481 E 38048 289022] (raylet) worker_pool.cc:581: Some workers of the worker process(38123) have not registered within the timeout. The process is still alive, probably it's hanging during start.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 12:53:44,474 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7919 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 12:53:54,532 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7918 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 12:54:04,612 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7963 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:09:14,450 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.789 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:09:24,530 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7907 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:09:34,616 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7905 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:09:44,674 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7902 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:04,230 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7866 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:04,337 E 38048 289022] (raylet) worker_pool.cc:581: Some workers of the worker process(38389) have not registered within the timeout. The process is still alive, probably it's hanging during start.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:14,232 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7898 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:24,326 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7946 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:34,335 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7846 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:44,424 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7855 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:24:54,510 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7856 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:25:04,599 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7802 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:25:14,692 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7801 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:25:24,694 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7799 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:25:34,791 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7745 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m *** SIGSEGV received at time=1744025144 ***\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m PC: @        0x1183b8214  (unknown)  ray::rpc::GcsRpcClient::AddTaskEventData()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x118d99e14  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x19d0d2de4  (unknown)  _sigtramp\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1183b80d8  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1183b80d8  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1182eaa20  (unknown)  ray::core::worker::TaskEventBufferImpl::FlushEvents()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1181b4e64  (unknown)  ray::core::CoreWorker::Disconnect()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1181b6578  (unknown)  ray::core::CoreWorker::ForceExit()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1181d78e0  (unknown)  ray::core::CoreWorker::HandleKillActor()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x11820864c  (unknown)  ray::rpc::ServerCallImpl<>::HandleRequestImpl()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1186c5e44  (unknown)  EventTracker::RecordExecution()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1186bd0e0  (unknown)  std::__1::__function::__func<>::operator()()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1186bc7e4  (unknown)  boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x118da87e0  (unknown)  boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x118d9d358  (unknown)  boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x118d9d240  (unknown)  boost::asio::io_context::run()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1181b6658  (unknown)  ray::core::CoreWorker::RunIOService()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x1187552ec  (unknown)  boost::(anonymous namespace)::thread_proxy()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x19d09c2e4  (unknown)  _pthread_start\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m     @        0x19d0970fc  (unknown)  thread_start\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497: *** SIGSEGV received at time=1744025144 ***\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497: PC: @        0x1183b8214  (unknown)  ray::rpc::GcsRpcClient::AddTaskEventData()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497:     @        0x118d99f34  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497:     @        0x19d0d2de4  (unknown)  _sigtramp\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497:     @        0x1183b80d8  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497:     @        0x1183b80d8  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,238 E 38669 296404] logging.cc:497:     @        0x1182eaa20  (unknown)  ray::core::worker::TaskEventBufferImpl::FlushEvents()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x1181b4e64  (unknown)  ray::core::CoreWorker::Disconnect()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x1181b6578  (unknown)  ray::core::CoreWorker::ForceExit()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x1181d78e0  (unknown)  ray::core::CoreWorker::HandleKillActor()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x11820864c  (unknown)  ray::rpc::ServerCallImpl<>::HandleRequestImpl()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x1186c5e44  (unknown)  EventTracker::RecordExecution()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x1186bd0e0  (unknown)  std::__1::__function::__func<>::operator()()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x1186bc7e4  (unknown)  boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,239 E 38669 296404] logging.cc:497:     @        0x118da87e0  (unknown)  boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,240 E 38669 296404] logging.cc:497:     @        0x118d9d358  (unknown)  boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,240 E 38669 296404] logging.cc:497:     @        0x118d9d240  (unknown)  boost::asio::io_context::run()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,240 E 38669 296404] logging.cc:497:     @        0x1181b6658  (unknown)  ray::core::CoreWorker::RunIOService()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,240 E 38669 296404] logging.cc:497:     @        0x1187552ec  (unknown)  boost::(anonymous namespace)::thread_proxy()\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,240 E 38669 296404] logging.cc:497:     @        0x19d09c2e4  (unknown)  _pthread_start\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m [2025-04-07 13:25:44,240 E 38669 296404] logging.cc:497:     @        0x19d0970fc  (unknown)  thread_start\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m Fatal Python error: Segmentation fault\n",
      "\u001b[36m(train_model pid=38669)\u001b[0m \n",
      "\u001b[36m(train_model pid=38669)\u001b[0m \n",
      "\u001b[36m(train_model pid=38669)\u001b[0m Extension modules: msgpack._cmsgpack, google._upb._message, psutil._psutil_osx, psutil._psutil_posix, setproctitle, yaml._yaml, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, ray._raylet, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pandas._libs.hashing, pyarrow.lib, pandas._libs.tslib, pandas._libs.ops, pyarrow._compute, pandas._libs.arrays, pandas._libs.sparse, pandas._libs.reduction, pandas._libs.indexing, pandas._libs.index, pandas._libs.internals, pandas._libs.join, pandas._libs.writers, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.testing, pandas._libs.parsers, pandas._libs.json, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pyarrow._parquet, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, pyarrow._json (total: 80)\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:25:44,886 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7725 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:25:54,975 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7021 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:26:05,075 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7001 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:26:15,173 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.7 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:26:25,271 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6999 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:26:35,272 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6994 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:26:45,367 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6993 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:26:55,367 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6992 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:27:05,380 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6859 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:27:15,384 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6808 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:27:25,399 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6806 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:27:35,421 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6805 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:27:45,435 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6805 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:27:55,453 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6844 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:28:05,469 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6839 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:28:15,500 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6839 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:28:25,513 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6839 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:28:35,529 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6838 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "2025-04-07 13:28:40,266\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-04-07 13:28:43,085\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/I538952/ray_results/train_model_2025-04-07_12-37-13' in 2.8166s.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-07 13:28:45,545 E 38048 289051] (raylet) file_system_monitor.cc:116: /tmp/ray/session_2025-04-07_12-37-11_064519_36639 is over 95% full, available space: 12.6838 GB; capacity: 460.432 GB. Object creation will fail if spilling is required.\n",
      "2025-04-07 13:28:53,193\tINFO tune.py:1041 -- Total run time: 3099.88 seconds (3086.57 seconds for the tuning loop).\n",
      "2025-04-07 13:28:53,194\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/Users/I538952/ray_results/train_model_2025-04-07_12-37-13\", trainable=...)\n",
      "2025-04-07 13:28:53,244\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 1 trial(s):\n",
      "- train_model_925a42bf: FileNotFoundError('Could not fetch metrics for train_model_925a42bf: both result.json and progress.csv were not found at /Users/I538952/ray_results/train_model_2025-04-07_12-37-13/train_model_925a42bf_49_activation_fn=leaky_relu,dropout_rate=0.4004,epochs=21,hidden_layer_size=2048,loss_fn=BCEWithLogitsLoss,lr_2025-04-07_13-27-52')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'num_layers': 5, 'hidden_layer_size': 256, 'dropout_rate': 0.4844135931365565, 'activation_fn': 'gelu', 'optimizer': 'SGD', 'loss_fn': 'MultiLabelSoftMarginLoss', 'lr': 1.5087644320080698e-05, 'epochs': 29}\n"
     ]
    }
   ],
   "source": [
    "# Define extended search space\n",
    "search_space = {\n",
    "    \"num_layers\": tune.randint(1, 8),  # Vary number of layers\n",
    "    \"hidden_layer_size\": tune.choice([128, 256, 512, 1024, 2048]),  # Size of hidden layers\n",
    "    \"dropout_rate\": tune.uniform(0.1, 0.4),  # Dropout\n",
    "    \"activation_fn\": tune.choice([\"relu\", \"leaky_relu\", \"gelu\"]),  # Activation function\n",
    "    \"optimizer\": tune.choice([\"Adam\", \"SGD\", \"RMSprop\"]),  # Optimizer selection\n",
    "    \"loss_fn\": tune.choice([\"BCEWithLogitsLoss\"]),  # Loss function selection\n",
    "    # \"loss_fn\": tune.choice([\"BCEWithLogitsLoss\", \"MultiLabelSoftMarginLoss\"]),  # Loss function selection\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),  # Learning rate\n",
    "    \"epochs\": tune.randint(10, 20),  # Fixed number of epochs\n",
    "}\n",
    "\n",
    "# Run Ray Tune with Optuna\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "optuna_search = OptunaSearch(metric=\"dice\", mode=\"max\")\n",
    "scheduler = ASHAScheduler(metric=\"dice\", mode=\"max\")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    train_model,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        search_alg=optuna_search,\n",
    "        scheduler=scheduler,\n",
    "        num_samples=50  # Number of trials\n",
    "    ),\n",
    "    param_space=search_space\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "print(\"Best hyperparameters:\", results.get_best_result(metric=\"dice\", mode=\"max\").config)\n",
    "\n",
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
